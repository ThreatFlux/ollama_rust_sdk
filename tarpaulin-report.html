<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>html, body {
  margin: 0;
  padding: 0;
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: #ddd;
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: #ccf;
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: #fcc;
}
.files-list__file_medium {
  background: #ffc;
}
.files-list__file_high {
  background: #cfc;
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: white;
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: #338;
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
    content: counter(line);
    margin-right: 10px;
}
.code-line {
  margin: 0;
  padding: 0.3em;
  height: 1em;
  counter-increment: line;
}
.code-line_covered {
  background: #cfc;
}
.code-line_uncovered {
  background: #fcc;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["/","home","vtriple","ollama_rust_sdk","examples","basic_generation.rs"],"content":"//! Basic text generation example\n\nuse ollama_rust_sdk::{OllamaClient, OllamaError};\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    // Initialize logging\n    env_logger::init();\n\n    // Create a client\n    let client = OllamaClient::new(\"http://localhost:11434\")?;\n\n    // Check if the server is healthy\n    if !client.health().await? {\n        eprintln!(\"Ollama server is not healthy or not running\");\n        std::process::exit(1);\n    }\n\n    println!(\"Connected to Ollama server successfully!\");\n\n    // List available models\n    match client.list_models().await {\n        Ok(models) =\u003e {\n            println!(\"Available models:\");\n            for model in \u0026models.models {\n                println!(\"  - {} ({})\", model.name, model.size_string());\n            }\n\n            if models.models.is_empty() {\n                println!(\"No models available. Please pull a model first:\");\n                println!(\"  ollama pull qwen3:30b-a3b\");\n                return Ok(());\n            }\n        }\n        Err(e) =\u003e {\n            eprintln!(\"Failed to list models: {}\", e);\n            return Ok(());\n        }\n    }\n\n    // Use the first available model, or default to qwen3:30b-a3b\n    let models = client.list_models().await?;\n    let model_name = models\n        .models\n        .first()\n        .map(|m| m.name.as_str())\n        .unwrap_or(\"qwen3:30b-a3b\");\n\n    println!(\"\\nUsing model: {}\", model_name);\n\n    // Generate text\n    println!(\"\\n=== Basic Generation ===\");\n    match client\n        .generate()\n        .model(model_name)\n        .prompt(\"Why is the sky blue? Explain in simple terms.\")\n        .temperature(0.7)\n        .max_tokens(150)\n        .send()\n        .await\n    {\n        Ok(response) =\u003e {\n            println!(\"Response: {}\", response.response);\n\n            // Show performance metrics if available\n            if let Some(rate) = response.eval_rate() {\n                println!(\"Generation speed: {:.2} tokens/second\", rate);\n            }\n            if let Some(total_duration) = response.total_duration {\n                println!(\"Total time: {:.2}s\", total_duration as f64 / 1e9);\n            }\n        }\n        Err(OllamaError::ModelNotFound(model)) =\u003e {\n            eprintln!(\"Model '{}' not found. Available models:\", model);\n            let models = client.list_models().await?;\n            for model in models.models {\n                eprintln!(\"  - {}\", model.name);\n            }\n            eprintln!(\"\\nTry pulling a model first:\");\n            eprintln!(\"  ollama pull qwen3:30b-a3b\");\n        }\n        Err(e) =\u003e {\n            eprintln!(\"Generation failed: {}\", e);\n        }\n    }\n\n    // Generate with system prompt\n    println!(\"\\n=== Generation with System Prompt ===\");\n    match client\n        .generate()\n        .model(model_name)\n        .system(\"You are a helpful assistant that explains things like I'm 5 years old.\")\n        .prompt(\"How do computers work?\")\n        .temperature(0.8)\n        .max_tokens(100)\n        .send()\n        .await\n    {\n        Ok(response) =\u003e {\n            println!(\"Response: {}\", response.response);\n        }\n        Err(e) =\u003e {\n            eprintln!(\"Generation with system prompt failed: {}\", e);\n        }\n    }\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","examples","embeddings.rs"],"content":"//! Embeddings example\n\nuse ollama_rust_sdk::OllamaClient;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    env_logger::init();\n\n    let client = OllamaClient::new(\"http://localhost:11434\")?;\n\n    // Check server health\n    if !client.health().await? {\n        eprintln!(\"Ollama server is not available\");\n        return Ok(());\n    }\n\n    println!(\"=== Embeddings Example ===\");\n\n    // Try to use an embedding model, fallback to any available model\n    let embedding_models = [\"qwen3-embedding:8b\", \"nomic-embed-text\", \"all-minilm\"];\n    let models = client.list_models().await?;\n\n    let embedding_model = embedding_models\n        .iter()\n        .find(|\u0026model| models.models.iter().any(|m| m.name.contains(model)))\n        .copied()\n        .unwrap_or_else(|| {\n            // Use first available model as fallback\n            models\n                .models\n                .first()\n                .map(|m| m.name.as_str())\n                .unwrap_or(\"qwen3:30b-a3b\")\n        });\n\n    println!(\"Using embedding model: {}\", embedding_model);\n\n    // Single text embedding\n    println!(\"\\n--- Single Text Embedding ---\");\n    let single_text = \"The quick brown fox jumps over the lazy dog.\";\n\n    match client\n        .embed()\n        .model(embedding_model)\n        .input(single_text)\n        .send()\n        .await\n    {\n        Ok(response) =\u003e {\n            println!(\"Input text: \\\"{}\\\"\", single_text);\n            println!(\n                \"Embedding dimensions: {}\",\n                response.dimensions().unwrap_or(0)\n            );\n\n            if let Some(embedding) = response.get_embedding(0) {\n                println!(\n                    \"First 10 values: {:?}\",\n                    \u0026embedding[..10.min(embedding.len())]\n                );\n\n                // Calculate magnitude (L2 norm)\n                let magnitude: f64 = embedding.iter().map(|x| x * x).sum::\u003cf64\u003e().sqrt();\n                println!(\"Embedding magnitude: {:.4}\", magnitude);\n            }\n        }\n        Err(e) =\u003e {\n            eprintln!(\"Single embedding failed: {}\", e);\n        }\n    }\n\n    // Batch embeddings\n    println!(\"\\n--- Batch Embeddings ---\");\n    let texts = vec![\n        \"I love programming in Rust.\",\n        \"Python is a great language for data science.\",\n        \"Machine learning is fascinating.\",\n        \"The weather is nice today.\",\n        \"I enjoy reading books.\",\n    ];\n\n    match client\n        .embed()\n        .model(embedding_model)\n        .input(texts.clone())\n        .truncate(true)\n        .send()\n        .await\n    {\n        Ok(response) =\u003e {\n            println!(\"Generated {} embeddings\", response.count());\n            println!(\n                \"Embedding dimensions: {}\",\n                response.dimensions().unwrap_or(0)\n            );\n\n            // Calculate pairwise similarities\n            println!(\"\\n--- Similarity Analysis ---\");\n            for (i, text1) in texts.iter().enumerate() {\n                for (j, text2) in texts.iter().enumerate() {\n                    if i \u003c j {\n                        if let (Some(emb1), Some(emb2)) =\n                            (response.get_embedding(i), response.get_embedding(j))\n                        {\n                            if let Some(similarity) =\n                                ollama_rust_sdk::models::embedding::EmbedResponse::cosine_similarity(\n                                    emb1, emb2,\n                                )\n                            {\n                                println!(\n                                    \"Similarity between \\\"{}\\\" and \\\"{}\\\": {:.4}\",\n                                    text1, text2, similarity\n                                );\n                            }\n                        }\n                    }\n                }\n            }\n\n            // Find most similar pair\n            let mut max_similarity = -1.0;\n            let mut most_similar = (0, 0);\n\n            for i in 0..texts.len() {\n                for j in (i + 1)..texts.len() {\n                    if let (Some(emb1), Some(emb2)) =\n                        (response.get_embedding(i), response.get_embedding(j))\n                    {\n                        if let Some(similarity) =\n                            ollama_rust_sdk::models::embedding::EmbedResponse::cosine_similarity(\n                                emb1, emb2,\n                            )\n                        {\n                            if similarity \u003e max_similarity {\n                                max_similarity = similarity;\n                                most_similar = (i, j);\n                            }\n                        }\n                    }\n                }\n            }\n\n            println!(\"\\nMost similar texts (similarity: {:.4}):\", max_similarity);\n            println!(\"  1: \\\"{}\\\"\", texts[most_similar.0]);\n            println!(\"  2: \\\"{}\\\"\", texts[most_similar.1]);\n        }\n        Err(e) =\u003e {\n            eprintln!(\"Batch embeddings failed: {}\", e);\n\n            // If embedding model failed, suggest downloading one\n            if e.to_string().contains(\"not found\") {\n                println!(\"\\nTo use embeddings, try pulling an embedding model:\");\n                println!(\"  ollama pull qwen3-embedding:8b\");\n                println!(\"  ollama pull nomic-embed-text\");\n                println!(\"  ollama pull all-minilm\");\n            }\n        }\n    }\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","examples","streaming_chat.rs"],"content":"//! Streaming chat example\n\nuse ollama_rust_sdk::OllamaClient;\nuse tokio_stream::StreamExt;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    env_logger::init();\n\n    let client = OllamaClient::new(\"http://localhost:11434\")?;\n\n    // Check server health\n    if !client.health().await? {\n        eprintln!(\"Ollama server is not available\");\n        return Ok(());\n    }\n\n    // Get available model\n    let models = client.list_models().await?;\n    let model_name = models\n        .models\n        .first()\n        .map(|m| m.name.as_str())\n        .unwrap_or(\"qwen3:30b-a3b\");\n\n    println!(\"Using model: {}\", model_name);\n    println!(\"Starting streaming chat example..\\n\");\n\n    // Create a streaming chat request\n    let mut stream = client\n        .chat()\n        .model(model_name)\n        .add_system_message(\n            \"You are a helpful AI assistant. Keep your responses concise but informative.\",\n        )\n        .add_user_message(\"Tell me an interesting fact about space exploration.\")\n        .temperature(0.7)\n        .stream()\n        .await?;\n\n    println!(\"Assistant: \");\n    let mut full_response = String::new();\n\n    // Process the stream\n    while let Some(chunk) = stream.next().await {\n        match chunk {\n            Ok(response) =\u003e {\n                print!(\"{}\", response.message.content);\n                full_response.push_str(\u0026response.message.content);\n\n                // Flush stdout to see text appear in real-time\n                use std::io::{self, Write};\n                io::stdout().flush()?;\n\n                if response.done {\n                    println!(\"\\n\\n[Stream completed]\");\n                    if let Some(eval_count) = response.eval_count {\n                        if let Some(eval_duration) = response.eval_duration {\n                            let tokens_per_second =\n                                eval_count as f64 / (eval_duration as f64 / 1e9);\n                            println!(\"Tokens generated: {}\", eval_count);\n                            println!(\"Speed: {:.2} tokens/second\", tokens_per_second);\n                        }\n                    }\n                    break;\n                }\n            }\n            Err(e) =\u003e {\n                eprintln!(\"\\nStream error: {}\", e);\n                break;\n            }\n        }\n    }\n\n    // Demonstrate multi-turn conversation\n    println!(\"\\n{}\", \"=\".repeat(50));\n    println!(\"Multi-turn conversation example:\");\n    println!(\"{}\", \"=\".repeat(50));\n\n    let response = client\n        .chat()\n        .model(model_name)\n        .add_system_message(\"You are a knowledgeable science teacher.\")\n        .add_user_message(\"What is photosynthesis?\")\n        .add_assistant_message(\u0026full_response) // Use previous response\n        .add_user_message(\"Can you explain it in even simpler terms?\")\n        .temperature(0.6)\n        .send()\n        .await?;\n\n    println!(\"\\nTeacher: {}\", response.message.content);\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","blobs.rs"],"content":"//! Blobs API implementation\n\nuse crate::{\n    error::{OllamaError, Result},\n    utils::http::HttpClient,\n};\nuse std::sync::Arc;\n\n/// API implementation for blob management\npub struct BlobsApi;\n\nimpl BlobsApi {\n    /// Check if a blob exists\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or if the server returns an error status.\n    pub async fn blob_exists(http_client: \u0026Arc\u003cHttpClient\u003e, digest: \u0026str) -\u003e Result\u003cbool\u003e {\n        let path = format!(\"api/blobs/{digest}\");\n        let response = http_client.head(\u0026path).await?;\n\n        match response.status().as_u16() {\n            200 =\u003e Ok(true),\n            404 =\u003e Ok(false),\n            status =\u003e Err(OllamaError::ServerError {\n                status,\n                message: \"Blob check failed\".to_string(),\n            }),\n        }\n    }\n\n    /// Create/upload a blob\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or if the server returns an error status.\n    pub async fn create_blob(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        digest: \u0026str,\n        data: Vec\u003cu8\u003e,\n    ) -\u003e Result\u003c()\u003e {\n        let path = format!(\"api/blobs/{digest}\");\n        let response = http_client\n            .put(\u0026path)\n            .header(\"Content-Type\", \"application/octet-stream\")\n            .body(data)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_blob_digest_format() {\n        let digest = \"sha256:29fdb92e57cf0827ded04ae6461b5931d01fa595843f55d36f5b275a52087dd2\";\n        assert!(digest.starts_with(\"sha256:\"));\n        assert_eq!(digest.len(), 71); // \"sha256:\" + 64 hex characters\n    }\n}\n","traces":[{"line":17,"address":[2822784,2822802],"length":1,"stats":{"Line":0}},{"line":18,"address":[2078359,2078238],"length":1,"stats":{"Line":0}},{"line":19,"address":[2867444,2867208,2867618,2867380],"length":1,"stats":{"Line":0}},{"line":21,"address":[6927434,6927373],"length":1,"stats":{"Line":0}},{"line":22,"address":[2079259],"length":1,"stats":{"Line":0}},{"line":23,"address":[2868235],"length":1,"stats":{"Line":0}},{"line":24,"address":[2868288],"length":1,"stats":{"Line":0}},{"line":26,"address":[2876592],"length":1,"stats":{"Line":0}},{"line":35,"address":[2822832],"length":1,"stats":{"Line":0}},{"line":40,"address":[2868778,2868912],"length":1,"stats":{"Line":0}},{"line":41,"address":[6929070,6928967,6928349,6928469,6928942,6928673,6929715,6928584],"length":1,"stats":{"Line":0}},{"line":42,"address":[2877513],"length":1,"stats":{"Line":0}},{"line":44,"address":[2869212],"length":1,"stats":{"Line":0}},{"line":46,"address":[2673305],"length":1,"stats":{"Line":0}},{"line":48,"address":[6929267,6929193],"length":1,"stats":{"Line":0}},{"line":49,"address":[2879102],"length":1,"stats":{"Line":0}},{"line":50,"address":[2081074,2080984],"length":1,"stats":{"Line":0}},{"line":51,"address":[2870433,2870118,2868854],"length":1,"stats":{"Line":0}},{"line":55,"address":[2081030],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":19},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","chat.rs"],"content":"//! Chat API implementation\n\nuse crate::{\n    error::{OllamaError, Result},\n    models::chat::{ChatRequest, ChatResponse},\n    utils::http::HttpClient,\n};\nuse futures_util::StreamExt;\nuse std::sync::Arc;\n\n/// API implementation for chat completions\npub struct ChatApi;\n\nimpl ChatApi {\n    /// Send a chat completion request (non-streaming)\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails, the model is not found, or the server returns an error.\n    pub async fn chat(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        mut request: ChatRequest,\n    ) -\u003e Result\u003cChatResponse\u003e {\n        request.stream = Some(false);\n\n        let response = http_client.post(\"api/chat\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            let message = response.text().await.unwrap_or_default();\n\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(request.model),\n                _ =\u003e OllamaError::ServerError { status, message },\n            });\n        }\n\n        let chat_response: ChatResponse = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(chat_response)\n    }\n\n    /// Send a chat completion request with streaming\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails, the model is not found, or the server returns an error.\n    pub async fn chat_stream(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        mut request: ChatRequest,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cChatResponse\u003e\u003e\u003e {\n        request.stream = Some(true);\n\n        let response = http_client.post(\"api/chat\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(request.model),\n                _ =\u003e OllamaError::ServerError {\n                    status,\n                    message: \"Stream request failed\".to_string(),\n                },\n            });\n        }\n\n        let stream = response.bytes_stream().map(|chunk| match chunk {\n            Ok(bytes) =\u003e {\n                let text = String::from_utf8_lossy(\u0026bytes);\n                for line in text.lines() {\n                    let line = line.trim();\n                    if !line.is_empty() {\n                        match serde_json::from_str::\u003cChatResponse\u003e(line) {\n                            Ok(response) =\u003e return Ok(response),\n                            Err(e) =\u003e {\n                                return Err(OllamaError::InvalidResponse(format!(\n                                    \"Failed to parse chunk: {e} - Line: {line}\"\n                                )))\n                            }\n                        }\n                    }\n                }\n                Err(OllamaError::InvalidResponse(\n                    \"Empty or invalid chunk\".to_string(),\n                ))\n            }\n            Err(e) =\u003e Err(OllamaError::StreamError(e.to_string())),\n        });\n\n        Ok(stream)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::models::chat::MessageRole;\n\n    #[test]\n    fn test_chat_request_creation() {\n        let request = ChatRequest::new(\"test-model\")\n            .add_system_message(\"You are helpful\")\n            .add_user_message(\"Hello\")\n            .stream(false);\n\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.messages.len(), 2);\n        assert_eq!(request.messages[0].role, MessageRole::System);\n        assert_eq!(request.messages[1].role, MessageRole::User);\n        assert_eq!(request.stream, Some(false));\n    }\n}\n","traces":[{"line":19,"address":[1900384],"length":1,"stats":{"Line":1}},{"line":23,"address":[2560180],"length":1,"stats":{"Line":1}},{"line":25,"address":[6743439],"length":1,"stats":{"Line":3}},{"line":27,"address":[2561049,2561129],"length":1,"stats":{"Line":2}},{"line":28,"address":[2561282,2561166],"length":1,"stats":{"Line":0}},{"line":29,"address":[1830162,1830367,1829014,1830030],"length":1,"stats":{"Line":0}},{"line":31,"address":[2561954,2562261],"length":1,"stats":{"Line":0}},{"line":32,"address":[1830637],"length":1,"stats":{"Line":0}},{"line":33,"address":[1830776],"length":1,"stats":{"Line":0}},{"line":37,"address":[6613883,6613600,6612105,6612491,6613442,6613470],"length":1,"stats":{"Line":4}},{"line":39,"address":[2673088],"length":1,"stats":{"Line":3}},{"line":40,"address":[2543152,2544096,2544114],"length":1,"stats":{"Line":0}},{"line":42,"address":[2543303],"length":1,"stats":{"Line":1}},{"line":49,"address":[6825408],"length":1,"stats":{"Line":0}},{"line":53,"address":[2563941],"length":1,"stats":{"Line":0}},{"line":55,"address":[2526301],"length":1,"stats":{"Line":0}},{"line":57,"address":[6615657,6615715],"length":1,"stats":{"Line":0}},{"line":58,"address":[2564848,2564935],"length":1,"stats":{"Line":0}},{"line":59,"address":[2545488,2545665],"length":1,"stats":{"Line":0}},{"line":60,"address":[2564986],"length":1,"stats":{"Line":0}},{"line":61,"address":[2545785],"length":1,"stats":{"Line":0}},{"line":63,"address":[2545634],"length":1,"stats":{"Line":0}},{"line":68,"address":[6618438,6616298,6615772,6617200,6617230],"length":1,"stats":{"Line":0}},{"line":69,"address":[6617308],"length":1,"stats":{"Line":0}},{"line":70,"address":[2546930,2546998],"length":1,"stats":{"Line":0}},{"line":71,"address":[2566505,2566593],"length":1,"stats":{"Line":0}},{"line":72,"address":[1835223,1835425],"length":1,"stats":{"Line":0}},{"line":73,"address":[6617897],"length":1,"stats":{"Line":0}},{"line":74,"address":[1835482],"length":1,"stats":{"Line":0}},{"line":75,"address":[1835580],"length":1,"stats":{"Line":0}},{"line":76,"address":[2547601],"length":1,"stats":{"Line":0}},{"line":77,"address":[2547617,2547759],"length":1,"stats":{"Line":0}},{"line":84,"address":[2547335],"length":1,"stats":{"Line":0}},{"line":85,"address":[2566787],"length":1,"stats":{"Line":0}},{"line":88,"address":[1835993,1834813],"length":1,"stats":{"Line":0}},{"line":91,"address":[1833941],"length":1,"stats":{"Line":0}}],"covered":7,"coverable":36},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","embeddings.rs"],"content":"//! Embeddings API implementation\n\nuse crate::{\n    error::{OllamaError, Result},\n    models::embedding::{\n        EmbedRequest, EmbedResponse, LegacyEmbeddingRequest, LegacyEmbeddingResponse,\n    },\n    utils::http::HttpClient,\n};\nuse std::sync::Arc;\n\n/// API implementation for embeddings\npub struct EmbeddingsApi;\n\nimpl EmbeddingsApi {\n    /// Generate embeddings using the new API\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails, the model is not found, or the server returns an error.\n    pub async fn embed(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        request: EmbedRequest,\n    ) -\u003e Result\u003cEmbedResponse\u003e {\n        let response = http_client.post(\"api/embed\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            let message = response.text().await.unwrap_or_default();\n\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(request.model),\n                _ =\u003e OllamaError::ServerError { status, message },\n            });\n        }\n\n        let embed_response: EmbedResponse = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(embed_response)\n    }\n\n    /// Generate embeddings using the legacy API (deprecated)\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails, the model is not found, or the server returns an error.\n    pub async fn embed_legacy(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        request: LegacyEmbeddingRequest,\n    ) -\u003e Result\u003cLegacyEmbeddingResponse\u003e {\n        let response = http_client\n            .post(\"api/embeddings\")\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            let message = response.text().await.unwrap_or_default();\n\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(request.model),\n                _ =\u003e OllamaError::ServerError { status, message },\n            });\n        }\n\n        let embed_response: LegacyEmbeddingResponse = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(embed_response)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n\n    #[test]\n    fn test_embed_request_creation() {\n        let request = EmbedRequest::new(\"test-model\", \"test text\");\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.input_count(), 1);\n    }\n\n    #[test]\n    fn test_embed_request_multiple_inputs() {\n        let inputs = vec![\"text1\", \"text2\", \"text3\"];\n        let request = EmbedRequest::new(\"test-model\", inputs.clone());\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.input_count(), 3);\n        assert_eq!(request.inputs_as_vec(), vec![\"text1\", \"text2\", \"text3\"]);\n    }\n}\n","traces":[{"line":20,"address":[2872272],"length":1,"stats":{"Line":2}},{"line":24,"address":[2656383],"length":1,"stats":{"Line":6}},{"line":26,"address":[2802562,2802642],"length":1,"stats":{"Line":4}},{"line":27,"address":[2824103,2824219],"length":1,"stats":{"Line":0}},{"line":28,"address":[2824279,2824395,2823228,2824631],"length":1,"stats":{"Line":0}},{"line":30,"address":[2803463,2803770],"length":1,"stats":{"Line":0}},{"line":31,"address":[2824910],"length":1,"stats":{"Line":0}},{"line":32,"address":[2115821],"length":1,"stats":{"Line":0}},{"line":36,"address":[2824130,2825431,2826087,2824516,2825553,2825683],"length":1,"stats":{"Line":8}},{"line":38,"address":[2801822,2803125,2803854,2804103,2803065],"length":1,"stats":{"Line":8}},{"line":39,"address":[2805088,2805106,2804211],"length":1,"stats":{"Line":0}},{"line":41,"address":[2116564],"length":1,"stats":{"Line":2}},{"line":48,"address":[6932752],"length":1,"stats":{"Line":0}},{"line":52,"address":[2827071,2827198,2828326,2826908,2827498,2827601,2827470,2827117],"length":1,"stats":{"Line":0}},{"line":54,"address":[2827102],"length":1,"stats":{"Line":0}},{"line":56,"address":[2827171,2827553,2826954,2827288,2827231,2827472],"length":1,"stats":{"Line":0}},{"line":58,"address":[2806306,2806386],"length":1,"stats":{"Line":0}},{"line":59,"address":[6878875,6878759],"length":1,"stats":{"Line":0}},{"line":60,"address":[2118679,2119015,2118811,2117672],"length":1,"stats":{"Line":0}},{"line":62,"address":[2828631,2828938],"length":1,"stats":{"Line":0}},{"line":63,"address":[2119282],"length":1,"stats":{"Line":0}},{"line":64,"address":[2119421],"length":1,"stats":{"Line":0}},{"line":68,"address":[2829297,2827874,2829831,2829175,2828260,2829427],"length":1,"stats":{"Line":0}},{"line":70,"address":[2829271,2828293,2826990,2828233,2829022],"length":1,"stats":{"Line":0}},{"line":71,"address":[2119987,2120832,2120860],"length":1,"stats":{"Line":0}},{"line":73,"address":[2120164],"length":1,"stats":{"Line":0}}],"covered":6,"coverable":26},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","generate.rs"],"content":"//! Generate API implementation\n\nuse crate::{\n    error::{OllamaError, Result},\n    models::generation::{GenerateRequest, GenerateResponse},\n    utils::http::HttpClient,\n};\nuse futures_util::StreamExt;\nuse std::sync::Arc;\n\n/// API implementation for text generation\npub struct GenerateApi;\n\nimpl GenerateApi {\n    /// Generate text completion (non-streaming)\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or the server returns an error.\n    pub async fn generate(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        mut request: GenerateRequest,\n    ) -\u003e Result\u003cGenerateResponse\u003e {\n        request.stream = Some(false);\n\n        let response = http_client\n            .post(\"api/generate\")\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        let generate_response: GenerateResponse = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(generate_response)\n    }\n\n    /// Generate text completion with streaming\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or the server returns an error.\n    pub async fn generate_stream(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        mut request: GenerateRequest,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cGenerateResponse\u003e\u003e\u003e {\n        request.stream = Some(true);\n\n        let response = http_client\n            .post(\"api/generate\")\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: \"Stream request failed\".to_string(),\n            });\n        }\n\n        let stream = response.bytes_stream().map(|chunk| match chunk {\n            Ok(bytes) =\u003e {\n                let text = String::from_utf8_lossy(\u0026bytes);\n                for line in text.lines() {\n                    if !line.trim().is_empty() {\n                        match serde_json::from_str::\u003cGenerateResponse\u003e(line) {\n                            Ok(response) =\u003e return Ok(response),\n                            Err(e) =\u003e return Err(OllamaError::InvalidResponse(e.to_string())),\n                        }\n                    }\n                }\n                Err(OllamaError::InvalidResponse(\"Empty chunk\".to_string()))\n            }\n            Err(e) =\u003e Err(OllamaError::StreamError(e.to_string())),\n        });\n\n        Ok(stream)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n\n    #[tokio::test]\n    async fn test_generate_request_format() {\n        let request = GenerateRequest::new(\"test-model\", \"test prompt\")\n            .stream(false)\n            .system(\"test system\");\n\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.prompt, \"test prompt\");\n        assert_eq!(request.stream, Some(false));\n        assert_eq!(request.system, Some(\"test system\".to_string()));\n    }\n}\n","traces":[{"line":19,"address":[6822560],"length":1,"stats":{"Line":3}},{"line":23,"address":[2840789],"length":1,"stats":{"Line":3}},{"line":25,"address":[2483649,2482290,2482966,2482521,2482463,2482843,2482574,2482883],"length":1,"stats":{"Line":16}},{"line":27,"address":[6891942],"length":1,"stats":{"Line":3}},{"line":29,"address":[2655452],"length":1,"stats":{"Line":10}},{"line":31,"address":[6892579,6892659],"length":1,"stats":{"Line":4}},{"line":32,"address":[2831844],"length":1,"stats":{"Line":0}},{"line":33,"address":[2483339,2483208],"length":1,"stats":{"Line":0}},{"line":34,"address":[2655474],"length":1,"stats":{"Line":0}},{"line":38,"address":[6892737,6893809,6893939,6893090,6894194,6893781],"length":1,"stats":{"Line":8}},{"line":40,"address":[2674987],"length":1,"stats":{"Line":6}},{"line":41,"address":[2484688,2484716,2484347],"length":1,"stats":{"Line":0}},{"line":43,"address":[2832428],"length":1,"stats":{"Line":2}},{"line":50,"address":[1903280],"length":1,"stats":{"Line":1}},{"line":54,"address":[2832951],"length":1,"stats":{"Line":1}},{"line":56,"address":[2843684,2844234,2843850,2844337,2844206,2843804,2845214,2843931],"length":1,"stats":{"Line":6}},{"line":58,"address":[2833131],"length":1,"stats":{"Line":1}},{"line":60,"address":[2657473],"length":1,"stats":{"Line":4}},{"line":62,"address":[6895432,6895374],"length":1,"stats":{"Line":2}},{"line":63,"address":[2486028],"length":1,"stats":{"Line":0}},{"line":64,"address":[2485877,2485964],"length":1,"stats":{"Line":0}},{"line":65,"address":[2844680],"length":1,"stats":{"Line":0}},{"line":69,"address":[2846302,2844577,2845232,2845262,2844926],"length":1,"stats":{"Line":4}},{"line":70,"address":[2845340],"length":1,"stats":{"Line":1}},{"line":71,"address":[6896345,6896277],"length":1,"stats":{"Line":2}},{"line":72,"address":[6896364,6896452],"length":1,"stats":{"Line":2}},{"line":73,"address":[2487214,2487012],"length":1,"stats":{"Line":2}},{"line":74,"address":[2845961],"length":1,"stats":{"Line":1}},{"line":75,"address":[2846051],"length":1,"stats":{"Line":1}},{"line":76,"address":[2835304,2835418],"length":1,"stats":{"Line":0}},{"line":80,"address":[2487032],"length":1,"stats":{"Line":0}},{"line":82,"address":[2486589,2487601],"length":1,"stats":{"Line":0}},{"line":85,"address":[2486257],"length":1,"stats":{"Line":1}}],"covered":23,"coverable":33},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","mod.rs"],"content":"//! API modules for different Ollama endpoints\n\npub mod blobs;\npub mod chat;\npub mod embeddings;\npub mod generate;\npub mod models;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","api","models.rs"],"content":"//! Models API implementation\n\nuse crate::{\n    error::{OllamaError, Result},\n    models::model_info::{\n        CopyRequest, CreateRequest, DeleteRequest, ModelInfo, ModelList, PullRequest,\n        RunningModels, ShowRequest,\n    },\n    utils::http::HttpClient,\n};\nuse futures_util::StreamExt;\nuse std::sync::Arc;\n\n/// API implementation for model management\npub struct ModelsApi;\n\nimpl ModelsApi {\n    /// List all available models\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or the server returns an error.\n    pub async fn list_models(http_client: \u0026Arc\u003cHttpClient\u003e) -\u003e Result\u003cModelList\u003e {\n        let response = http_client.get(\"api/tags\").await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        let model_list: ModelList = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(model_list)\n    }\n\n    /// Get information about a specific model\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails, the model is not found, or the server returns an error.\n    pub async fn show_model(http_client: \u0026Arc\u003cHttpClient\u003e, name: \u0026str) -\u003e Result\u003cModelInfo\u003e {\n        let request = ShowRequest {\n            name: name.to_string(),\n            verbose: Some(false),\n        };\n\n        let response = http_client.post(\"api/show\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(name.to_string()),\n                _ =\u003e OllamaError::ServerError {\n                    status,\n                    message: response.text().await.unwrap_or_default(),\n                },\n            });\n        }\n\n        let model_info: ModelInfo = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(model_info)\n    }\n\n    /// Pull a model from the registry\n    ///\n    /// # Errors\n    /// Returns an error if the HTTP request fails or the server returns an error.\n    pub async fn pull_model(http_client: \u0026Arc\u003cHttpClient\u003e, name: \u0026str, stream: bool) -\u003e Result\u003c()\u003e {\n        let request = PullRequest {\n            name: name.to_string(),\n            stream: Some(stream),\n            insecure: None,\n        };\n\n        let response = http_client.post(\"api/pull\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        if !stream {\n            let _: serde_json::Value = response\n                .json()\n                .await\n                .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n        }\n\n        Ok(())\n    }\n\n    /// Pull a model with streaming progress\n    pub async fn pull_model_stream(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        name: \u0026str,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cserde_json::Value\u003e\u003e\u003e {\n        let request = PullRequest {\n            name: name.to_string(),\n            stream: Some(true),\n            insecure: None,\n        };\n\n        let response = http_client.post(\"api/pull\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: \"Pull stream request failed\".to_string(),\n            });\n        }\n\n        let stream = response.bytes_stream().map(|chunk| match chunk {\n            Ok(bytes) =\u003e {\n                let text = String::from_utf8_lossy(\u0026bytes);\n                for line in text.lines() {\n                    if !line.trim().is_empty() {\n                        match serde_json::from_str::\u003cserde_json::Value\u003e(line) {\n                            Ok(progress) =\u003e return Ok(progress),\n                            Err(e) =\u003e return Err(OllamaError::InvalidResponse(e.to_string())),\n                        }\n                    }\n                }\n                Err(OllamaError::InvalidResponse(\"Empty chunk\".to_string()))\n            }\n            Err(e) =\u003e Err(OllamaError::StreamError(e.to_string())),\n        });\n\n        Ok(stream)\n    }\n\n    /// Create a new model\n    pub async fn create_model(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        name: \u0026str,\n        modelfile: \u0026str,\n        stream: bool,\n    ) -\u003e Result\u003c()\u003e {\n        let request = CreateRequest {\n            name: name.to_string(),\n            modelfile: modelfile.to_string(),\n            stream: Some(stream),\n            quantize: None,\n        };\n\n        let response = http_client.post(\"api/create\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        Ok(())\n    }\n\n    /// Create a model with streaming progress\n    pub async fn create_model_stream(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        name: \u0026str,\n        modelfile: \u0026str,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cserde_json::Value\u003e\u003e\u003e {\n        let request = CreateRequest {\n            name: name.to_string(),\n            modelfile: modelfile.to_string(),\n            stream: Some(true),\n            quantize: None,\n        };\n\n        let response = http_client.post(\"api/create\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: \"Create stream request failed\".to_string(),\n            });\n        }\n\n        let stream = response.bytes_stream().map(|chunk| match chunk {\n            Ok(bytes) =\u003e {\n                let text = String::from_utf8_lossy(\u0026bytes);\n                for line in text.lines() {\n                    if !line.trim().is_empty() {\n                        match serde_json::from_str::\u003cserde_json::Value\u003e(line) {\n                            Ok(progress) =\u003e return Ok(progress),\n                            Err(e) =\u003e return Err(OllamaError::InvalidResponse(e.to_string())),\n                        }\n                    }\n                }\n                Err(OllamaError::InvalidResponse(\"Empty chunk\".to_string()))\n            }\n            Err(e) =\u003e Err(OllamaError::StreamError(e.to_string())),\n        });\n\n        Ok(stream)\n    }\n\n    /// Copy a model\n    pub async fn copy_model(\n        http_client: \u0026Arc\u003cHttpClient\u003e,\n        source: \u0026str,\n        destination: \u0026str,\n    ) -\u003e Result\u003c()\u003e {\n        let request = CopyRequest {\n            source: source.to_string(),\n            destination: destination.to_string(),\n        };\n\n        let response = http_client.post(\"api/copy\").json(\u0026request).send().await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(source.to_string()),\n                _ =\u003e OllamaError::ServerError {\n                    status,\n                    message: response.text().await.unwrap_or_default(),\n                },\n            });\n        }\n\n        Ok(())\n    }\n\n    /// Delete a model\n    pub async fn delete_model(http_client: \u0026Arc\u003cHttpClient\u003e, name: \u0026str) -\u003e Result\u003c()\u003e {\n        let request = DeleteRequest {\n            name: name.to_string(),\n        };\n\n        let response = http_client\n            .delete(\"api/delete\")\n            .json(\u0026request)\n            .send()\n            .await?;\n\n        if !response.status().is_success() {\n            let status = response.status().as_u16();\n            return Err(match status {\n                404 =\u003e OllamaError::ModelNotFound(name.to_string()),\n                _ =\u003e OllamaError::ServerError {\n                    status,\n                    message: response.text().await.unwrap_or_default(),\n                },\n            });\n        }\n\n        Ok(())\n    }\n\n    /// List running models\n    pub async fn list_running_models(http_client: \u0026Arc\u003cHttpClient\u003e) -\u003e Result\u003cRunningModels\u003e {\n        let response = http_client.get(\"api/ps\").await?;\n\n        if !response.status().is_success() {\n            return Err(OllamaError::ServerError {\n                status: response.status().as_u16(),\n                message: response.text().await.unwrap_or_default(),\n            });\n        }\n\n        let running_models: RunningModels = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n\n        Ok(running_models)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_pull_request_creation() {\n        let request = PullRequest {\n            name: \"test-model\".to_string(),\n            stream: Some(true),\n            insecure: None,\n        };\n\n        assert_eq!(request.name, \"test-model\");\n        assert_eq!(request.stream, Some(true));\n    }\n}\n","traces":[{"line":22,"address":[2797848,2798235,2797967,2799273,2798058,2797792],"length":1,"stats":{"Line":14}},{"line":23,"address":[2655138],"length":1,"stats":{"Line":10}},{"line":25,"address":[2798702,2798775],"length":1,"stats":{"Line":6}},{"line":26,"address":[6850445],"length":1,"stats":{"Line":0}},{"line":27,"address":[6849724,6849845],"length":1,"stats":{"Line":0}},{"line":28,"address":[2776588,2777566,2777855],"length":1,"stats":{"Line":0}},{"line":32,"address":[1922397,1922074,1923009,1923079,1923194,1923410],"length":1,"stats":{"Line":11}},{"line":34,"address":[2674670],"length":1,"stats":{"Line":12}},{"line":35,"address":[2799970,2800290,2800272],"length":1,"stats":{"Line":0}},{"line":37,"address":[2778679],"length":1,"stats":{"Line":4}},{"line":44,"address":[6932882,6932864],"length":1,"stats":{"Line":0}},{"line":46,"address":[2800641],"length":1,"stats":{"Line":0}},{"line":47,"address":[2800819],"length":1,"stats":{"Line":0}},{"line":50,"address":[2674098],"length":1,"stats":{"Line":0}},{"line":52,"address":[2780182,2780259],"length":1,"stats":{"Line":0}},{"line":53,"address":[6852742,6852632],"length":1,"stats":{"Line":0}},{"line":54,"address":[6852988,6852783],"length":1,"stats":{"Line":0}},{"line":55,"address":[2802010,2801877],"length":1,"stats":{"Line":0}},{"line":56,"address":[6853531],"length":1,"stats":{"Line":0}},{"line":57,"address":[2801917],"length":1,"stats":{"Line":0}},{"line":58,"address":[1923898,1925261,1925458,1925048],"length":1,"stats":{"Line":0}},{"line":63,"address":[2803302,2801744,2802250,2802967,2803106,2802939],"length":1,"stats":{"Line":0}},{"line":65,"address":[6851663,6853195,6853651,6853135,6853853],"length":1,"stats":{"Line":0}},{"line":66,"address":[1926122,1926416,1926444],"length":1,"stats":{"Line":0}},{"line":68,"address":[2803209],"length":1,"stats":{"Line":0}},{"line":75,"address":[2803849,2803520,2805394,2804248,2803764,2803582],"length":1,"stats":{"Line":0}},{"line":77,"address":[6854654],"length":1,"stats":{"Line":0}},{"line":78,"address":[2782480],"length":1,"stats":{"Line":0}},{"line":82,"address":[2673796],"length":1,"stats":{"Line":0}},{"line":84,"address":[6855711,6855634],"length":1,"stats":{"Line":0}},{"line":85,"address":[2805657],"length":1,"stats":{"Line":0}},{"line":86,"address":[1927844,1927918],"length":1,"stats":{"Line":0}},{"line":87,"address":[6855879,6856312,6854727],"length":1,"stats":{"Line":0}},{"line":91,"address":[2783450],"length":1,"stats":{"Line":0}},{"line":92,"address":[6857048,6856051,6856200,6857285,6856851,6856909],"length":1,"stats":{"Line":0}},{"line":94,"address":[2654354],"length":1,"stats":{"Line":0}},{"line":95,"address":[2806088,2806237,2806434,2806416],"length":1,"stats":{"Line":0}},{"line":98,"address":[1928213],"length":1,"stats":{"Line":0}},{"line":102,"address":[2872608],"length":1,"stats":{"Line":0}},{"line":107,"address":[6857634],"length":1,"stats":{"Line":0}},{"line":108,"address":[2806833],"length":1,"stats":{"Line":0}},{"line":112,"address":[6859196,6857680,6858083,6857810,6857884],"length":1,"stats":{"Line":0}},{"line":114,"address":[6858509,6858567],"length":1,"stats":{"Line":0}},{"line":115,"address":[2786427],"length":1,"stats":{"Line":0}},{"line":116,"address":[1930596,1930683],"length":1,"stats":{"Line":0}},{"line":117,"address":[6858727],"length":1,"stats":{"Line":0}},{"line":121,"address":[1930608,1930963,1931184,1932309,1931214],"length":1,"stats":{"Line":0}},{"line":122,"address":[2808412],"length":1,"stats":{"Line":0}},{"line":123,"address":[2787081,2787013],"length":1,"stats":{"Line":0}},{"line":124,"address":[1931400,1931488],"length":1,"stats":{"Line":0}},{"line":125,"address":[1931668,1931862],"length":1,"stats":{"Line":0}},{"line":126,"address":[2787601],"length":1,"stats":{"Line":0}},{"line":127,"address":[2787698],"length":1,"stats":{"Line":0}},{"line":128,"address":[2787647,2787845],"length":1,"stats":{"Line":0}},{"line":132,"address":[2808816],"length":1,"stats":{"Line":0}},{"line":134,"address":[2786941,2788036],"length":1,"stats":{"Line":0}},{"line":137,"address":[2786658],"length":1,"stats":{"Line":0}},{"line":141,"address":[2566080],"length":1,"stats":{"Line":0}},{"line":148,"address":[2809873],"length":1,"stats":{"Line":0}},{"line":149,"address":[1932877],"length":1,"stats":{"Line":0}},{"line":150,"address":[1932946],"length":1,"stats":{"Line":0}},{"line":154,"address":[2507151],"length":1,"stats":{"Line":0}},{"line":156,"address":[2810927,2811004],"length":1,"stats":{"Line":0}},{"line":157,"address":[2811736],"length":1,"stats":{"Line":0}},{"line":158,"address":[6861953,6862051],"length":1,"stats":{"Line":0}},{"line":159,"address":[1934010,1932807,1934283],"length":1,"stats":{"Line":0}},{"line":163,"address":[1933908],"length":1,"stats":{"Line":0}},{"line":167,"address":[2882304],"length":1,"stats":{"Line":0}},{"line":173,"address":[2812094],"length":1,"stats":{"Line":0}},{"line":174,"address":[2790789],"length":1,"stats":{"Line":0}},{"line":175,"address":[1935078],"length":1,"stats":{"Line":0}},{"line":179,"address":[2509063],"length":1,"stats":{"Line":0}},{"line":181,"address":[6864032,6864090],"length":1,"stats":{"Line":0}},{"line":182,"address":[1936126],"length":1,"stats":{"Line":0}},{"line":183,"address":[2813223,2813310],"length":1,"stats":{"Line":0}},{"line":184,"address":[2791914],"length":1,"stats":{"Line":0}},{"line":188,"address":[2814961,2813824,2813235,2813581,2813854],"length":1,"stats":{"Line":0}},{"line":189,"address":[1936664],"length":1,"stats":{"Line":0}},{"line":190,"address":[2792533,2792601],"length":1,"stats":{"Line":0}},{"line":191,"address":[1936864,1936776],"length":1,"stats":{"Line":0}},{"line":192,"address":[6865422,6865228],"length":1,"stats":{"Line":0}},{"line":193,"address":[1937273],"length":1,"stats":{"Line":0}},{"line":194,"address":[6865554],"length":1,"stats":{"Line":0}},{"line":195,"address":[1937513,1937319],"length":1,"stats":{"Line":0}},{"line":199,"address":[2814336],"length":1,"stats":{"Line":0}},{"line":201,"address":[1936621,1937704],"length":1,"stats":{"Line":0}},{"line":204,"address":[1936352],"length":1,"stats":{"Line":0}},{"line":208,"address":[6933344],"length":1,"stats":{"Line":0}},{"line":214,"address":[6866256],"length":1,"stats":{"Line":0}},{"line":215,"address":[6866405],"length":1,"stats":{"Line":0}},{"line":218,"address":[6866526,6866821,6866607,6866317,6867899],"length":1,"stats":{"Line":0}},{"line":220,"address":[2794915,2794989],"length":1,"stats":{"Line":0}},{"line":221,"address":[2795099,2795026],"length":1,"stats":{"Line":0}},{"line":222,"address":[2816564,2816762],"length":1,"stats":{"Line":0}},{"line":223,"address":[6867608,6867482],"length":1,"stats":{"Line":0}},{"line":224,"address":[1939915],"length":1,"stats":{"Line":0}},{"line":225,"address":[2816609],"length":1,"stats":{"Line":0}},{"line":226,"address":[2654098],"length":1,"stats":{"Line":0}},{"line":231,"address":[2795060],"length":1,"stats":{"Line":0}},{"line":235,"address":[2566384,2566402],"length":1,"stats":{"Line":0}},{"line":237,"address":[6868487],"length":1,"stats":{"Line":0}},{"line":240,"address":[2817854,2818208,2818186,2817935,2818311,2817814,2817742,2819035],"length":1,"stats":{"Line":0}},{"line":242,"address":[6868757],"length":1,"stats":{"Line":0}},{"line":244,"address":[2675487],"length":1,"stats":{"Line":0}},{"line":246,"address":[1941088,1941020],"length":1,"stats":{"Line":0}},{"line":247,"address":[2797176,2797109],"length":1,"stats":{"Line":0}},{"line":248,"address":[2818641,2818827],"length":1,"stats":{"Line":0}},{"line":249,"address":[2797223,2797337],"length":1,"stats":{"Line":0}},{"line":250,"address":[2797887],"length":1,"stats":{"Line":0}},{"line":251,"address":[1941275],"length":1,"stats":{"Line":0}},{"line":252,"address":[1941481,1940291,1941648,1941284],"length":1,"stats":{"Line":0}},{"line":257,"address":[6869476],"length":1,"stats":{"Line":0}},{"line":261,"address":[1942187,1942443,1942072,1943441,1942278,1942016],"length":1,"stats":{"Line":0}},{"line":262,"address":[2819612,2819777,2819925,2820915,2819658],"length":1,"stats":{"Line":0}},{"line":264,"address":[2798942,2799015],"length":1,"stats":{"Line":0}},{"line":265,"address":[2821197],"length":1,"stats":{"Line":0}},{"line":266,"address":[6871509,6871388],"length":1,"stats":{"Line":0}},{"line":267,"address":[6871855,6870588,6871566],"length":1,"stats":{"Line":0}},{"line":271,"address":[1943357,1944039,1943969,1943034,1944154,1944370],"length":1,"stats":{"Line":0}},{"line":273,"address":[2677406],"length":1,"stats":{"Line":0}},{"line":274,"address":[1944400,1944106,1944428],"length":1,"stats":{"Line":0}},{"line":276,"address":[1944235],"length":1,"stats":{"Line":0}}],"covered":6,"coverable":122},{"path":["/","home","vtriple","ollama_rust_sdk","src","builders","chat_builder.rs"],"content":"//! Builder for chat requests\n\nuse crate::{\n    api::chat::ChatApi,\n    error::Result,\n    models::{\n        chat::{ChatMessage, ChatRequest, ChatResponse, ToolChoice},\n        common::{KeepAlive, Options, ResponseFormat, Tool},\n    },\n    streaming::stream::ChatStream,\n    utils::http::HttpClient,\n};\nuse std::sync::Arc;\n\n/// Builder for chat requests\n#[derive(Debug, Clone)]\npub struct ChatBuilder {\n    http_client: Arc\u003cHttpClient\u003e,\n    request: ChatRequest,\n}\n\nimpl ChatBuilder {\n    /// Create a new chat builder\n    pub fn new(http_client: Arc\u003cHttpClient\u003e) -\u003e Self {\n        Self {\n            http_client,\n            request: ChatRequest::default(),\n        }\n    }\n\n    /// Set the model to use\n    pub fn model\u003cS: Into\u003cString\u003e\u003e(mut self, model: S) -\u003e Self {\n        self.request.model = model.into();\n        self\n    }\n\n    /// Add a message to the conversation\n    pub fn add_message(mut self, message: ChatMessage) -\u003e Self {\n        self.request.messages.push(message);\n        self\n    }\n\n    /// Add a system message\n    pub fn add_system_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.request.messages.push(ChatMessage::system(content));\n        self\n    }\n\n    /// Add a user message\n    pub fn add_user_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.request.messages.push(ChatMessage::user(content));\n        self\n    }\n\n    /// Add an assistant message\n    pub fn add_assistant_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.request.messages.push(ChatMessage::assistant(content));\n        self\n    }\n\n    /// Add a user message with images\n    pub fn add_user_message_with_images\u003cS: Into\u003cString\u003e\u003e(\n        mut self,\n        content: S,\n        images: Vec\u003cString\u003e,\n    ) -\u003e Self {\n        let message = ChatMessage::user(content).with_images(images);\n        self.request.messages.push(message);\n        self\n    }\n\n    /// Set all messages at once\n    pub fn messages(mut self, messages: Vec\u003cChatMessage\u003e) -\u003e Self {\n        self.request.messages = messages;\n        self\n    }\n\n    /// Set generation options\n    pub fn options(mut self, options: Options) -\u003e Self {\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set temperature\n    pub fn temperature(mut self, temperature: f64) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.temperature = Some(temperature);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set max tokens\n    pub fn max_tokens(mut self, max_tokens: u32) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.num_predict = Some(max_tokens as i32);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set top-k\n    pub fn top_k(mut self, top_k: i32) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.top_k = Some(top_k);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set top-p\n    pub fn top_p(mut self, top_p: f64) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.top_p = Some(top_p);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set response format\n    pub fn format(mut self, format: ResponseFormat) -\u003e Self {\n        self.request.format = Some(format);\n        self\n    }\n\n    /// Set keep alive\n    pub fn keep_alive(mut self, keep_alive: KeepAlive) -\u003e Self {\n        self.request.keep_alive = Some(keep_alive);\n        self\n    }\n\n    /// Set available tools\n    pub fn tools(mut self, tools: Vec\u003cTool\u003e) -\u003e Self {\n        self.request.tools = Some(tools);\n        self\n    }\n\n    /// Set tool choice strategy\n    pub fn tool_choice(mut self, choice: ToolChoice) -\u003e Self {\n        self.request.tool_choice = Some(choice);\n        self\n    }\n\n    /// Send the request (non-streaming)\n    pub async fn send(self) -\u003e Result\u003cChatResponse\u003e {\n        ChatApi::chat(\u0026self.http_client, self.request).await\n    }\n\n    /// Send the request with streaming\n    pub async fn stream(self) -\u003e Result\u003cChatStream\u003e {\n        let stream = ChatApi::chat_stream(\u0026self.http_client, self.request).await?;\n        Ok(ChatStream::new(Box::pin(stream)))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n\n    #[test]\n    fn test_chat_builder() {\n        let config = crate::config::ClientConfig::default();\n        let http_client = Arc::new(crate::utils::http::HttpClient::new(config).unwrap());\n\n        let builder = ChatBuilder::new(http_client)\n            .model(\"test-model\")\n            .add_system_message(\"You are helpful\")\n            .add_user_message(\"Hello\")\n            .temperature(0.7);\n\n        assert_eq!(builder.request.model, \"test-model\");\n        assert_eq!(builder.request.messages.len(), 2);\n        assert_eq!(\n            builder.request.messages[0].role,\n            crate::models::chat::MessageRole::System\n        );\n        assert_eq!(\n            builder.request.messages[1].role,\n            crate::models::chat::MessageRole::User\n        );\n\n        let options = builder.request.options.unwrap();\n        assert_eq!(options.temperature, Some(0.7));\n    }\n}\n","traces":[{"line":24,"address":[2776391,2776256,2776385],"length":1,"stats":{"Line":3}},{"line":27,"address":[2776286],"length":1,"stats":{"Line":3}},{"line":32,"address":[1907731,1907488],"length":1,"stats":{"Line":3}},{"line":33,"address":[1907588,1907525],"length":1,"stats":{"Line":6}},{"line":34,"address":[1907711],"length":1,"stats":{"Line":3}},{"line":38,"address":[2776416,2776543],"length":1,"stats":{"Line":0}},{"line":39,"address":[2776456],"length":1,"stats":{"Line":0}},{"line":40,"address":[2756219],"length":1,"stats":{"Line":0}},{"line":44,"address":[1907280,1907464],"length":1,"stats":{"Line":3}},{"line":45,"address":[1843244,1843182],"length":1,"stats":{"Line":6}},{"line":46,"address":[2410668],"length":1,"stats":{"Line":3}},{"line":50,"address":[1907256,1907072],"length":1,"stats":{"Line":3}},{"line":51,"address":[],"length":0,"stats":{"Line":6}},{"line":52,"address":[1907233],"length":1,"stats":{"Line":3}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[2410761,2410827],"length":1,"stats":{"Line":0}},{"line":58,"address":[2410860],"length":1,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[2776735,2776560],"length":1,"stats":{"Line":0}},{"line":74,"address":[2756379,2756288],"length":1,"stats":{"Line":0}},{"line":75,"address":[2756411],"length":1,"stats":{"Line":0}},{"line":79,"address":[2756631,2756448],"length":1,"stats":{"Line":0}},{"line":80,"address":[2255282,2255359],"length":1,"stats":{"Line":0}},{"line":81,"address":[2255384],"length":1,"stats":{"Line":0}},{"line":85,"address":[2777253,2777374,2776960],"length":1,"stats":{"Line":3}},{"line":86,"address":[2255502],"length":1,"stats":{"Line":3}},{"line":87,"address":[2756795],"length":1,"stats":{"Line":3}},{"line":88,"address":[2777148],"length":1,"stats":{"Line":3}},{"line":89,"address":[2777230],"length":1,"stats":{"Line":3}},{"line":93,"address":[2777676,2777797,2777392],"length":1,"stats":{"Line":1}},{"line":94,"address":[2777450],"length":1,"stats":{"Line":1}},{"line":95,"address":[6828437],"length":1,"stats":{"Line":1}},{"line":96,"address":[2256027],"length":1,"stats":{"Line":1}},{"line":97,"address":[2256109],"length":1,"stats":{"Line":1}},{"line":101,"address":[2256256,2256532,2256637],"length":1,"stats":{"Line":0}},{"line":102,"address":[2777882],"length":1,"stats":{"Line":0}},{"line":103,"address":[2256381],"length":1,"stats":{"Line":0}},{"line":104,"address":[2256427],"length":1,"stats":{"Line":0}},{"line":105,"address":[2757781],"length":1,"stats":{"Line":0}},{"line":109,"address":[2256656,2256941,2257046],"length":1,"stats":{"Line":0}},{"line":110,"address":[2256718],"length":1,"stats":{"Line":0}},{"line":111,"address":[2256787],"length":1,"stats":{"Line":0}},{"line":112,"address":[2256836],"length":1,"stats":{"Line":0}},{"line":113,"address":[6829438],"length":1,"stats":{"Line":0}},{"line":117,"address":[6829600],"length":1,"stats":{"Line":0}},{"line":118,"address":[2257095],"length":1,"stats":{"Line":0}},{"line":119,"address":[2758423],"length":1,"stats":{"Line":0}},{"line":123,"address":[2257312,2257136],"length":1,"stats":{"Line":0}},{"line":124,"address":[2778779,2778880],"length":1,"stats":{"Line":0}},{"line":125,"address":[2758612],"length":1,"stats":{"Line":0}},{"line":129,"address":[2257328,2257504],"length":1,"stats":{"Line":0}},{"line":130,"address":[2779088,2778987],"length":1,"stats":{"Line":0}},{"line":131,"address":[2257484],"length":1,"stats":{"Line":0}},{"line":135,"address":[2779168,2779364],"length":1,"stats":{"Line":0}},{"line":136,"address":[2257656,2257547],"length":1,"stats":{"Line":0}},{"line":137,"address":[2779344],"length":1,"stats":{"Line":0}},{"line":141,"address":[2436880,2436930,2437098,2437261,2437507,2437602],"length":1,"stats":{"Line":4}},{"line":142,"address":[1843678,1843927,1843844,1843777],"length":1,"stats":{"Line":3}},{"line":146,"address":[2257792,2257809],"length":1,"stats":{"Line":0}},{"line":147,"address":[1844567,1844489,1844654,1844390],"length":1,"stats":{"Line":0}},{"line":148,"address":[1845260,1845160],"length":1,"stats":{"Line":0}}],"covered":23,"coverable":63},{"path":["/","home","vtriple","ollama_rust_sdk","src","builders","generate_builder.rs"],"content":"//! Builder for generate requests\n\nuse crate::{\n    api::generate::GenerateApi,\n    error::Result,\n    models::{\n        common::{KeepAlive, Options, ResponseFormat},\n        generation::{GenerateRequest, GenerateResponse},\n    },\n    streaming::stream::GenerateStream,\n    utils::http::HttpClient,\n};\nuse std::sync::Arc;\n\n/// Builder for generate requests\n#[derive(Debug, Clone)]\npub struct GenerateBuilder {\n    http_client: Arc\u003cHttpClient\u003e,\n    request: GenerateRequest,\n}\n\nimpl GenerateBuilder {\n    /// Create a new generate builder\n    pub fn new(http_client: Arc\u003cHttpClient\u003e) -\u003e Self {\n        Self {\n            http_client,\n            request: GenerateRequest::default(),\n        }\n    }\n\n    /// Set the model to use\n    pub fn model\u003cS: Into\u003cString\u003e\u003e(mut self, model: S) -\u003e Self {\n        self.request.model = model.into();\n        self\n    }\n\n    /// Set the prompt\n    pub fn prompt\u003cS: Into\u003cString\u003e\u003e(mut self, prompt: S) -\u003e Self {\n        self.request.prompt = prompt.into();\n        self\n    }\n\n    /// Set the system message\n    pub fn system\u003cS: Into\u003cString\u003e\u003e(mut self, system: S) -\u003e Self {\n        self.request.system = Some(system.into());\n        self\n    }\n\n    /// Set the template\n    pub fn template\u003cS: Into\u003cString\u003e\u003e(mut self, template: S) -\u003e Self {\n        self.request.template = Some(template.into());\n        self\n    }\n\n    /// Set the context for conversation continuity\n    pub fn context(mut self, context: Vec\u003ci32\u003e) -\u003e Self {\n        self.request.context = Some(context);\n        self\n    }\n\n    /// Set generation options\n    pub fn options(mut self, options: Options) -\u003e Self {\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set temperature\n    pub fn temperature(mut self, temperature: f64) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.temperature = Some(temperature);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set max tokens\n    pub fn max_tokens(mut self, max_tokens: u32) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.num_predict = Some(max_tokens as i32);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set top-k\n    pub fn top_k(mut self, top_k: i32) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.top_k = Some(top_k);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set top-p\n    pub fn top_p(mut self, top_p: f64) -\u003e Self {\n        let mut options = self.request.options.unwrap_or_default();\n        options.top_p = Some(top_p);\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set response format\n    pub fn format(mut self, format: ResponseFormat) -\u003e Self {\n        self.request.format = Some(format);\n        self\n    }\n\n    /// Set raw mode\n    pub fn raw(mut self, raw: bool) -\u003e Self {\n        self.request.raw = Some(raw);\n        self\n    }\n\n    /// Set keep alive\n    pub fn keep_alive(mut self, keep_alive: KeepAlive) -\u003e Self {\n        self.request.keep_alive = Some(keep_alive);\n        self\n    }\n\n    /// Add images for multimodal models\n    pub fn images(mut self, images: Vec\u003cString\u003e) -\u003e Self {\n        self.request.images = Some(images);\n        self\n    }\n\n    /// Send the request (non-streaming)\n    pub async fn send(self) -\u003e Result\u003cGenerateResponse\u003e {\n        GenerateApi::generate(\u0026self.http_client, self.request).await\n    }\n\n    /// Send the request with streaming\n    pub async fn stream(self) -\u003e Result\u003cGenerateStream\u003e {\n        let stream = GenerateApi::generate_stream(\u0026self.http_client, self.request).await?;\n        Ok(GenerateStream::new(Box::pin(stream)))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n\n    #[test]\n    fn test_generate_builder() {\n        let config = crate::config::ClientConfig::default();\n        let http_client = Arc::new(crate::utils::http::HttpClient::new(config).unwrap());\n\n        let builder = GenerateBuilder::new(http_client)\n            .model(\"test-model\")\n            .prompt(\"test prompt\")\n            .temperature(0.7)\n            .max_tokens(100);\n\n        assert_eq!(builder.request.model, \"test-model\");\n        assert_eq!(builder.request.prompt, \"test prompt\");\n        assert!(builder.request.options.is_some());\n\n        let options = builder.request.options.unwrap();\n        assert_eq!(options.temperature, Some(0.7));\n        assert_eq!(options.num_predict, Some(100));\n    }\n}\n","traces":[{"line":24,"address":[6256565,6256432,6256559],"length":1,"stats":{"Line":5}},{"line":27,"address":[2205549],"length":1,"stats":{"Line":5}},{"line":32,"address":[1872704,1872947],"length":1,"stats":{"Line":5}},{"line":33,"address":[2444868,2444805],"length":1,"stats":{"Line":10}},{"line":34,"address":[1908351],"length":1,"stats":{"Line":5}},{"line":38,"address":[1872976,1873237],"length":1,"stats":{"Line":5}},{"line":39,"address":[1873031,1873094],"length":1,"stats":{"Line":10}},{"line":40,"address":[2445263],"length":1,"stats":{"Line":5}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[2201912,2201728],"length":1,"stats":{"Line":0}},{"line":57,"address":[2205707,2205808],"length":1,"stats":{"Line":0}},{"line":58,"address":[6256756],"length":1,"stats":{"Line":0}},{"line":62,"address":[2202119,2201936],"length":1,"stats":{"Line":0}},{"line":63,"address":[6256850,6256935],"length":1,"stats":{"Line":0}},{"line":64,"address":[2206048],"length":1,"stats":{"Line":0}},{"line":68,"address":[2202437,2202604,2202144],"length":1,"stats":{"Line":5}},{"line":69,"address":[2259342],"length":1,"stats":{"Line":4}},{"line":70,"address":[2202283],"length":1,"stats":{"Line":5}},{"line":71,"address":[2202332],"length":1,"stats":{"Line":5}},{"line":72,"address":[2259542],"length":1,"stats":{"Line":5}},{"line":76,"address":[2202908,2203075,2202624],"length":1,"stats":{"Line":5}},{"line":77,"address":[2202682],"length":1,"stats":{"Line":5}},{"line":78,"address":[6257621],"length":1,"stats":{"Line":5}},{"line":79,"address":[2259915],"length":1,"stats":{"Line":5}},{"line":80,"address":[6257749],"length":1,"stats":{"Line":5}},{"line":84,"address":[2203372,2203088,2203539],"length":1,"stats":{"Line":0}},{"line":85,"address":[2260250],"length":1,"stats":{"Line":0}},{"line":86,"address":[6258085],"length":1,"stats":{"Line":0}},{"line":87,"address":[6258131],"length":1,"stats":{"Line":0}},{"line":88,"address":[2260445],"length":1,"stats":{"Line":0}},{"line":92,"address":[2260640,2260925,2261084],"length":1,"stats":{"Line":0}},{"line":93,"address":[2260702],"length":1,"stats":{"Line":0}},{"line":94,"address":[2260771],"length":1,"stats":{"Line":0}},{"line":95,"address":[2260820],"length":1,"stats":{"Line":0}},{"line":96,"address":[2203822],"length":1,"stats":{"Line":0}},{"line":100,"address":[6258896],"length":1,"stats":{"Line":0}},{"line":101,"address":[2208007],"length":1,"stats":{"Line":0}},{"line":102,"address":[2261143],"length":1,"stats":{"Line":0}},{"line":106,"address":[2208048],"length":1,"stats":{"Line":0}},{"line":107,"address":[2208071],"length":1,"stats":{"Line":0}},{"line":108,"address":[6258999],"length":1,"stats":{"Line":0}},{"line":112,"address":[6259024,6259208],"length":1,"stats":{"Line":0}},{"line":113,"address":[2261259,2261352],"length":1,"stats":{"Line":0}},{"line":114,"address":[2208276],"length":1,"stats":{"Line":0}},{"line":118,"address":[2261604,2261424],"length":1,"stats":{"Line":0}},{"line":119,"address":[2261548,2261451],"length":1,"stats":{"Line":0}},{"line":120,"address":[2208484],"length":1,"stats":{"Line":0}},{"line":124,"address":[2204576,2204593],"length":1,"stats":{"Line":12}},{"line":125,"address":[2528904,2528741,2528799,2528638],"length":1,"stats":{"Line":8}},{"line":129,"address":[2208609,2208592],"length":1,"stats":{"Line":4}},{"line":130,"address":[2646806,2646905,2647070,2646983],"length":1,"stats":{"Line":3}},{"line":131,"address":[2647576,2647676],"length":1,"stats":{"Line":2}}],"covered":23,"coverable":57},{"path":["/","home","vtriple","ollama_rust_sdk","src","builders","mod.rs"],"content":"//! Builder patterns for API requests\n\npub mod chat_builder;\npub mod generate_builder;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","client.rs"],"content":"//! Main client for interacting with the Ollama API\n\nuse crate::{\n    api::{blobs::BlobsApi, embeddings::EmbeddingsApi, models::ModelsApi},\n    builders::{chat_builder::ChatBuilder, generate_builder::GenerateBuilder},\n    config::ClientConfig,\n    error::{OllamaError, Result},\n    models::{\n        embedding::EmbedRequest,\n        model_info::{ModelInfo, ModelList, RunningModels},\n    },\n    utils::http::HttpClient,\n};\nuse std::sync::Arc;\n\n/// Main client for interacting with the Ollama API\n#[derive(Debug, Clone)]\npub struct OllamaClient {\n    /// HTTP client for making requests\n    http_client: Arc\u003cHttpClient\u003e,\n    /// Client configuration\n    config: Arc\u003cClientConfig\u003e,\n}\n\nimpl OllamaClient {\n    /// Create a new Ollama client with the default configuration\n    pub fn new\u003cU: AsRef\u003cstr\u003e\u003e(base_url: U) -\u003e Result\u003cSelf\u003e {\n        let config = ClientConfig::new(base_url)?;\n        Self::with_config(config)\n    }\n\n    /// Create a new Ollama client with custom configuration\n    pub fn with_config(config: ClientConfig) -\u003e Result\u003cSelf\u003e {\n        let http_client = HttpClient::new(config.clone())?;\n\n        Ok(Self {\n            http_client: Arc::new(http_client),\n            config: Arc::new(config),\n        })\n    }\n\n    /// Get the client configuration\n    pub fn config(\u0026self) -\u003e \u0026ClientConfig {\n        \u0026self.config\n    }\n\n    /// Check if the Ollama server is healthy\n    pub async fn health(\u0026self) -\u003e Result\u003cbool\u003e {\n        match self.http_client.get(\"\").await {\n            Ok(response) =\u003e Ok(response.status().is_success()),\n            Err(_) =\u003e Ok(false),\n        }\n    }\n\n    /// Get the Ollama server version\n    pub async fn version(\u0026self) -\u003e Result\u003cserde_json::Value\u003e {\n        let response = self.http_client.get(\"api/version\").await?;\n        let json: serde_json::Value = response\n            .json()\n            .await\n            .map_err(|e| OllamaError::InvalidResponse(e.to_string()))?;\n        Ok(json)\n    }\n\n    // Generation API methods\n\n    /// Create a generate request builder\n    pub fn generate(\u0026self) -\u003e GenerateBuilder {\n        GenerateBuilder::new(self.http_client.clone())\n    }\n\n    // Chat API methods\n\n    /// Create a chat request builder\n    pub fn chat(\u0026self) -\u003e ChatBuilder {\n        ChatBuilder::new(self.http_client.clone())\n    }\n\n    // Embeddings API methods\n\n    /// Create an embeddings request builder\n    pub fn embed(\u0026self) -\u003e EmbedRequestBuilder {\n        EmbedRequestBuilder::new(self.http_client.clone())\n    }\n\n    // Model Management API methods\n\n    /// List all available models\n    pub async fn list_models(\u0026self) -\u003e Result\u003cModelList\u003e {\n        ModelsApi::list_models(\u0026self.http_client).await\n    }\n\n    /// Get information about a specific model\n    pub async fn show_model(\u0026self, name: \u0026str) -\u003e Result\u003cModelInfo\u003e {\n        ModelsApi::show_model(\u0026self.http_client, name).await\n    }\n\n    /// Pull a model from the registry\n    pub async fn pull_model(\u0026self, name: \u0026str) -\u003e Result\u003c()\u003e {\n        ModelsApi::pull_model(\u0026self.http_client, name, false).await\n    }\n\n    /// Pull a model with streaming progress updates\n    pub async fn pull_model_stream(\n        \u0026self,\n        name: \u0026str,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cserde_json::Value\u003e\u003e\u003e {\n        ModelsApi::pull_model_stream(\u0026self.http_client, name).await\n    }\n\n    /// Create a new model from a Modelfile\n    pub async fn create_model(\u0026self, name: \u0026str, modelfile: \u0026str) -\u003e Result\u003c()\u003e {\n        ModelsApi::create_model(\u0026self.http_client, name, modelfile, false).await\n    }\n\n    /// Create a model with streaming progress updates\n    pub async fn create_model_stream(\n        \u0026self,\n        name: \u0026str,\n        modelfile: \u0026str,\n    ) -\u003e Result\u003cimpl tokio_stream::Stream\u003cItem = Result\u003cserde_json::Value\u003e\u003e\u003e {\n        ModelsApi::create_model_stream(\u0026self.http_client, name, modelfile).await\n    }\n\n    /// Copy a model\n    pub async fn copy_model(\u0026self, source: \u0026str, destination: \u0026str) -\u003e Result\u003c()\u003e {\n        ModelsApi::copy_model(\u0026self.http_client, source, destination).await\n    }\n\n    /// Delete a model\n    pub async fn delete_model(\u0026self, name: \u0026str) -\u003e Result\u003c()\u003e {\n        ModelsApi::delete_model(\u0026self.http_client, name).await\n    }\n\n    /// List currently running models\n    pub async fn list_running_models(\u0026self) -\u003e Result\u003cRunningModels\u003e {\n        ModelsApi::list_running_models(\u0026self.http_client).await\n    }\n\n    // Blob Management API methods\n\n    /// Check if a blob exists\n    pub async fn blob_exists(\u0026self, digest: \u0026str) -\u003e Result\u003cbool\u003e {\n        BlobsApi::blob_exists(\u0026self.http_client, digest).await\n    }\n\n    /// Create/upload a blob\n    pub async fn create_blob(\u0026self, digest: \u0026str, data: Vec\u003cu8\u003e) -\u003e Result\u003c()\u003e {\n        BlobsApi::create_blob(\u0026self.http_client, digest, data).await\n    }\n}\n\n/// Builder for embedding requests\n#[derive(Debug)]\npub struct EmbedRequestBuilder {\n    http_client: Arc\u003cHttpClient\u003e,\n    request: EmbedRequest,\n}\n\nimpl EmbedRequestBuilder {\n    fn new(http_client: Arc\u003cHttpClient\u003e) -\u003e Self {\n        Self {\n            http_client,\n            request: EmbedRequest::default(),\n        }\n    }\n\n    /// Set the model to use for embeddings\n    pub fn model\u003cS: Into\u003cString\u003e\u003e(mut self, model: S) -\u003e Self {\n        self.request.model = model.into();\n        self\n    }\n\n    /// Set the input text(s) to embed\n    pub fn input\u003cI\u003e(mut self, input: I) -\u003e Self\n    where\n        I: Into\u003ccrate::models::embedding::EmbedInput\u003e,\n    {\n        self.request.input = input.into();\n        self\n    }\n\n    /// Set additional options\n    pub fn options(mut self, options: crate::models::common::Options) -\u003e Self {\n        self.request.options = Some(options);\n        self\n    }\n\n    /// Set keep alive duration\n    pub fn keep_alive(mut self, keep_alive: crate::models::common::KeepAlive) -\u003e Self {\n        self.request.keep_alive = Some(keep_alive);\n        self\n    }\n\n    /// Enable/disable truncation\n    pub fn truncate(mut self, truncate: bool) -\u003e Self {\n        self.request.truncate = Some(truncate);\n        self\n    }\n\n    /// Send the embedding request\n    pub async fn send(self) -\u003e Result\u003ccrate::models::embedding::EmbedResponse\u003e {\n        EmbeddingsApi::embed(\u0026self.http_client, self.request).await\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_client_creation() {\n        let client = OllamaClient::new(\"http://localhost:11434\");\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    fn test_client_with_invalid_url() {\n        let client = OllamaClient::new(\"invalid-url\");\n        assert!(client.is_err());\n    }\n\n    #[test]\n    fn test_embed_builder() {\n        let config = ClientConfig::default();\n        let http_client = Arc::new(HttpClient::new(config).unwrap());\n\n        let builder = EmbedRequestBuilder::new(http_client)\n            .model(\"test-model\")\n            .input(\"test text\")\n            .truncate(true);\n\n        assert_eq!(builder.request.model, \"test-model\");\n        assert_eq!(builder.request.truncate, Some(true));\n    }\n}\n","traces":[{"line":27,"address":[2489920,2489945,2489552],"length":1,"stats":{"Line":11}},{"line":28,"address":[1841023,1840833],"length":1,"stats":{"Line":21}},{"line":29,"address":[2489825],"length":1,"stats":{"Line":10}},{"line":33,"address":[2768935,2768981,2768304],"length":1,"stats":{"Line":10}},{"line":34,"address":[2748838,2748918],"length":1,"stats":{"Line":20}},{"line":36,"address":[6819797],"length":1,"stats":{"Line":7}},{"line":37,"address":[2749186,2749281],"length":1,"stats":{"Line":11}},{"line":38,"address":[6819689],"length":1,"stats":{"Line":6}},{"line":43,"address":[10911790],"length":1,"stats":{"Line":0}},{"line":44,"address":[6854608,6854621],"length":1,"stats":{"Line":0}},{"line":48,"address":[2749568,2749576],"length":1,"stats":{"Line":18}},{"line":49,"address":[2696664,2696772,2696903,2696707],"length":1,"stats":{"Line":12}},{"line":50,"address":[2697224],"length":1,"stats":{"Line":3}},{"line":51,"address":[2677675],"length":1,"stats":{"Line":0}},{"line":56,"address":[2749600,2749608],"length":1,"stats":{"Line":0}},{"line":57,"address":[2491826,2491006,2491258,2491134,2491045],"length":1,"stats":{"Line":0}},{"line":58,"address":[2492048,2492396,2491669,2491778,2492163,2491984],"length":1,"stats":{"Line":0}},{"line":60,"address":[6749347,6748619,6749448,6749624,6749401],"length":1,"stats":{"Line":0}},{"line":61,"address":[6750048,6750066,6749735],"length":1,"stats":{"Line":0}},{"line":62,"address":[6749884],"length":1,"stats":{"Line":0}},{"line":68,"address":[2749616],"length":1,"stats":{"Line":3}},{"line":69,"address":[2126624],"length":1,"stats":{"Line":3}},{"line":75,"address":[2126656],"length":1,"stats":{"Line":1}},{"line":76,"address":[2749712],"length":1,"stats":{"Line":1}},{"line":82,"address":[6820144],"length":1,"stats":{"Line":2}},{"line":83,"address":[2769264],"length":1,"stats":{"Line":2}},{"line":89,"address":[2749808,2749816],"length":1,"stats":{"Line":10}},{"line":90,"address":[2531735],"length":1,"stats":{"Line":10}},{"line":94,"address":[6820240,6820258],"length":1,"stats":{"Line":0}},{"line":95,"address":[2538407],"length":1,"stats":{"Line":0}},{"line":99,"address":[2681163,2681008,2681200,2681043,2681319,2681617],"length":1,"stats":{"Line":0}},{"line":100,"address":[6751647,6751541,6751590,6751745],"length":1,"stats":{"Line":0}},{"line":104,"address":[2769424],"length":1,"stats":{"Line":0}},{"line":108,"address":[6752366,6752211,6752165,6752268],"length":1,"stats":{"Line":0}},{"line":112,"address":[6820432,6820460],"length":1,"stats":{"Line":0}},{"line":113,"address":[2495122,2495321,2495173,2495243],"length":1,"stats":{"Line":0}},{"line":117,"address":[2769584],"length":1,"stats":{"Line":0}},{"line":122,"address":[6753625,6753568,6753522,6753723],"length":1,"stats":{"Line":0}},{"line":126,"address":[2683699,2683882,2684001,2684299,2683664,2683845],"length":1,"stats":{"Line":0}},{"line":127,"address":[2683826,2684027,2683872,2683929],"length":1,"stats":{"Line":0}},{"line":131,"address":[2127264,2127282],"length":1,"stats":{"Line":0}},{"line":132,"address":[2704044,2704142,2703941,2703987],"length":1,"stats":{"Line":0}},{"line":136,"address":[6820736,6820744],"length":1,"stats":{"Line":0}},{"line":137,"address":[6755448,6755494,6755551,6755649],"length":1,"stats":{"Line":0}},{"line":143,"address":[2498048,2498344,2498196,2498083,2498233,2498630],"length":1,"stats":{"Line":0}},{"line":144,"address":[2705358,2705203,2705157,2705260],"length":1,"stats":{"Line":0}},{"line":148,"address":[2705828,2705865,2705648,2705984,2706282,2705683],"length":1,"stats":{"Line":0}},{"line":149,"address":[6756922,6756824,6756767,6756716],"length":1,"stats":{"Line":0}},{"line":161,"address":[2127456,2127583,2127577],"length":1,"stats":{"Line":4}},{"line":164,"address":[6820910],"length":1,"stats":{"Line":4}},{"line":169,"address":[2597059,2596816],"length":1,"stats":{"Line":4}},{"line":170,"address":[1841527,1841590],"length":1,"stats":{"Line":8}},{"line":171,"address":[1872561],"length":1,"stats":{"Line":4}},{"line":175,"address":[2499790,2499552],"length":1,"stats":{"Line":4}},{"line":179,"address":[6855177],"length":1,"stats":{"Line":8}},{"line":180,"address":[6898603],"length":1,"stats":{"Line":4}},{"line":184,"address":[2127787,2127600],"length":1,"stats":{"Line":0}},{"line":185,"address":[6821183,6821090],"length":1,"stats":{"Line":0}},{"line":186,"address":[2127764],"length":1,"stats":{"Line":0}},{"line":190,"address":[6821448,6821264],"length":1,"stats":{"Line":0}},{"line":191,"address":[2750992,2750891],"length":1,"stats":{"Line":0}},{"line":192,"address":[2127964],"length":1,"stats":{"Line":0}},{"line":196,"address":[2770560],"length":1,"stats":{"Line":2}},{"line":197,"address":[6821495],"length":1,"stats":{"Line":2}},{"line":198,"address":[2751111],"length":1,"stats":{"Line":2}},{"line":202,"address":[2687018,2686800,2686850,2687493,2687181,2687588],"length":1,"stats":{"Line":8}},{"line":203,"address":[2500199,2499950,2500049,2500116],"length":1,"stats":{"Line":6}}],"covered":32,"coverable":67},{"path":["/","home","vtriple","ollama_rust_sdk","src","config.rs"],"content":"//! Configuration for the Ollama client\n\nuse crate::error::{OllamaError, Result};\nuse std::time::Duration;\nuse url::Url;\n\n/// Configuration for the Ollama client\n#[derive(Debug, Clone)]\npub struct ClientConfig {\n    /// Base URL for the Ollama API\n    pub base_url: Url,\n    /// Request timeout duration\n    pub timeout: Duration,\n    /// User agent string\n    pub user_agent: String,\n    /// Maximum number of retries for failed requests\n    pub max_retries: u32,\n    /// Delay between retries\n    pub retry_delay: Duration,\n    /// Whether to follow HTTP redirects\n    pub follow_redirects: bool,\n    /// Custom headers to include in requests\n    pub headers: std::collections::HashMap\u003cString, String\u003e,\n}\n\nimpl Default for ClientConfig {\n    fn default() -\u003e Self {\n        Self {\n            base_url: Url::parse(\"http://localhost:11434\").expect(\"Default URL should be valid\"),\n            timeout: Duration::from_secs(120),\n            user_agent: format!(\"ollama-rust-sdk/{}\", env!(\"CARGO_PKG_VERSION\")),\n            max_retries: 3,\n            retry_delay: Duration::from_millis(1000),\n            follow_redirects: true,\n            headers: std::collections::HashMap::new(),\n        }\n    }\n}\n\nimpl ClientConfig {\n    /// Create a new client configuration with the specified base URL\n    pub fn new\u003cU: AsRef\u003cstr\u003e\u003e(base_url: U) -\u003e Result\u003cSelf\u003e {\n        let base_url = Url::parse(base_url.as_ref())\n            .map_err(|e| OllamaError::ConfigError(format!(\"Invalid base URL: {}\", e)))?;\n\n        Ok(Self {\n            base_url,\n            ..Default::default()\n        })\n    }\n\n    /// Create a builder for client configuration\n    pub fn builder() -\u003e ClientConfigBuilder {\n        ClientConfigBuilder::new()\n    }\n\n    /// Get the full URL for an API endpoint\n    pub fn endpoint_url(\u0026self, path: \u0026str) -\u003e Result\u003cUrl\u003e {\n        let path = if path.starts_with('/') {\n            path\n        } else {\n            \u0026format!(\"/{}\", path)\n        };\n\n        self.base_url.join(path).map_err(|e| {\n            OllamaError::ConfigError(format!(\"Invalid endpoint path '{}': {}\", path, e))\n        })\n    }\n}\n\n/// Builder for client configuration\n#[derive(Debug, Default)]\npub struct ClientConfigBuilder {\n    base_url: Option\u003cString\u003e,\n    timeout: Option\u003cDuration\u003e,\n    user_agent: Option\u003cString\u003e,\n    max_retries: Option\u003cu32\u003e,\n    retry_delay: Option\u003cDuration\u003e,\n    follow_redirects: Option\u003cbool\u003e,\n    headers: std::collections::HashMap\u003cString, String\u003e,\n}\n\nimpl ClientConfigBuilder {\n    /// Create a new configuration builder\n    pub fn new() -\u003e Self {\n        Self::default()\n    }\n\n    /// Set the base URL for the Ollama API\n    pub fn base_url\u003cU: Into\u003cString\u003e\u003e(mut self, url: U) -\u003e Self {\n        self.base_url = Some(url.into());\n        self\n    }\n\n    /// Set the request timeout\n    pub fn timeout(mut self, timeout: Duration) -\u003e Self {\n        self.timeout = Some(timeout);\n        self\n    }\n\n    /// Set the user agent string\n    pub fn user_agent\u003cS: Into\u003cString\u003e\u003e(mut self, user_agent: S) -\u003e Self {\n        self.user_agent = Some(user_agent.into());\n        self\n    }\n\n    /// Set the maximum number of retries\n    pub fn max_retries(mut self, retries: u32) -\u003e Self {\n        self.max_retries = Some(retries);\n        self\n    }\n\n    /// Set the delay between retries\n    pub fn retry_delay(mut self, delay: Duration) -\u003e Self {\n        self.retry_delay = Some(delay);\n        self\n    }\n\n    /// Set whether to follow HTTP redirects\n    pub fn follow_redirects(mut self, follow: bool) -\u003e Self {\n        self.follow_redirects = Some(follow);\n        self\n    }\n\n    /// Add a custom header\n    pub fn header\u003cK: Into\u003cString\u003e, V: Into\u003cString\u003e\u003e(mut self, key: K, value: V) -\u003e Self {\n        self.headers.insert(key.into(), value.into());\n        self\n    }\n\n    /// Build the client configuration\n    pub fn build(self) -\u003e Result\u003cClientConfig\u003e {\n        let base_url = match self.base_url {\n            Some(url) =\u003e Url::parse(\u0026url)\n                .map_err(|e| OllamaError::ConfigError(format!(\"Invalid base URL: {}\", e)))?,\n            None =\u003e ClientConfig::default().base_url,\n        };\n\n        Ok(ClientConfig {\n            base_url,\n            timeout: self\n                .timeout\n                .unwrap_or_else(|| ClientConfig::default().timeout),\n            user_agent: self\n                .user_agent\n                .unwrap_or_else(|| ClientConfig::default().user_agent),\n            max_retries: self\n                .max_retries\n                .unwrap_or_else(|| ClientConfig::default().max_retries),\n            retry_delay: self\n                .retry_delay\n                .unwrap_or_else(|| ClientConfig::default().retry_delay),\n            follow_redirects: self\n                .follow_redirects\n                .unwrap_or_else(|| ClientConfig::default().follow_redirects),\n            headers: self.headers,\n        })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_default_config() {\n        let config = ClientConfig::default();\n        assert_eq!(config.base_url.as_str(), \"http://localhost:11434/\");\n        assert_eq!(config.timeout, Duration::from_secs(120));\n        assert!(config.user_agent.contains(\"ollama-rust-sdk\"));\n    }\n\n    #[test]\n    fn test_config_builder() {\n        let config = ClientConfig::builder()\n            .base_url(\"http://example.com:8080\")\n            .timeout(Duration::from_secs(60))\n            .max_retries(5)\n            .header(\"X-Custom\", \"value\")\n            .build()\n            .unwrap();\n\n        assert_eq!(config.base_url.as_str(), \"http://example.com:8080/\");\n        assert_eq!(config.timeout, Duration::from_secs(60));\n        assert_eq!(config.max_retries, 5);\n        assert_eq!(config.headers.get(\"X-Custom\"), Some(\u0026\"value\".to_string()));\n    }\n\n    #[test]\n    fn test_endpoint_url() {\n        let config = ClientConfig::default();\n\n        let url = config.endpoint_url(\"api/generate\").unwrap();\n        assert_eq!(url.as_str(), \"http://localhost:11434/api/generate\");\n\n        let url = config.endpoint_url(\"/api/chat\").unwrap();\n        assert_eq!(url.as_str(), \"http://localhost:11434/api/chat\");\n    }\n}\n","traces":[{"line":27,"address":[6274912,6275422,6275428],"length":1,"stats":{"Line":14}},{"line":29,"address":[2210209],"length":1,"stats":{"Line":14}},{"line":30,"address":[2224090],"length":1,"stats":{"Line":15}},{"line":31,"address":[2561381],"length":1,"stats":{"Line":11}},{"line":33,"address":[3046128,3046197],"length":1,"stats":{"Line":11}},{"line":35,"address":[3052686],"length":1,"stats":{"Line":16}},{"line":40,"address":[2798386],"length":1,"stats":{"Line":0}},{"line":42,"address":[2558139,2557184,2557240],"length":1,"stats":{"Line":11}},{"line":43,"address":[1903338,1903571,1903425],"length":1,"stats":{"Line":24}},{"line":44,"address":[2798506],"length":1,"stats":{"Line":6}},{"line":46,"address":[2557811],"length":1,"stats":{"Line":10}},{"line":47,"address":[3046688],"length":1,"stats":{"Line":10}},{"line":48,"address":[2065602],"length":1,"stats":{"Line":10}},{"line":53,"address":[2224544],"length":1,"stats":{"Line":2}},{"line":54,"address":[2224552],"length":1,"stats":{"Line":2}},{"line":58,"address":[2562211,2561776,2562182],"length":1,"stats":{"Line":7}},{"line":59,"address":[2562020,2561816],"length":1,"stats":{"Line":8}},{"line":60,"address":[2224800],"length":1,"stats":{"Line":2}},{"line":62,"address":[6275565,6275785],"length":1,"stats":{"Line":14}},{"line":65,"address":[2562088],"length":1,"stats":{"Line":7}},{"line":66,"address":[2066268],"length":1,"stats":{"Line":0}},{"line":85,"address":[6275936],"length":1,"stats":{"Line":2}},{"line":86,"address":[3046750],"length":1,"stats":{"Line":2}},{"line":90,"address":[2798902,2799623],"length":1,"stats":{"Line":2}},{"line":91,"address":[],"length":0,"stats":{"Line":4}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":96,"address":[6275968],"length":1,"stats":{"Line":2}},{"line":97,"address":[2799154],"length":1,"stats":{"Line":2}},{"line":98,"address":[7104946,7104712],"length":1,"stats":{"Line":2}},{"line":102,"address":[3053165,3054066,3053933],"length":1,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[3053987],"length":1,"stats":{"Line":0}},{"line":108,"address":[2225120],"length":1,"stats":{"Line":2}},{"line":109,"address":[2225135],"length":1,"stats":{"Line":2}},{"line":110,"address":[6276073],"length":1,"stats":{"Line":2}},{"line":114,"address":[2225184],"length":1,"stats":{"Line":0}},{"line":115,"address":[2211396],"length":1,"stats":{"Line":0}},{"line":116,"address":[2225229],"length":1,"stats":{"Line":0}},{"line":120,"address":[2562448],"length":1,"stats":{"Line":0}},{"line":121,"address":[2225271],"length":1,"stats":{"Line":0}},{"line":122,"address":[2562487],"length":1,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":2}},{"line":127,"address":[2067146,2066981,2066874],"length":1,"stats":{"Line":4}},{"line":128,"address":[7105768,7105795,7105040],"length":1,"stats":{"Line":2}},{"line":132,"address":[2211504,2212000,2213099],"length":1,"stats":{"Line":2}},{"line":133,"address":[2211526],"length":1,"stats":{"Line":2}},{"line":134,"address":[2212068,2212219,2211579],"length":1,"stats":{"Line":4}},{"line":135,"address":[3054808],"length":1,"stats":{"Line":2}},{"line":136,"address":[2211630,2211690],"length":1,"stats":{"Line":0}},{"line":139,"address":[3048576,3049460,3049441],"length":1,"stats":{"Line":2}},{"line":140,"address":[2211870],"length":1,"stats":{"Line":2}},{"line":141,"address":[2225771],"length":1,"stats":{"Line":2}},{"line":143,"address":[2800843,2800910],"length":1,"stats":{"Line":0}},{"line":144,"address":[3055648,3055434],"length":1,"stats":{"Line":2}},{"line":146,"address":[2801298,2801081],"length":1,"stats":{"Line":4}},{"line":147,"address":[2563581],"length":1,"stats":{"Line":2}},{"line":148,"address":[3049406],"length":1,"stats":{"Line":0}},{"line":149,"address":[2067655,2067648],"length":1,"stats":{"Line":0}},{"line":150,"address":[2212674],"length":1,"stats":{"Line":2}},{"line":151,"address":[3050275,3049504,3050304],"length":1,"stats":{"Line":0}},{"line":152,"address":[6819031,6819024],"length":1,"stats":{"Line":4}},{"line":153,"address":[2563707],"length":1,"stats":{"Line":2}},{"line":155,"address":[2768199,2768192],"length":1,"stats":{"Line":4}},{"line":156,"address":[2563736],"length":1,"stats":{"Line":2}}],"covered":48,"coverable":64},{"path":["/","home","vtriple","ollama_rust_sdk","src","error.rs"],"content":"//! Error types for the Ollama SDK\n\nuse thiserror::Error;\n\n/// Result type alias for Ollama operations\npub type Result\u003cT\u003e = std::result::Result\u003cT, OllamaError\u003e;\n\n/// Comprehensive error types for Ollama SDK operations\n#[derive(Error, Debug)]\npub enum OllamaError {\n    /// Network-related errors (connection issues, timeouts, etc.)\n    #[error(\"Network error: {0}\")]\n    NetworkError(#[from] reqwest::Error),\n\n    /// JSON serialization/deserialization errors\n    #[error(\"JSON error: {0}\")]\n    JsonError(#[from] serde_json::Error),\n\n    /// URL parsing errors\n    #[error(\"Invalid URL: {0}\")]\n    UrlError(#[from] url::ParseError),\n\n    /// Model not found on the server\n    #[error(\"Model '{0}' not found\")]\n    ModelNotFound(String),\n\n    /// Invalid model name format\n    #[error(\"Invalid model name: {0}\")]\n    InvalidModelName(String),\n\n    /// Server returned an error response\n    #[error(\"Server error: {status} - {message}\")]\n    ServerError { status: u16, message: String },\n\n    /// Request timeout\n    #[error(\"Request timeout\")]\n    Timeout,\n\n    /// Invalid API response format\n    #[error(\"Invalid response format: {0}\")]\n    InvalidResponse(String),\n\n    /// Authentication error\n    #[error(\"Authentication failed: {0}\")]\n    AuthenticationError(String),\n\n    /// Rate limit exceeded\n    #[error(\"Rate limit exceeded\")]\n    RateLimitExceeded,\n\n    /// Streaming error\n    #[error(\"Streaming error: {0}\")]\n    StreamError(String),\n\n    /// Configuration error\n    #[error(\"Configuration error: {0}\")]\n    ConfigError(String),\n\n    /// IO error\n    #[error(\"IO error: {0}\")]\n    IoError(#[from] std::io::Error),\n\n    /// Invalid parameters provided\n    #[error(\"Invalid parameter: {parameter} - {reason}\")]\n    InvalidParameter { parameter: String, reason: String },\n\n    /// Model is currently loading\n    #[error(\"Model '{0}' is currently loading, please try again\")]\n    ModelLoading(String),\n\n    /// Insufficient system resources\n    #[error(\"Insufficient resources: {0}\")]\n    InsufficientResources(String),\n\n    /// Generic error for other cases\n    #[error(\"Ollama error: {0}\")]\n    Other(String),\n}\n\nimpl OllamaError {\n    /// Check if the error is retryable\n    pub fn is_retryable(\u0026self) -\u003e bool {\n        matches!(\n            self,\n            OllamaError::NetworkError(_)\n                | OllamaError::Timeout\n                | OllamaError::ModelLoading(_)\n                | OllamaError::ServerError {\n                    status: 500..=599,\n                    ..\n                }\n        )\n    }\n\n    /// Check if the error indicates the model is not available\n    pub fn is_model_unavailable(\u0026self) -\u003e bool {\n        matches!(\n            self,\n            OllamaError::ModelNotFound(_) | OllamaError::ModelLoading(_)\n        )\n    }\n\n    /// Get the HTTP status code if this is a server error\n    pub fn status_code(\u0026self) -\u003e Option\u003cu16\u003e {\n        match self {\n            OllamaError::ServerError { status, .. } =\u003e Some(*status),\n            _ =\u003e None,\n        }\n    }\n}\n","traces":[{"line":6,"address":[3922811,3922752,3922847,3922952,3922912,3923123,3923056],"length":1,"stats":{"Line":0}},{"line":80,"address":[3672035],"length":1,"stats":{"Line":0}},{"line":82,"address":[12557952],"length":1,"stats":{"Line":0}},{"line":83,"address":[2138970,2138943],"length":1,"stats":{"Line":0}},{"line":84,"address":[3369513],"length":1,"stats":{"Line":0}},{"line":85,"address":[10150665],"length":1,"stats":{"Line":0}},{"line":86,"address":[11970445],"length":1,"stats":{"Line":0}},{"line":87,"address":[5671381],"length":1,"stats":{"Line":0}},{"line":88,"address":[5714803],"length":1,"stats":{"Line":0}},{"line":89,"address":[2209085],"length":1,"stats":{"Line":0}},{"line":90,"address":[3672307],"length":1,"stats":{"Line":0}},{"line":96,"address":[5493497,5495354,5496457,5498314],"length":1,"stats":{"Line":0}},{"line":97,"address":[3672545],"length":1,"stats":{"Line":0}},{"line":98,"address":[17156659,17156478],"length":1,"stats":{"Line":0}},{"line":99,"address":[10700226,10700048,10700279,10700147],"length":1,"stats":{"Line":0}},{"line":104,"address":[2205280],"length":1,"stats":{"Line":0}},{"line":105,"address":[17157055,17156879],"length":1,"stats":{"Line":0}},{"line":106,"address":[16021499],"length":1,"stats":{"Line":0}},{"line":107,"address":[2669209,2669082],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":19},{"path":["/","home","vtriple","ollama_rust_sdk","src","lib.rs"],"content":"//! # Ollama Rust SDK\n//!\n//! A comprehensive Rust SDK for interacting with the Ollama API.\n//!\n//! This crate provides type-safe, async-first bindings for all Ollama API endpoints\n//! including text generation, chat, embeddings, and model management.\n//!\n//! ## Features\n//!\n//! - Async/await support with tokio\n//! - Type-safe API with proper error handling\n//! - Streaming support for real-time text generation\n//! - Builder pattern for easy request configuration\n//! - Comprehensive model management\n//! - Embedding generation with batch processing\n//!\n//! ## Quick Start\n//!\n//! ```rust,no_run\n//! use ollama_rust_sdk::OllamaClient;\n//!\n//! #[tokio::main]\n//! async fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n//!     let client = OllamaClient::new(\"http://localhost:11434\")?;\n//!     \n//!     let response = client\n//!         .generate()\n//!         .model(\"qwen3:30b-a3b\")\n//!         .prompt(\"Why is the sky blue?\")\n//!         .send()\n//!         .await?;\n//!     \n//!     println!(\"Response: {}\", response.response);\n//!     Ok(())\n//! }\n//! ```\n\npub mod api;\npub mod builders;\npub mod client;\npub mod config;\npub mod error;\npub mod models;\npub mod streaming;\npub mod types;\npub mod utils;\n\n// Re-export main types for convenience\npub use client::OllamaClient;\npub use config::{ClientConfig, ClientConfigBuilder};\npub use error::{OllamaError, Result};\n\n// Re-export commonly used types\npub use models::{\n    chat::{ChatMessage, ChatRequest, ChatResponse, MessageRole},\n    common::{Options, ToolCall, ToolFunction},\n    embedding::{EmbedRequest, EmbedResponse},\n    generation::{GenerateRequest, GenerateResponse},\n    model_info::{ModelDetails, ModelInfo, ModelList},\n};\n\n// Re-export builders\npub use builders::{chat_builder::ChatBuilder, generate_builder::GenerateBuilder};\n\n// Re-export streaming types\npub use streaming::stream::{ChatStream, GenerateStream, StreamChunk};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","main.rs"],"content":"//! Ollama CLI tool\n//!\n//! A command-line interface for interacting with the Ollama API using the Rust SDK.\n\nuse clap::{Parser, Subcommand};\nuse ollama_rust_sdk::{OllamaClient, OllamaError};\nuse std::io::{self, Write};\nuse tokio_stream::StreamExt;\n\n#[derive(Parser)]\n#[command(name = \"ollama-cli\")]\n#[command(about = \"A CLI for interacting with the Ollama API\")]\n#[command(version)]\nstruct Cli {\n    /// Ollama server URL\n    #[arg(long, default_value = \"http://localhost:11434\")]\n    url: String,\n\n    #[command(subcommand)]\n    command: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    /// Generate text completion\n    Generate {\n        /// The prompt to generate from\n        prompt: String,\n        /// Model to use\n        #[arg(short, long, default_value = \"qwen3:30b-a3b\")]\n        model: String,\n        /// Enable streaming output\n        #[arg(short, long)]\n        stream: bool,\n        /// Temperature for randomness (0.0 to 1.0)\n        #[arg(short, long)]\n        temperature: Option\u003cf64\u003e,\n        /// Maximum number of tokens to generate\n        #[arg(long)]\n        max_tokens: Option\u003cu32\u003e,\n    },\n    /// Start an interactive chat session\n    Chat {\n        /// Model to use for chat\n        #[arg(short, long, default_value = \"qwen3:30b-a3b\")]\n        model: String,\n        /// System message to set context\n        #[arg(short, long)]\n        system: Option\u003cString\u003e,\n    },\n    /// Embed text and get vectors\n    Embed {\n        /// Text to embed\n        text: Vec\u003cString\u003e,\n        /// Model to use for embeddings\n        #[arg(short, long, default_value = \"qwen3-embedding:8b\")]\n        model: String,\n    },\n    /// Model management commands\n    #[command(subcommand)]\n    Models(ModelCommands),\n}\n\n#[derive(Subcommand)]\nenum ModelCommands {\n    /// List available models\n    List,\n    /// Show model information\n    Show {\n        /// Model name to show info for\n        name: String,\n    },\n    /// Pull a model from registry\n    Pull {\n        /// Model name to pull\n        name: String,\n    },\n    /// Delete a model\n    Delete {\n        /// Model name to delete\n        name: String,\n    },\n    /// List running models\n    Running,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    env_logger::init();\n\n    let cli = Cli::parse();\n    let client = OllamaClient::new(\u0026cli.url)?;\n\n    match cli.command {\n        Commands::Generate {\n            prompt,\n            model,\n            stream,\n            temperature,\n            max_tokens,\n        } =\u003e {\n            handle_generate(client, prompt, model, stream, temperature, max_tokens).await?;\n        }\n        Commands::Chat { model, system } =\u003e {\n            handle_chat(client, model, system).await?;\n        }\n        Commands::Embed { text, model } =\u003e {\n            handle_embed(client, text, model).await?;\n        }\n        Commands::Models(model_cmd) =\u003e {\n            handle_model_commands(client, model_cmd).await?;\n        }\n    }\n\n    Ok(())\n}\n\nasync fn handle_generate(\n    client: OllamaClient,\n    prompt: String,\n    model: String,\n    stream: bool,\n    temperature: Option\u003cf64\u003e,\n    max_tokens: Option\u003cu32\u003e,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let mut builder = client.generate().model(\u0026model).prompt(\u0026prompt);\n\n    if let Some(temp) = temperature {\n        builder = builder.temperature(temp);\n    }\n\n    if let Some(max_tokens) = max_tokens {\n        builder = builder.max_tokens(max_tokens);\n    }\n\n    if stream {\n        let mut stream = builder.stream().await?;\n        while let Some(chunk) = stream.next().await {\n            match chunk {\n                Ok(response) =\u003e {\n                    print!(\"{}\", response.response);\n                    io::stdout().flush()?;\n                }\n                Err(e) =\u003e eprintln!(\"Stream error: {}\", e),\n            }\n        }\n        println!();\n    } else {\n        let response = builder.send().await?;\n        println!(\"{}\", response.response);\n    }\n\n    Ok(())\n}\n\nasync fn handle_chat(\n    client: OllamaClient,\n    model: String,\n    system: Option\u003cString\u003e,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    println!(\"Starting chat session with {}. Type 'quit' to exit.\", model);\n\n    let mut chat_builder = client.chat().model(\u0026model);\n\n    if let Some(sys_msg) = system {\n        chat_builder = chat_builder.add_system_message(\u0026sys_msg);\n    }\n\n    loop {\n        print!(\"\u003e \");\n        io::stdout().flush()?;\n\n        let mut input = String::new();\n        io::stdin().read_line(\u0026mut input)?;\n        let input = input.trim();\n\n        if input.is_empty() {\n            continue;\n        }\n\n        if input == \"quit\" {\n            break;\n        }\n\n        chat_builder = chat_builder.add_user_message(input);\n\n        match chat_builder.clone().send().await {\n            Ok(response) =\u003e {\n                println!(\"{}\", response.message.content);\n                chat_builder = chat_builder.add_assistant_message(\u0026response.message.content);\n            }\n            Err(e) =\u003e {\n                eprintln!(\"Error: {}\", e);\n            }\n        }\n    }\n\n    Ok(())\n}\n\nasync fn handle_embed(\n    client: OllamaClient,\n    texts: Vec\u003cString\u003e,\n    model: String,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let response = client\n        .embed()\n        .model(\u0026model)\n        .input(texts.clone())\n        .send()\n        .await?;\n\n    println!(\"Generated {} embeddings:\", response.embeddings.len());\n    for (i, text) in texts.iter().enumerate() {\n        if let Some(embedding) = response.embeddings.get(i) {\n            println!(\"Text: \\\"{}\\\"\", text);\n            println!(\"Embedding dimensions: {}\", embedding.len());\n            println!(\"First 5 values: {:?}\", \u0026embedding[..5.min(embedding.len())]);\n            println!();\n        }\n    }\n\n    Ok(())\n}\n\nasync fn handle_model_commands(\n    client: OllamaClient,\n    command: ModelCommands,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    match command {\n        ModelCommands::List =\u003e {\n            let models = client.list_models().await?;\n            println!(\"Available models:\");\n            for model in models.models {\n                println!(\"  {} ({})\", model.name, model.size);\n                if let Some(modified) = model.modified_at {\n                    println!(\"    Modified: {}\", modified.format(\"%Y-%m-%d %H:%M:%S\"));\n                }\n            }\n        }\n        ModelCommands::Show { name } =\u003e match client.show_model(\u0026name).await {\n            Ok(info) =\u003e {\n                println!(\"Model: {}\", name);\n                println!(\"Template: {}\", info.template.unwrap_or_default());\n                if let Some(params) = info.parameters {\n                    println!(\"Parameters: {}\", params);\n                }\n                if let Some(details) = info.details {\n                    println!(\"Family: {}\", details.family);\n                    println!(\"Format: {}\", details.format);\n                    println!(\"Parameter Size: {}\", details.parameter_size);\n                    println!(\"Quantization Level: {}\", details.quantization_level);\n                }\n            }\n            Err(OllamaError::ModelNotFound(_)) =\u003e {\n                eprintln!(\"Model '{}' not found\", name);\n            }\n            Err(e) =\u003e return Err(e.into()),\n        },\n        ModelCommands::Pull { name } =\u003e {\n            println!(\"Pulling model '{}'...\", name);\n            client.pull_model(\u0026name).await?;\n            println!(\"Successfully pulled model '{}'\", name);\n        }\n        ModelCommands::Delete { name } =\u003e {\n            println!(\"Deleting model '{}'...\", name);\n            client.delete_model(\u0026name).await?;\n            println!(\"Successfully deleted model '{}'\", name);\n        }\n        ModelCommands::Running =\u003e {\n            let running = client.list_running_models().await?;\n            if running.models.is_empty() {\n                println!(\"No models currently running\");\n            } else {\n                println!(\"Running models:\");\n                for model in running.models {\n                    println!(\"  {} ({})\", model.name, model.size);\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n","traces":[{"line":88,"address":[2515104,2515546,2515552],"length":1,"stats":{"Line":0}},{"line":89,"address":[2590520],"length":1,"stats":{"Line":0}},{"line":91,"address":[2590783],"length":1,"stats":{"Line":0}},{"line":92,"address":[2590909,2592392,2591096],"length":1,"stats":{"Line":0}},{"line":94,"address":[2515386,2515280,2515210,2515150],"length":1,"stats":{"Line":0}},{"line":95,"address":[2591396],"length":1,"stats":{"Line":0}},{"line":102,"address":[2534817],"length":1,"stats":{"Line":0}},{"line":104,"address":[2591601],"length":1,"stats":{"Line":0}},{"line":105,"address":[2534833],"length":1,"stats":{"Line":0}},{"line":107,"address":[2591751],"length":1,"stats":{"Line":0}},{"line":108,"address":[2593335,2592226,2591839,2593695,2590702],"length":1,"stats":{"Line":0}},{"line":110,"address":[2591901],"length":1,"stats":{"Line":0}},{"line":111,"address":[2534871],"length":1,"stats":{"Line":0}},{"line":115,"address":[2515234,2515418],"length":1,"stats":{"Line":0}},{"line":118,"address":[2464736],"length":1,"stats":{"Line":0}},{"line":126,"address":[2571315,2571482],"length":1,"stats":{"Line":0}},{"line":128,"address":[2571710,2571552],"length":1,"stats":{"Line":0}},{"line":129,"address":[2571629,2571684],"length":1,"stats":{"Line":0}},{"line":132,"address":[2571712,2571667,2571844],"length":1,"stats":{"Line":0}},{"line":133,"address":[2571769,2571818],"length":1,"stats":{"Line":0}},{"line":136,"address":[2571812],"length":1,"stats":{"Line":0}},{"line":137,"address":[2536739],"length":1,"stats":{"Line":0}},{"line":138,"address":[2573672,2571400,2572692,2572600,2572779],"length":1,"stats":{"Line":0}},{"line":139,"address":[2572986],"length":1,"stats":{"Line":0}},{"line":140,"address":[2573136],"length":1,"stats":{"Line":0}},{"line":141,"address":[2573138,2573209],"length":1,"stats":{"Line":0}},{"line":142,"address":[2573468,2573278],"length":1,"stats":{"Line":0}},{"line":144,"address":[2573532,2573034],"length":1,"stats":{"Line":0}},{"line":147,"address":[2573713],"length":1,"stats":{"Line":0}},{"line":149,"address":[2571421,2574664,2573822,2571882,2571992],"length":1,"stats":{"Line":0}},{"line":150,"address":[2574236,2574307],"length":1,"stats":{"Line":0}},{"line":153,"address":[2573784],"length":1,"stats":{"Line":0}},{"line":156,"address":[2464912],"length":1,"stats":{"Line":0}},{"line":161,"address":[2574994,2575138],"length":1,"stats":{"Line":0}},{"line":163,"address":[2575207,2575280],"length":1,"stats":{"Line":0}},{"line":165,"address":[2575329],"length":1,"stats":{"Line":0}},{"line":166,"address":[2575579,2575421],"length":1,"stats":{"Line":0}},{"line":170,"address":[2576659,2575509],"length":1,"stats":{"Line":0}},{"line":171,"address":[2576678,2578203],"length":1,"stats":{"Line":0}},{"line":173,"address":[2576860],"length":1,"stats":{"Line":0}},{"line":174,"address":[2576954,2576882,2578125],"length":1,"stats":{"Line":0}},{"line":175,"address":[2577136],"length":1,"stats":{"Line":0}},{"line":177,"address":[2577236],"length":1,"stats":{"Line":0}},{"line":181,"address":[2577279,2577349],"length":1,"stats":{"Line":0}},{"line":185,"address":[2577480,2577355],"length":1,"stats":{"Line":0}},{"line":187,"address":[2575730,2577529,2575055,2575760,2576019,2577607],"length":1,"stats":{"Line":0}},{"line":188,"address":[2576149],"length":1,"stats":{"Line":0}},{"line":189,"address":[2576222,2576151],"length":1,"stats":{"Line":0}},{"line":190,"address":[2576291],"length":1,"stats":{"Line":0}},{"line":192,"address":[2576047],"length":1,"stats":{"Line":0}},{"line":193,"address":[2576568,2576111],"length":1,"stats":{"Line":0}},{"line":198,"address":[2577695],"length":1,"stats":{"Line":0}},{"line":201,"address":[2464992],"length":1,"stats":{"Line":0}},{"line":206,"address":[2578807,2579428,2581177,2579313,2579531,2578901,2578948,2578670,2579046],"length":1,"stats":{"Line":0}},{"line":208,"address":[2578779,2578814],"length":1,"stats":{"Line":0}},{"line":209,"address":[2578822,2578744,2578940,2578860,2579106],"length":1,"stats":{"Line":0}},{"line":211,"address":[2579039,2579409,2579079,2579160,2579483,2578731],"length":1,"stats":{"Line":0}},{"line":213,"address":[2579843,2579764],"length":1,"stats":{"Line":0}},{"line":214,"address":[2579947],"length":1,"stats":{"Line":0}},{"line":215,"address":[2580244,2580601],"length":1,"stats":{"Line":0}},{"line":216,"address":[2580686],"length":1,"stats":{"Line":0}},{"line":217,"address":[2580787],"length":1,"stats":{"Line":0}},{"line":218,"address":[2580917],"length":1,"stats":{"Line":0}},{"line":219,"address":[2581111],"length":1,"stats":{"Line":0}},{"line":223,"address":[2580276],"length":1,"stats":{"Line":0}},{"line":226,"address":[2465072],"length":1,"stats":{"Line":0}},{"line":230,"address":[2581544],"length":1,"stats":{"Line":0}},{"line":232,"address":[2581715,2584351,2581618,2583015,2582027],"length":1,"stats":{"Line":0}},{"line":233,"address":[2583527,2583460],"length":1,"stats":{"Line":0}},{"line":234,"address":[2583736,2583546],"length":1,"stats":{"Line":0}},{"line":235,"address":[2583813,2583937],"length":1,"stats":{"Line":0}},{"line":236,"address":[2584049],"length":1,"stats":{"Line":0}},{"line":237,"address":[2584106,2584179],"length":1,"stats":{"Line":0}},{"line":241,"address":[2537299],"length":1,"stats":{"Line":0}},{"line":242,"address":[2584769],"length":1,"stats":{"Line":0}},{"line":243,"address":[2584898,2584823],"length":1,"stats":{"Line":0}},{"line":244,"address":[2584967],"length":1,"stats":{"Line":0}},{"line":245,"address":[2585193],"length":1,"stats":{"Line":0}},{"line":246,"address":[2585270,2585387],"length":1,"stats":{"Line":0}},{"line":248,"address":[2585297,2585478],"length":1,"stats":{"Line":0}},{"line":249,"address":[2585611,2585526],"length":1,"stats":{"Line":0}},{"line":250,"address":[2585680],"length":1,"stats":{"Line":0}},{"line":251,"address":[2585776],"length":1,"stats":{"Line":0}},{"line":252,"address":[2585872],"length":1,"stats":{"Line":0}},{"line":256,"address":[2586884,2587031],"length":1,"stats":{"Line":0}},{"line":258,"address":[2586915,2587203],"length":1,"stats":{"Line":0}},{"line":260,"address":[2581826],"length":1,"stats":{"Line":0}},{"line":261,"address":[2582327,2581850],"length":1,"stats":{"Line":0}},{"line":262,"address":[2537318],"length":1,"stats":{"Line":0}},{"line":263,"address":[2587655],"length":1,"stats":{"Line":0}},{"line":265,"address":[2581884],"length":1,"stats":{"Line":0}},{"line":266,"address":[2582623,2581908],"length":1,"stats":{"Line":0}},{"line":267,"address":[2537337],"length":1,"stats":{"Line":0}},{"line":268,"address":[2588199],"length":1,"stats":{"Line":0}},{"line":271,"address":[2537356],"length":1,"stats":{"Line":0}},{"line":272,"address":[2588830,2588886],"length":1,"stats":{"Line":0}},{"line":273,"address":[2589453,2588918],"length":1,"stats":{"Line":0}},{"line":275,"address":[2588947,2588892],"length":1,"stats":{"Line":0}},{"line":276,"address":[2588966,2589156],"length":1,"stats":{"Line":0}},{"line":277,"address":[2589214,2589319],"length":1,"stats":{"Line":0}},{"line":283,"address":[2583855],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":101},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","chat.rs"],"content":"//! Chat API request and response models\n\nuse crate::models::common::{KeepAlive, Options, ResponseFormat, Tool, ToolCall};\nuse serde::{Deserialize, Serialize};\n\n/// Role of a message in a chat conversation\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum MessageRole {\n    /// System message that provides context\n    System,\n    /// User message\n    User,\n    /// Assistant/AI response\n    Assistant,\n    /// Tool/function call result\n    Tool,\n}\n\nimpl std::fmt::Display for MessageRole {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            MessageRole::System =\u003e write!(f, \"system\"),\n            MessageRole::User =\u003e write!(f, \"user\"),\n            MessageRole::Assistant =\u003e write!(f, \"assistant\"),\n            MessageRole::Tool =\u003e write!(f, \"tool\"),\n        }\n    }\n}\n\n/// A message in a chat conversation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChatMessage {\n    /// Role of the message sender\n    pub role: MessageRole,\n\n    /// Content of the message\n    pub content: String,\n\n    /// Images associated with the message (for multimodal models)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub images: Option\u003cVec\u003cString\u003e\u003e,\n\n    /// Tool calls made by the assistant\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub tool_calls: Option\u003cVec\u003cToolCall\u003e\u003e,\n\n    /// Tool call ID (for tool response messages)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub tool_call_id: Option\u003cString\u003e,\n}\n\nimpl ChatMessage {\n    /// Create a new system message\n    pub fn system\u003cS: Into\u003cString\u003e\u003e(content: S) -\u003e Self {\n        Self {\n            role: MessageRole::System,\n            content: content.into(),\n            images: None,\n            tool_calls: None,\n            tool_call_id: None,\n        }\n    }\n\n    /// Create a new user message\n    pub fn user\u003cS: Into\u003cString\u003e\u003e(content: S) -\u003e Self {\n        Self {\n            role: MessageRole::User,\n            content: content.into(),\n            images: None,\n            tool_calls: None,\n            tool_call_id: None,\n        }\n    }\n\n    /// Create a new assistant message\n    pub fn assistant\u003cS: Into\u003cString\u003e\u003e(content: S) -\u003e Self {\n        Self {\n            role: MessageRole::Assistant,\n            content: content.into(),\n            images: None,\n            tool_calls: None,\n            tool_call_id: None,\n        }\n    }\n\n    /// Create a new tool message\n    pub fn tool\u003cS: Into\u003cString\u003e\u003e(content: S, tool_call_id: S) -\u003e Self {\n        Self {\n            role: MessageRole::Tool,\n            content: content.into(),\n            images: None,\n            tool_calls: None,\n            tool_call_id: Some(tool_call_id.into()),\n        }\n    }\n\n    /// Add images to the message\n    pub fn with_images(mut self, images: Vec\u003cString\u003e) -\u003e Self {\n        self.images = Some(images);\n        self\n    }\n\n    /// Add tool calls to the message\n    pub fn with_tool_calls(mut self, tool_calls: Vec\u003cToolCall\u003e) -\u003e Self {\n        self.tool_calls = Some(tool_calls);\n        self\n    }\n}\n\n/// Request for chat completion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChatRequest {\n    /// Model to use for chat\n    pub model: String,\n\n    /// List of messages in the conversation\n    pub messages: Vec\u003cChatMessage\u003e,\n\n    /// Enable or disable streaming\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub stream: Option\u003cbool\u003e,\n\n    /// Additional generation options\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub options: Option\u003cOptions\u003e,\n\n    /// Response format\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub format: Option\u003cResponseFormat\u003e,\n\n    /// How long to keep the model loaded\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub keep_alive: Option\u003cKeepAlive\u003e,\n\n    /// Available tools/functions\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub tools: Option\u003cVec\u003cTool\u003e\u003e,\n\n    /// Tool choice strategy\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub tool_choice: Option\u003cToolChoice\u003e,\n}\n\n/// Tool choice strategy\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(untagged)]\npub enum ToolChoice {\n    /// Automatically choose when to use tools\n    Auto(String), // \"auto\"\n    /// Never use tools\n    None(String), // \"none\"\n    /// Always use tools\n    Required(String), // \"required\"\n    /// Use a specific tool\n    Specific {\n        #[serde(rename = \"type\")]\n        tool_type: String,\n        function: FunctionChoice,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FunctionChoice {\n    pub name: String,\n}\n\nimpl Default for ChatRequest {\n    fn default() -\u003e Self {\n        Self {\n            model: String::new(),\n            messages: Vec::new(),\n            stream: None,\n            options: None,\n            format: None,\n            keep_alive: None,\n            tools: None,\n            tool_choice: None,\n        }\n    }\n}\n\nimpl ChatRequest {\n    /// Create a new chat request\n    pub fn new\u003cS: Into\u003cString\u003e\u003e(model: S) -\u003e Self {\n        Self {\n            model: model.into(),\n            ..Default::default()\n        }\n    }\n\n    /// Add a message to the conversation\n    pub fn add_message(mut self, message: ChatMessage) -\u003e Self {\n        self.messages.push(message);\n        self\n    }\n\n    /// Add a system message\n    pub fn add_system_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.messages.push(ChatMessage::system(content));\n        self\n    }\n\n    /// Add a user message\n    pub fn add_user_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.messages.push(ChatMessage::user(content));\n        self\n    }\n\n    /// Add an assistant message\n    pub fn add_assistant_message\u003cS: Into\u003cString\u003e\u003e(mut self, content: S) -\u003e Self {\n        self.messages.push(ChatMessage::assistant(content));\n        self\n    }\n\n    /// Set whether to stream the response\n    pub fn stream(mut self, stream: bool) -\u003e Self {\n        self.stream = Some(stream);\n        self\n    }\n\n    /// Set generation options\n    pub fn options(mut self, options: Options) -\u003e Self {\n        self.options = Some(options);\n        self\n    }\n\n    /// Set available tools\n    pub fn tools(mut self, tools: Vec\u003cTool\u003e) -\u003e Self {\n        self.tools = Some(tools);\n        self\n    }\n\n    /// Set tool choice strategy\n    pub fn tool_choice(mut self, choice: ToolChoice) -\u003e Self {\n        self.tool_choice = Some(choice);\n        self\n    }\n}\n\n/// Response from chat completion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChatResponse {\n    /// The model that was used\n    pub model: String,\n\n    /// The generated message\n    pub message: ChatMessage,\n\n    /// Whether this is the final response\n    pub done: bool,\n\n    /// Total duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub total_duration: Option\u003cu64\u003e,\n\n    /// Load duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub load_duration: Option\u003cu64\u003e,\n\n    /// Prompt evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_count: Option\u003cu32\u003e,\n\n    /// Prompt evaluation duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_duration: Option\u003cu64\u003e,\n\n    /// Evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub eval_count: Option\u003cu32\u003e,\n\n    /// Evaluation duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub eval_duration: Option\u003cu64\u003e,\n}\n\nimpl ChatResponse {\n    /// Get the assistant's response content\n    pub fn content(\u0026self) -\u003e \u0026str {\n        \u0026self.message.content\n    }\n\n    /// Check if the message has tool calls\n    pub fn has_tool_calls(\u0026self) -\u003e bool {\n        self.message.tool_calls.is_some()\n    }\n\n    /// Get tool calls if any\n    pub fn tool_calls(\u0026self) -\u003e Option\u003c\u0026Vec\u003cToolCall\u003e\u003e {\n        self.message.tool_calls.as_ref()\n    }\n\n    /// Get tokens per second for evaluation\n    pub fn eval_rate(\u0026self) -\u003e Option\u003cf64\u003e {\n        match (self.eval_count, self.eval_duration) {\n            (Some(count), Some(duration)) if duration \u003e 0 =\u003e {\n                Some(count as f64 / (duration as f64 / 1e9))\n            }\n            _ =\u003e None,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_message_creation() {\n        let system_msg = ChatMessage::system(\"You are a helpful assistant\");\n        assert_eq!(system_msg.role, MessageRole::System);\n        assert_eq!(system_msg.content, \"You are a helpful assistant\");\n\n        let user_msg = ChatMessage::user(\"Hello\");\n        assert_eq!(user_msg.role, MessageRole::User);\n        assert_eq!(user_msg.content, \"Hello\");\n\n        let assistant_msg = ChatMessage::assistant(\"Hi there!\");\n        assert_eq!(assistant_msg.role, MessageRole::Assistant);\n        assert_eq!(assistant_msg.content, \"Hi there!\");\n    }\n\n    #[test]\n    fn test_chat_request_builder() {\n        let request = ChatRequest::new(\"test-model\")\n            .add_system_message(\"You are helpful\")\n            .add_user_message(\"Hello\")\n            .stream(true);\n\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.messages.len(), 2);\n        assert_eq!(request.messages[0].role, MessageRole::System);\n        assert_eq!(request.messages[1].role, MessageRole::User);\n        assert_eq!(request.stream, Some(true));\n    }\n\n    #[test]\n    fn test_message_role_display() {\n        assert_eq!(MessageRole::System.to_string(), \"system\");\n        assert_eq!(MessageRole::User.to_string(), \"user\");\n        assert_eq!(MessageRole::Assistant.to_string(), \"assistant\");\n        assert_eq!(MessageRole::Tool.to_string(), \"tool\");\n    }\n}\n","traces":[{"line":21,"address":[2497952],"length":1,"stats":{"Line":2}},{"line":22,"address":[2572187],"length":1,"stats":{"Line":2}},{"line":23,"address":[2480122],"length":1,"stats":{"Line":2}},{"line":24,"address":[2480162],"length":1,"stats":{"Line":2}},{"line":25,"address":[2572298],"length":1,"stats":{"Line":2}},{"line":26,"address":[2498130],"length":1,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":3}},{"line":58,"address":[1961394],"length":1,"stats":{"Line":3}},{"line":66,"address":[2608480],"length":1,"stats":{"Line":3}},{"line":69,"address":[],"length":0,"stats":{"Line":3}},{"line":77,"address":[],"length":0,"stats":{"Line":2}},{"line":80,"address":[1961874],"length":1,"stats":{"Line":2}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[2480470,2480304],"length":1,"stats":{"Line":0}},{"line":100,"address":[2480331,2480423],"length":1,"stats":{"Line":0}},{"line":101,"address":[2572542],"length":1,"stats":{"Line":0}},{"line":105,"address":[6549462,6549296],"length":1,"stats":{"Line":0}},{"line":106,"address":[2480615,2480523],"length":1,"stats":{"Line":0}},{"line":107,"address":[2480642],"length":1,"stats":{"Line":0}},{"line":169,"address":[2481099,2480688,2481093],"length":1,"stats":{"Line":4}},{"line":171,"address":[2572789],"length":1,"stats":{"Line":4}},{"line":172,"address":[2480714],"length":1,"stats":{"Line":4}},{"line":185,"address":[1962080,1962472,1962466],"length":1,"stats":{"Line":3}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":193,"address":[2573319,2573200],"length":1,"stats":{"Line":0}},{"line":194,"address":[2481160],"length":1,"stats":{"Line":0}},{"line":195,"address":[2499115],"length":1,"stats":{"Line":0}},{"line":199,"address":[1962672,1962496],"length":1,"stats":{"Line":2}},{"line":200,"address":[1962620,1962558],"length":1,"stats":{"Line":6}},{"line":201,"address":[],"length":0,"stats":{"Line":2}},{"line":205,"address":[],"length":0,"stats":{"Line":3}},{"line":206,"address":[],"length":0,"stats":{"Line":6}},{"line":207,"address":[1962857],"length":1,"stats":{"Line":2}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[2481264],"length":1,"stats":{"Line":2}},{"line":218,"address":[2481287],"length":1,"stats":{"Line":2}},{"line":219,"address":[2481303],"length":1,"stats":{"Line":3}},{"line":223,"address":[2481328,2481511],"length":1,"stats":{"Line":0}},{"line":224,"address":[2573535,2573458],"length":1,"stats":{"Line":0}},{"line":225,"address":[2481488],"length":1,"stats":{"Line":0}},{"line":229,"address":[2573792,2573616],"length":1,"stats":{"Line":0}},{"line":230,"address":[2481563,2481664],"length":1,"stats":{"Line":0}},{"line":231,"address":[2573772],"length":1,"stats":{"Line":0}},{"line":235,"address":[2499632,2499828],"length":1,"stats":{"Line":0}},{"line":236,"address":[2481771,2481888],"length":1,"stats":{"Line":0}},{"line":237,"address":[2573976],"length":1,"stats":{"Line":0}},{"line":280,"address":[2574016],"length":1,"stats":{"Line":0}},{"line":281,"address":[2574021],"length":1,"stats":{"Line":0}},{"line":285,"address":[2499872],"length":1,"stats":{"Line":0}},{"line":286,"address":[2481989],"length":1,"stats":{"Line":0}},{"line":290,"address":[2574064],"length":1,"stats":{"Line":0}},{"line":291,"address":[2499909],"length":1,"stats":{"Line":0}},{"line":295,"address":[2574096],"length":1,"stats":{"Line":1}},{"line":296,"address":[2574101],"length":1,"stats":{"Line":1}},{"line":297,"address":[2574176],"length":1,"stats":{"Line":1}},{"line":298,"address":[2574238],"length":1,"stats":{"Line":1}},{"line":300,"address":[2574162],"length":1,"stats":{"Line":0}}],"covered":30,"coverable":61},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","common.rs"],"content":"//! Common types shared across different API models\n\nuse serde::{Deserialize, Serialize};\n\n/// Generation options that can be applied to various requests\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct Options {\n    /// Number of tokens to predict\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_predict: Option\u003ci32\u003e,\n\n    /// Sets the random number seed to use for generation\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub seed: Option\u003ci32\u003e,\n\n    /// The temperature of the model. Increasing the temperature will make the model answer more creatively. (0.1 to 2.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub temperature: Option\u003cf64\u003e,\n\n    /// Sets the size of the context window used to generate the next token (default: 2048)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_ctx: Option\u003ci32\u003e,\n\n    /// Works together with top_p. A higher value (e.g. 100) will give more diverse answers, whereas a lower value (e.g. 10) will be more conservative. (1 to 100)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub top_k: Option\u003ci32\u003e,\n\n    /// Works together with top_k. A higher value (e.g. 0.95) will lead to more diverse text, while a lower value (e.g. 0.5) will generate more focused and conservative text. (0.1 to 1.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub top_p: Option\u003cf64\u003e,\n\n    /// Tail free sampling is used to reduce the impact of less probable tokens from the output. (0.1 to 1.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub tfs_z: Option\u003cf64\u003e,\n\n    /// Typical P is used to reduce the impact of less probable tokens from the output. (0.1 to 1.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub typical_p: Option\u003cf64\u003e,\n\n    /// Sets how far back for the model to look back to prevent repetition. (0 = disabled)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub repeat_last_n: Option\u003ci32\u003e,\n\n    /// Sets how strongly to penalize repetitions. (0.0 to 2.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub repeat_penalty: Option\u003cf64\u003e,\n\n    /// Positive values penalize new tokens based on whether they appear in the text so far\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub presence_penalty: Option\u003cf64\u003e,\n\n    /// Positive values penalize new tokens based on their existing frequency in the text so far\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub frequency_penalty: Option\u003cf64\u003e,\n\n    /// Enable Mirostat sampling for controlling perplexity. (0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub mirostat: Option\u003ci32\u003e,\n\n    /// Controls the balance between coherence and diversity of the output. (1.0 to 10.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub mirostat_tau: Option\u003cf64\u003e,\n\n    /// Influences how quickly the algorithm responds to feedback from the generated text. (0.1 to 1.0)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub mirostat_eta: Option\u003cf64\u003e,\n\n    /// Penalize newlines in the output\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub penalize_newline: Option\u003cbool\u003e,\n\n    /// Sequences where the API will stop generating further tokens\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub stop: Option\u003cVec\u003cString\u003e\u003e,\n\n    /// Enable or disable the use of a GPU for the model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub numa: Option\u003cbool\u003e,\n\n    /// Sets the number of threads to use during computation\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_thread: Option\u003ci32\u003e,\n\n    /// Sets the number of tokens to keep from the initial prompt\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_keep: Option\u003ci32\u003e,\n\n    /// Sets the batch size for prompt processing (default 512)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_batch: Option\u003ci32\u003e,\n\n    /// The number of GPUs to use for the model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub num_gpu: Option\u003ci32\u003e,\n\n    /// The main GPU to use for the model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub main_gpu: Option\u003ci32\u003e,\n\n    /// Enable low VRAM mode\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub low_vram: Option\u003cbool\u003e,\n\n    /// Enable F16 key-value cache\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub f16_kv: Option\u003cbool\u003e,\n\n    /// Return logits for all tokens in the vocabulary\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub logits_all: Option\u003cbool\u003e,\n\n    /// Load only the vocabulary, not the weights\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub vocab_only: Option\u003cbool\u003e,\n\n    /// Use memory mapping for file access\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub use_mmap: Option\u003cbool\u003e,\n\n    /// Use memory locking to keep the model in RAM\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub use_mlock: Option\u003cbool\u003e,\n}\n\nimpl Options {\n    /// Create a new Options struct with default values\n    pub fn new() -\u003e Self {\n        Self::default()\n    }\n\n    /// Set temperature (0.1 to 2.0)\n    pub fn temperature(mut self, temperature: f64) -\u003e Self {\n        self.temperature = Some(temperature);\n        self\n    }\n\n    /// Set top_k (1 to 100)\n    pub fn top_k(mut self, top_k: i32) -\u003e Self {\n        self.top_k = Some(top_k);\n        self\n    }\n\n    /// Set top_p (0.1 to 1.0)\n    pub fn top_p(mut self, top_p: f64) -\u003e Self {\n        self.top_p = Some(top_p);\n        self\n    }\n\n    /// Set the number of tokens to predict\n    pub fn num_predict(mut self, num_predict: i32) -\u003e Self {\n        self.num_predict = Some(num_predict);\n        self\n    }\n\n    /// Set the context window size\n    pub fn num_ctx(mut self, num_ctx: i32) -\u003e Self {\n        self.num_ctx = Some(num_ctx);\n        self\n    }\n\n    /// Set the random seed\n    pub fn seed(mut self, seed: i32) -\u003e Self {\n        self.seed = Some(seed);\n        self\n    }\n\n    /// Set stop sequences\n    pub fn stop(mut self, stop: Vec\u003cString\u003e) -\u003e Self {\n        self.stop = Some(stop);\n        self\n    }\n}\n\n/// Tool function definition for function calling\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolFunction {\n    /// Function name\n    pub name: String,\n\n    /// Function description\n    pub description: String,\n\n    /// Function parameters schema\n    pub parameters: serde_json::Value,\n}\n\n/// Tool definition for function calling\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Tool {\n    /// Tool type (currently only \"function\" is supported)\n    #[serde(rename = \"type\")]\n    pub tool_type: String,\n\n    /// Function definition\n    pub function: ToolFunction,\n}\n\nimpl Tool {\n    /// Create a new function tool\n    pub fn function(name: String, description: String, parameters: serde_json::Value) -\u003e Self {\n        Self {\n            tool_type: \"function\".to_string(),\n            function: ToolFunction {\n                name,\n                description,\n                parameters,\n            },\n        }\n    }\n}\n\n/// Tool call made by the model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolCall {\n    /// Tool call ID\n    pub id: String,\n\n    /// Tool type\n    #[serde(rename = \"type\")]\n    pub tool_type: String,\n\n    /// Function call details\n    pub function: FunctionCall,\n}\n\n/// Function call details\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FunctionCall {\n    /// Function name\n    pub name: String,\n\n    /// Function arguments as JSON string\n    pub arguments: String,\n}\n\n/// Usage statistics for API calls\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Usage {\n    /// Number of tokens in the prompt\n    pub prompt_tokens: u32,\n\n    /// Number of tokens in the completion\n    pub completion_tokens: u32,\n\n    /// Total number of tokens\n    pub total_tokens: u32,\n}\n\n/// Format types for responses\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(rename_all = \"lowercase\")]\npub enum ResponseFormat {\n    /// Default text format\n    Text,\n    /// JSON format\n    Json,\n}\n\nimpl Default for ResponseFormat {\n    fn default() -\u003e Self {\n        Self::Text\n    }\n}\n\n/// Keep alive configuration\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(untagged)]\npub enum KeepAlive {\n    /// Keep alive duration as string (e.g., \"5m\", \"1h\")\n    Duration(String),\n    /// Keep alive as seconds\n    Seconds(u64),\n    /// Disable keep alive\n    Never,\n}\n\nimpl Default for KeepAlive {\n    fn default() -\u003e Self {\n        Self::Duration(\"5m\".to_string())\n    }\n}\n\nimpl From\u003c\u0026str\u003e for KeepAlive {\n    fn from(s: \u0026str) -\u003e Self {\n        Self::Duration(s.to_string())\n    }\n}\n\nimpl From\u003cu64\u003e for KeepAlive {\n    fn from(seconds: u64) -\u003e Self {\n        Self::Seconds(seconds)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_options_builder() {\n        let options = Options::new()\n            .temperature(0.7)\n            .top_k(40)\n            .top_p(0.9)\n            .num_predict(100);\n\n        assert_eq!(options.temperature, Some(0.7));\n        assert_eq!(options.top_k, Some(40));\n        assert_eq!(options.top_p, Some(0.9));\n        assert_eq!(options.num_predict, Some(100));\n    }\n\n    #[test]\n    fn test_tool_creation() {\n        let tool = Tool::function(\n            \"get_weather\".to_string(),\n            \"Get weather for a location\".to_string(),\n            serde_json::json!({\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\"}\n                }\n            }),\n        );\n\n        assert_eq!(tool.tool_type, \"function\");\n        assert_eq!(tool.function.name, \"get_weather\");\n    }\n\n    #[test]\n    fn test_keep_alive_variants() {\n        let duration = KeepAlive::from(\"10m\");\n        let seconds = KeepAlive::from(300u64);\n\n        match duration {\n            KeepAlive::Duration(d) =\u003e assert_eq!(d, \"10m\"),\n            _ =\u003e panic!(\"Expected Duration variant\"),\n        }\n\n        match seconds {\n            KeepAlive::Seconds(s) =\u003e assert_eq!(s, 300),\n            _ =\u003e panic!(\"Expected Seconds variant\"),\n        }\n    }\n}\n","traces":[{"line":127,"address":[6898000],"length":1,"stats":{"Line":2}},{"line":128,"address":[2143576],"length":1,"stats":{"Line":2}},{"line":132,"address":[2143600],"length":1,"stats":{"Line":2}},{"line":133,"address":[2143618],"length":1,"stats":{"Line":2}},{"line":134,"address":[2847172],"length":1,"stats":{"Line":2}},{"line":138,"address":[2836496],"length":1,"stats":{"Line":2}},{"line":139,"address":[2836511],"length":1,"stats":{"Line":2}},{"line":140,"address":[6898159],"length":1,"stats":{"Line":2}},{"line":144,"address":[2847280],"length":1,"stats":{"Line":2}},{"line":145,"address":[6898210],"length":1,"stats":{"Line":2}},{"line":146,"address":[2847333],"length":1,"stats":{"Line":2}},{"line":150,"address":[2143840],"length":1,"stats":{"Line":2}},{"line":151,"address":[2143855],"length":1,"stats":{"Line":2}},{"line":152,"address":[2836703],"length":1,"stats":{"Line":2}},{"line":156,"address":[2143920],"length":1,"stats":{"Line":0}},{"line":157,"address":[6898367],"length":1,"stats":{"Line":0}},{"line":158,"address":[2143967],"length":1,"stats":{"Line":0}},{"line":162,"address":[2836816],"length":1,"stats":{"Line":0}},{"line":163,"address":[2836831],"length":1,"stats":{"Line":0}},{"line":164,"address":[2847567],"length":1,"stats":{"Line":0}},{"line":168,"address":[2837080,2836896],"length":1,"stats":{"Line":0}},{"line":169,"address":[2847627,2847728],"length":1,"stats":{"Line":0}},{"line":170,"address":[2847764],"length":1,"stats":{"Line":0}},{"line":200,"address":[6899193,6899155,6898720],"length":1,"stats":{"Line":2}},{"line":202,"address":[2144320],"length":1,"stats":{"Line":2}},{"line":203,"address":[6898958],"length":1,"stats":{"Line":2}},{"line":261,"address":[2848304],"length":1,"stats":{"Line":0}},{"line":278,"address":[2144800],"length":1,"stats":{"Line":0}},{"line":279,"address":[2848333],"length":1,"stats":{"Line":0}},{"line":284,"address":[2837696],"length":1,"stats":{"Line":2}},{"line":285,"address":[2837719],"length":1,"stats":{"Line":2}},{"line":290,"address":[2144960],"length":1,"stats":{"Line":2}},{"line":291,"address":[2144968],"length":1,"stats":{"Line":2}}],"covered":21,"coverable":33},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","embedding.rs"],"content":"//! Embedding API request and response models\n\nuse crate::models::common::{KeepAlive, Options};\nuse serde::{Deserialize, Serialize};\n\n/// Input for embedding requests - can be a single string or array of strings\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(untagged)]\npub enum EmbedInput {\n    /// Single text input\n    Single(String),\n    /// Multiple text inputs\n    Multiple(Vec\u003cString\u003e),\n}\n\nimpl From\u003cString\u003e for EmbedInput {\n    fn from(s: String) -\u003e Self {\n        Self::Single(s)\n    }\n}\n\nimpl From\u003c\u0026str\u003e for EmbedInput {\n    fn from(s: \u0026str) -\u003e Self {\n        Self::Single(s.to_string())\n    }\n}\n\nimpl From\u003cVec\u003cString\u003e\u003e for EmbedInput {\n    fn from(v: Vec\u003cString\u003e) -\u003e Self {\n        Self::Multiple(v)\n    }\n}\n\nimpl From\u003cVec\u003c\u0026str\u003e\u003e for EmbedInput {\n    fn from(v: Vec\u003c\u0026str\u003e) -\u003e Self {\n        Self::Multiple(v.into_iter().map(|s| s.to_string()).collect())\n    }\n}\n\nimpl Default for EmbedInput {\n    fn default() -\u003e Self {\n        Self::Single(String::new())\n    }\n}\n\n/// Request for generating embeddings\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EmbedRequest {\n    /// Model to use for embeddings\n    pub model: String,\n\n    /// Input text(s) to embed\n    pub input: EmbedInput,\n\n    /// Additional options\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub options: Option\u003cOptions\u003e,\n\n    /// How long to keep the model loaded\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub keep_alive: Option\u003cKeepAlive\u003e,\n\n    /// Whether to truncate inputs that are too long\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub truncate: Option\u003cbool\u003e,\n}\n\nimpl Default for EmbedRequest {\n    fn default() -\u003e Self {\n        Self {\n            model: String::new(),\n            input: EmbedInput::default(),\n            options: None,\n            keep_alive: None,\n            truncate: None,\n        }\n    }\n}\n\nimpl EmbedRequest {\n    /// Create a new embedding request\n    pub fn new\u003cS: Into\u003cString\u003e, I: Into\u003cEmbedInput\u003e\u003e(model: S, input: I) -\u003e Self {\n        Self {\n            model: model.into(),\n            input: input.into(),\n            ..Default::default()\n        }\n    }\n\n    /// Set additional options\n    pub fn options(mut self, options: Options) -\u003e Self {\n        self.options = Some(options);\n        self\n    }\n\n    /// Set keep alive duration\n    pub fn keep_alive(mut self, keep_alive: KeepAlive) -\u003e Self {\n        self.keep_alive = Some(keep_alive);\n        self\n    }\n\n    /// Set whether to truncate inputs\n    pub fn truncate(mut self, truncate: bool) -\u003e Self {\n        self.truncate = Some(truncate);\n        self\n    }\n\n    /// Get the number of inputs\n    pub fn input_count(\u0026self) -\u003e usize {\n        match \u0026self.input {\n            EmbedInput::Single(_) =\u003e 1,\n            EmbedInput::Multiple(v) =\u003e v.len(),\n        }\n    }\n\n    /// Get the inputs as a vector of strings\n    pub fn inputs_as_vec(\u0026self) -\u003e Vec\u003cString\u003e {\n        match \u0026self.input {\n            EmbedInput::Single(s) =\u003e vec![s.clone()],\n            EmbedInput::Multiple(v) =\u003e v.clone(),\n        }\n    }\n}\n\n/// Response from embedding generation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EmbedResponse {\n    /// The model that was used\n    pub model: String,\n\n    /// Generated embeddings (array of arrays of floats)\n    pub embeddings: Vec\u003cVec\u003cf64\u003e\u003e,\n\n    /// Total duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub total_duration: Option\u003cu64\u003e,\n\n    /// Load duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub load_duration: Option\u003cu64\u003e,\n\n    /// Prompt evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_count: Option\u003cu32\u003e,\n}\n\nimpl EmbedResponse {\n    /// Get the number of embeddings\n    pub fn count(\u0026self) -\u003e usize {\n        self.embeddings.len()\n    }\n\n    /// Get the dimensionality of the embeddings (assumes all have same dimensions)\n    pub fn dimensions(\u0026self) -\u003e Option\u003cusize\u003e {\n        self.embeddings.first().map(|emb| emb.len())\n    }\n\n    /// Get a specific embedding by index\n    pub fn get_embedding(\u0026self, index: usize) -\u003e Option\u003c\u0026Vec\u003cf64\u003e\u003e {\n        self.embeddings.get(index)\n    }\n\n    /// Calculate cosine similarity between two embeddings\n    pub fn cosine_similarity(a: \u0026[f64], b: \u0026[f64]) -\u003e Option\u003cf64\u003e {\n        if a.len() != b.len() {\n            return None;\n        }\n\n        let dot_product: f64 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();\n        let norm_a: f64 = a.iter().map(|x| x * x).sum::\u003cf64\u003e().sqrt();\n        let norm_b: f64 = b.iter().map(|x| x * x).sum::\u003cf64\u003e().sqrt();\n\n        if norm_a == 0.0 || norm_b == 0.0 {\n            return Some(0.0);\n        }\n\n        Some(dot_product / (norm_a * norm_b))\n    }\n\n    /// Calculate Euclidean distance between two embeddings\n    pub fn euclidean_distance(a: \u0026[f64], b: \u0026[f64]) -\u003e Option\u003cf64\u003e {\n        if a.len() != b.len() {\n            return None;\n        }\n\n        let distance: f64 = a\n            .iter()\n            .zip(b.iter())\n            .map(|(x, y)| (x - y).powi(2))\n            .sum::\u003cf64\u003e()\n            .sqrt();\n\n        Some(distance)\n    }\n}\n\n/// Legacy embedding request format (deprecated but still supported)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LegacyEmbeddingRequest {\n    /// Model to use\n    pub model: String,\n\n    /// Text prompt to embed\n    pub prompt: String,\n\n    /// Additional options\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub options: Option\u003cOptions\u003e,\n\n    /// How long to keep the model loaded\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub keep_alive: Option\u003cKeepAlive\u003e,\n}\n\n/// Legacy embedding response format\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LegacyEmbeddingResponse {\n    /// Generated embedding\n    pub embedding: Vec\u003cf64\u003e,\n\n    /// The model used\n    pub model: String,\n\n    /// Total duration\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub total_duration: Option\u003cu64\u003e,\n\n    /// Load duration\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub load_duration: Option\u003cu64\u003e,\n\n    /// Prompt evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_count: Option\u003cu32\u003e,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_embed_input_from_string() {\n        let input: EmbedInput = \"test\".into();\n        match input {\n            EmbedInput::Single(s) =\u003e assert_eq!(s, \"test\"),\n            _ =\u003e panic!(\"Expected Single variant\"),\n        }\n    }\n\n    #[test]\n    fn test_embed_input_from_vec() {\n        let input: EmbedInput = vec![\"test1\", \"test2\"].into();\n        match input {\n            EmbedInput::Multiple(v) =\u003e assert_eq!(v, vec![\"test1\", \"test2\"]),\n            _ =\u003e panic!(\"Expected Multiple variant\"),\n        }\n    }\n\n    #[test]\n    fn test_embed_request_creation() {\n        let request = EmbedRequest::new(\"test-model\", \"test text\");\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.input_count(), 1);\n        assert_eq!(request.inputs_as_vec(), vec![\"test text\"]);\n    }\n\n    #[test]\n    fn test_cosine_similarity() {\n        let a = vec![1.0, 0.0, 0.0];\n        let b = vec![0.0, 1.0, 0.0];\n        let c = vec![1.0, 0.0, 0.0];\n\n        assert_eq!(EmbedResponse::cosine_similarity(\u0026a, \u0026b), Some(0.0));\n        assert_eq!(EmbedResponse::cosine_similarity(\u0026a, \u0026c), Some(1.0));\n    }\n\n    #[test]\n    fn test_euclidean_distance() {\n        let a = vec![0.0, 0.0];\n        let b = vec![3.0, 4.0];\n\n        assert_eq!(EmbedResponse::euclidean_distance(\u0026a, \u0026b), Some(5.0));\n    }\n}\n","traces":[{"line":17,"address":[6568080],"length":1,"stats":{"Line":0}},{"line":18,"address":[2499283],"length":1,"stats":{"Line":0}},{"line":23,"address":[2499328],"length":1,"stats":{"Line":2}},{"line":24,"address":[2263367],"length":1,"stats":{"Line":2}},{"line":29,"address":[2517312],"length":1,"stats":{"Line":1}},{"line":30,"address":[2499427],"length":1,"stats":{"Line":1}},{"line":35,"address":[6568272],"length":1,"stats":{"Line":3}},{"line":36,"address":[2524629,2524576],"length":1,"stats":{"Line":9}},{"line":41,"address":[2499584],"length":1,"stats":{"Line":4}},{"line":42,"address":[2263613],"length":1,"stats":{"Line":6}},{"line":69,"address":[2499664,2499960,2499954],"length":1,"stats":{"Line":4}},{"line":71,"address":[2517574],"length":1,"stats":{"Line":5}},{"line":72,"address":[2517579],"length":1,"stats":{"Line":4}},{"line":82,"address":[],"length":0,"stats":{"Line":5}},{"line":84,"address":[],"length":0,"stats":{"Line":4}},{"line":85,"address":[],"length":0,"stats":{"Line":5}},{"line":91,"address":[2500179,2499984],"length":1,"stats":{"Line":0}},{"line":92,"address":[6568927,6568834],"length":1,"stats":{"Line":0}},{"line":93,"address":[2264164],"length":1,"stats":{"Line":0}},{"line":97,"address":[6569192,6569008],"length":1,"stats":{"Line":0}},{"line":98,"address":[2518224,2518123],"length":1,"stats":{"Line":0}},{"line":99,"address":[2500372],"length":1,"stats":{"Line":0}},{"line":103,"address":[2500416],"length":1,"stats":{"Line":0}},{"line":104,"address":[2518327],"length":1,"stats":{"Line":0}},{"line":105,"address":[2518343],"length":1,"stats":{"Line":0}},{"line":109,"address":[6569280],"length":1,"stats":{"Line":2}},{"line":110,"address":[2500494],"length":1,"stats":{"Line":2}},{"line":111,"address":[2518418],"length":1,"stats":{"Line":3}},{"line":112,"address":[2518396],"length":1,"stats":{"Line":2}},{"line":117,"address":[2518448,2518755,2518761],"length":1,"stats":{"Line":2}},{"line":118,"address":[2264568],"length":1,"stats":{"Line":2}},{"line":119,"address":[2518523],"length":1,"stats":{"Line":2}},{"line":120,"address":[2500603],"length":1,"stats":{"Line":2}},{"line":149,"address":[2264880],"length":1,"stats":{"Line":2}},{"line":150,"address":[2500901],"length":1,"stats":{"Line":2}},{"line":154,"address":[2500928],"length":1,"stats":{"Line":2}},{"line":155,"address":[2524665,2524656],"length":1,"stats":{"Line":6}},{"line":159,"address":[2518864],"length":1,"stats":{"Line":0}},{"line":160,"address":[2264962],"length":1,"stats":{"Line":0}},{"line":164,"address":[2264992],"length":1,"stats":{"Line":2}},{"line":165,"address":[6569899],"length":1,"stats":{"Line":2}},{"line":166,"address":[2519255],"length":1,"stats":{"Line":0}},{"line":169,"address":[2524688,2524731],"length":1,"stats":{"Line":6}},{"line":170,"address":[2519123],"length":1,"stats":{"Line":6}},{"line":171,"address":[2519183],"length":1,"stats":{"Line":6}},{"line":173,"address":[2265295,2265325],"length":1,"stats":{"Line":4}},{"line":174,"address":[2519283],"length":1,"stats":{"Line":0}},{"line":177,"address":[2519321],"length":1,"stats":{"Line":2}},{"line":181,"address":[2501488],"length":1,"stats":{"Line":2}},{"line":182,"address":[2265483],"length":1,"stats":{"Line":2}},{"line":183,"address":[2519565],"length":1,"stats":{"Line":0}},{"line":186,"address":[2501562,2501608],"length":1,"stats":{"Line":4}},{"line":188,"address":[2519475],"length":1,"stats":{"Line":2}},{"line":189,"address":[2200768,2200811],"length":1,"stats":{"Line":4}},{"line":193,"address":[2265591],"length":1,"stats":{"Line":2}}],"covered":39,"coverable":55},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","generation.rs"],"content":"//! Generation API request and response models\n\nuse crate::models::common::{KeepAlive, Options, ResponseFormat};\nuse serde::{Deserialize, Serialize};\n\n/// Request for text generation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GenerateRequest {\n    /// Model to use for generation\n    pub model: String,\n\n    /// Text prompt for generation\n    pub prompt: String,\n\n    /// Enable or disable streaming\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub stream: Option\u003cbool\u003e,\n\n    /// System message to provide context\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub system: Option\u003cString\u003e,\n\n    /// Template string for formatting the prompt\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub template: Option\u003cString\u003e,\n\n    /// Context from previous requests for conversation continuity\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub context: Option\u003cVec\u003ci32\u003e\u003e,\n\n    /// Additional generation options\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub options: Option\u003cOptions\u003e,\n\n    /// Response format (json, text)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub format: Option\u003cResponseFormat\u003e,\n\n    /// Use raw prompt without formatting\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub raw: Option\u003cbool\u003e,\n\n    /// How long to keep the model loaded\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub keep_alive: Option\u003cKeepAlive\u003e,\n\n    /// Images to include with the prompt (for multimodal models)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub images: Option\u003cVec\u003cString\u003e\u003e,\n}\n\nimpl Default for GenerateRequest {\n    fn default() -\u003e Self {\n        Self {\n            model: String::new(),\n            prompt: String::new(),\n            stream: None,\n            system: None,\n            template: None,\n            context: None,\n            options: None,\n            format: None,\n            raw: None,\n            keep_alive: None,\n            images: None,\n        }\n    }\n}\n\nimpl GenerateRequest {\n    /// Create a new generate request\n    pub fn new\u003cS: Into\u003cString\u003e\u003e(model: S, prompt: S) -\u003e Self {\n        Self {\n            model: model.into(),\n            prompt: prompt.into(),\n            ..Default::default()\n        }\n    }\n\n    /// Set whether to stream the response\n    pub fn stream(mut self, stream: bool) -\u003e Self {\n        self.stream = Some(stream);\n        self\n    }\n\n    /// Set the system message\n    pub fn system\u003cS: Into\u003cString\u003e\u003e(mut self, system: S) -\u003e Self {\n        self.system = Some(system.into());\n        self\n    }\n\n    /// Set the generation options\n    pub fn options(mut self, options: Options) -\u003e Self {\n        self.options = Some(options);\n        self\n    }\n\n    /// Set the response format\n    pub fn format(mut self, format: ResponseFormat) -\u003e Self {\n        self.format = Some(format);\n        self\n    }\n\n    /// Set keep alive duration\n    pub fn keep_alive(mut self, keep_alive: KeepAlive) -\u003e Self {\n        self.keep_alive = Some(keep_alive);\n        self\n    }\n}\n\n/// Response from text generation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct GenerateResponse {\n    /// The model that was used\n    pub model: String,\n\n    /// The generated response text\n    pub response: String,\n\n    /// Whether this is the final response\n    pub done: bool,\n\n    /// Context for conversation continuity\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub context: Option\u003cVec\u003ci32\u003e\u003e,\n\n    /// Total duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub total_duration: Option\u003cu64\u003e,\n\n    /// Load duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub load_duration: Option\u003cu64\u003e,\n\n    /// Prompt evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_count: Option\u003cu32\u003e,\n\n    /// Prompt evaluation duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub prompt_eval_duration: Option\u003cu64\u003e,\n\n    /// Evaluation count\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub eval_count: Option\u003cu32\u003e,\n\n    /// Evaluation duration in nanoseconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub eval_duration: Option\u003cu64\u003e,\n}\n\nimpl GenerateResponse {\n    /// Get tokens per second for prompt evaluation\n    pub fn prompt_eval_rate(\u0026self) -\u003e Option\u003cf64\u003e {\n        match (self.prompt_eval_count, self.prompt_eval_duration) {\n            (Some(count), Some(duration)) if duration \u003e 0 =\u003e {\n                Some(count as f64 / (duration as f64 / 1e9))\n            }\n            _ =\u003e None,\n        }\n    }\n\n    /// Get tokens per second for generation\n    pub fn eval_rate(\u0026self) -\u003e Option\u003cf64\u003e {\n        match (self.eval_count, self.eval_duration) {\n            (Some(count), Some(duration)) if duration \u003e 0 =\u003e {\n                Some(count as f64 / (duration as f64 / 1e9))\n            }\n            _ =\u003e None,\n        }\n    }\n\n    /// Get total tokens per second\n    pub fn total_rate(\u0026self) -\u003e Option\u003cf64\u003e {\n        match (self.prompt_eval_count, self.eval_count, self.total_duration) {\n            (Some(prompt_count), Some(eval_count), Some(duration)) if duration \u003e 0 =\u003e {\n                Some((prompt_count + eval_count) as f64 / (duration as f64 / 1e9))\n            }\n            _ =\u003e None,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_generate_request_creation() {\n        let request = GenerateRequest::new(\"test-model\", \"test prompt\");\n        assert_eq!(request.model, \"test-model\");\n        assert_eq!(request.prompt, \"test prompt\");\n        assert!(request.stream.is_none());\n    }\n\n    #[test]\n    fn test_generate_request_builder() {\n        let request = GenerateRequest::new(\"test-model\", \"test prompt\")\n            .stream(true)\n            .system(\"You are a helpful assistant\")\n            .format(ResponseFormat::Json);\n\n        assert_eq!(request.stream, Some(true));\n        assert_eq!(\n            request.system,\n            Some(\"You are a helpful assistant\".to_string())\n        );\n        matches!(request.format, Some(ResponseFormat::Json));\n    }\n\n    #[test]\n    fn test_generate_response_rates() {\n        let response = GenerateResponse {\n            model: \"test\".to_string(),\n            response: \"test\".to_string(),\n            done: true,\n            context: None,\n            total_duration: Some(2_000_000_000), // 2 seconds\n            load_duration: None,\n            prompt_eval_count: Some(10),\n            prompt_eval_duration: Some(1_000_000_000), // 1 second\n            eval_count: Some(20),\n            eval_duration: Some(1_000_000_000), // 1 second\n        };\n\n        assert_eq!(response.prompt_eval_rate(), Some(10.0));\n        assert_eq!(response.eval_rate(), Some(20.0));\n        assert_eq!(response.total_rate(), Some(15.0)); // (10 + 20) / 2\n    }\n}\n","traces":[{"line":53,"address":[2246639,2246080,2246633],"length":1,"stats":{"Line":6}},{"line":55,"address":[2261798],"length":1,"stats":{"Line":7}},{"line":56,"address":[2246112],"length":1,"stats":{"Line":6}},{"line":72,"address":[2154544,2155173,2155179],"length":1,"stats":{"Line":4}},{"line":74,"address":[2154603],"length":1,"stats":{"Line":3}},{"line":75,"address":[2154693],"length":1,"stats":{"Line":4}},{"line":81,"address":[1954096],"length":1,"stats":{"Line":2}},{"line":82,"address":[6313287],"length":1,"stats":{"Line":3}},{"line":83,"address":[1954135],"length":1,"stats":{"Line":2}},{"line":87,"address":[2155489,2155200],"length":1,"stats":{"Line":2}},{"line":88,"address":[],"length":0,"stats":{"Line":5}},{"line":89,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[6313328,6313511],"length":1,"stats":{"Line":0}},{"line":94,"address":[2246770,2246855],"length":1,"stats":{"Line":0}},{"line":95,"address":[1954312],"length":1,"stats":{"Line":0}},{"line":99,"address":[2246928],"length":1,"stats":{"Line":2}},{"line":100,"address":[1954391],"length":1,"stats":{"Line":2}},{"line":101,"address":[1954407],"length":1,"stats":{"Line":2}},{"line":105,"address":[6313600,6313784],"length":1,"stats":{"Line":0}},{"line":106,"address":[2247019,2247120],"length":1,"stats":{"Line":0}},{"line":107,"address":[2262852],"length":1,"stats":{"Line":0}},{"line":154,"address":[2262896],"length":1,"stats":{"Line":2}},{"line":155,"address":[1954629],"length":1,"stats":{"Line":2}},{"line":156,"address":[2247280],"length":1,"stats":{"Line":2}},{"line":157,"address":[1954766],"length":1,"stats":{"Line":2}},{"line":159,"address":[2262962],"length":1,"stats":{"Line":0}},{"line":164,"address":[6314048],"length":1,"stats":{"Line":4}},{"line":165,"address":[2263141],"length":1,"stats":{"Line":4}},{"line":166,"address":[6314128],"length":1,"stats":{"Line":4}},{"line":167,"address":[2263278],"length":1,"stats":{"Line":4}},{"line":169,"address":[2263202],"length":1,"stats":{"Line":0}},{"line":174,"address":[2263376],"length":1,"stats":{"Line":2}},{"line":175,"address":[2247692,2247789],"length":1,"stats":{"Line":4}},{"line":176,"address":[2247800],"length":1,"stats":{"Line":2}},{"line":177,"address":[1955313,1955412],"length":1,"stats":{"Line":2}},{"line":179,"address":[1955199],"length":1,"stats":{"Line":0}}],"covered":27,"coverable":36},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","mod.rs"],"content":"//! Data models for the Ollama API\n\npub mod chat;\npub mod common;\npub mod embedding;\npub mod generation;\npub mod model_info;\npub mod options;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","model_info.rs"],"content":"//! Model information and management structures\n\nuse chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\n\n/// Information about a single model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Model {\n    /// Model name\n    pub name: String,\n\n    /// Model size in bytes\n    pub size: u64,\n\n    /// Digest/hash of the model\n    pub digest: String,\n\n    /// When the model was last modified\n    #[serde(default)]\n    pub modified_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n\n    /// Model details\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option\u003cModelDetails\u003e,\n}\n\n/// List of models response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ModelList {\n    /// Available models\n    pub models: Vec\u003cModel\u003e,\n}\n\n/// Detailed model information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ModelInfo {\n    /// License information\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub license: Option\u003cString\u003e,\n\n    /// Modelfile content\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub modelfile: Option\u003cString\u003e,\n\n    /// Model parameters\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub parameters: Option\u003cString\u003e,\n\n    /// Template used by the model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub template: Option\u003cString\u003e,\n\n    /// System message/prompt\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub system: Option\u003cString\u003e,\n\n    /// Model details\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option\u003cModelDetails\u003e,\n\n    /// Model messages (conversation examples)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub messages: Option\u003cVec\u003ccrate::models::chat::ChatMessage\u003e\u003e,\n}\n\n/// Detailed technical information about a model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ModelDetails {\n    /// Model family (e.g., \"qwen\", \"llama\")\n    pub family: String,\n\n    /// Model format (e.g., \"gguf\")\n    pub format: String,\n\n    /// Parameter size (e.g., \"30B\")\n    pub parameter_size: String,\n\n    /// Quantization level (e.g., \"Q4_K_M\")\n    pub quantization_level: String,\n\n    /// Families this model belongs to\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub families: Option\u003cVec\u003cString\u003e\u003e,\n\n    /// Parent model if this is a variant\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub parent_model: Option\u003cString\u003e,\n}\n\n/// Information about a running model\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RunningModel {\n    /// Model name\n    pub name: String,\n\n    /// Model size in bytes\n    pub size: u64,\n\n    /// Digest/hash of the model\n    pub digest: String,\n\n    /// Model details\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub details: Option\u003cModelDetails\u003e,\n\n    /// When the model expires from memory\n    #[serde(default)]\n    pub expires_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n\n    /// Size in memory\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub size_vram: Option\u003cu64\u003e,\n}\n\n/// List of running models\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RunningModels {\n    /// Currently running models\n    pub models: Vec\u003cRunningModel\u003e,\n}\n\n/// Model pull progress information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PullProgress {\n    /// Status of the pull operation\n    pub status: String,\n\n    /// Current digest being processed\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub digest: Option\u003cString\u003e,\n\n    /// Total bytes to download\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub total: Option\u003cu64\u003e,\n\n    /// Bytes completed\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub completed: Option\u003cu64\u003e,\n}\n\nimpl PullProgress {\n    /// Calculate progress percentage (0.0 to 100.0)\n    pub fn percentage(\u0026self) -\u003e Option\u003cf64\u003e {\n        match (self.completed, self.total) {\n            (Some(completed), Some(total)) if total \u003e 0 =\u003e {\n                Some((completed as f64 / total as f64) * 100.0)\n            }\n            _ =\u003e None,\n        }\n    }\n\n    /// Check if the pull is complete\n    pub fn is_complete(\u0026self) -\u003e bool {\n        self.status.to_lowercase().contains(\"success\")\n            || self.status.to_lowercase().contains(\"complete\")\n            || (self.completed.is_some() \u0026\u0026 self.total.is_some() \u0026\u0026 self.completed == self.total)\n    }\n}\n\n/// Model creation progress\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CreateProgress {\n    /// Status of the creation\n    pub status: String,\n\n    /// Progress details\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub detail: Option\u003cString\u003e,\n}\n\n/// Model copy request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CopyRequest {\n    /// Source model name\n    pub source: String,\n\n    /// Destination model name\n    pub destination: String,\n}\n\n/// Model delete request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DeleteRequest {\n    /// Model name to delete\n    pub name: String,\n}\n\n/// Model show request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ShowRequest {\n    /// Model name to show\n    pub name: String,\n\n    /// Include verbose information\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub verbose: Option\u003cbool\u003e,\n}\n\n/// Model pull request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PullRequest {\n    /// Model name to pull\n    pub name: String,\n\n    /// Whether to stream progress updates\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub stream: Option\u003cbool\u003e,\n\n    /// Insecure mode (skip TLS verification)\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub insecure: Option\u003cbool\u003e,\n}\n\n/// Model create request\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CreateRequest {\n    /// Name for the new model\n    pub name: String,\n\n    /// Modelfile content\n    pub modelfile: String,\n\n    /// Whether to stream progress updates\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub stream: Option\u003cbool\u003e,\n\n    /// Quantization method\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub quantize: Option\u003cString\u003e,\n}\n\nimpl Model {\n    /// Get a human-readable size string\n    pub fn size_string(\u0026self) -\u003e String {\n        format_bytes(self.size)\n    }\n\n    /// Check if this model is a fine-tune or custom model\n    pub fn is_custom(\u0026self) -\u003e bool {\n        self.name.contains(':') \u0026\u0026 !self.name.contains(\"latest\")\n    }\n\n    /// Get the base model name (without tags)\n    pub fn base_name(\u0026self) -\u003e \u0026str {\n        self.name.split(':').next().unwrap_or(\u0026self.name)\n    }\n\n    /// Get the model tag (part after ':')\n    pub fn tag(\u0026self) -\u003e Option\u003c\u0026str\u003e {\n        self.name.split(':').nth(1)\n    }\n}\n\nimpl RunningModel {\n    /// Get a human-readable size string\n    pub fn size_string(\u0026self) -\u003e String {\n        format_bytes(self.size)\n    }\n\n    /// Get VRAM usage as a string\n    pub fn vram_string(\u0026self) -\u003e String {\n        self.size_vram\n            .map(format_bytes)\n            .unwrap_or_else(|| \"Unknown\".to_string())\n    }\n\n    /// Check if the model is about to expire soon (within 1 minute)\n    pub fn expires_soon(\u0026self) -\u003e bool {\n        match self.expires_at {\n            Some(expires_at) =\u003e {\n                let now = Utc::now();\n                let time_until_expiry = expires_at.signed_duration_since(now);\n                time_until_expiry.num_minutes() \u003c= 1\n            }\n            None =\u003e false,\n        }\n    }\n}\n\n/// Helper function to format bytes in human-readable format\nfn format_bytes(bytes: u64) -\u003e String {\n    const UNITS: \u0026[\u0026str] = \u0026[\"B\", \"KB\", \"MB\", \"GB\", \"TB\"];\n    const THRESHOLD: u64 = 1024;\n\n    if bytes == 0 {\n        return \"0 B\".to_string();\n    }\n\n    let mut size = bytes as f64;\n    let mut unit_index = 0;\n\n    while size \u003e= THRESHOLD as f64 \u0026\u0026 unit_index \u003c UNITS.len() - 1 {\n        size /= THRESHOLD as f64;\n        unit_index += 1;\n    }\n\n    if unit_index == 0 {\n        format!(\"{} {}\", size as u64, UNITS[unit_index])\n    } else {\n        format!(\"{:.1} {}\", size, UNITS[unit_index])\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_format_bytes() {\n        assert_eq!(format_bytes(0), \"0 B\");\n        assert_eq!(format_bytes(512), \"512 B\");\n        assert_eq!(format_bytes(1024), \"1.0 KB\");\n        assert_eq!(format_bytes(1536), \"1.5 KB\");\n        assert_eq!(format_bytes(1048576), \"1.0 MB\");\n        assert_eq!(format_bytes(1073741824), \"1.0 GB\");\n    }\n\n    #[test]\n    fn test_model_methods() {\n        let model = Model {\n            name: \"qwen3:30b-a3b\".to_string(),\n            size: 1073741824, // 1GB\n            digest: \"sha256:abc123\".to_string(),\n            modified_at: None,\n            details: None,\n        };\n\n        assert_eq!(model.base_name(), \"qwen3\");\n        assert_eq!(model.tag(), Some(\"30b-a3b\"));\n        assert!(model.is_custom());\n        assert_eq!(model.size_string(), \"1.0 GB\");\n    }\n\n    #[test]\n    fn test_pull_progress() {\n        let progress = PullProgress {\n            status: \"downloading\".to_string(),\n            digest: Some(\"sha256:abc\".to_string()),\n            total: Some(1000),\n            completed: Some(500),\n        };\n\n        assert_eq!(progress.percentage(), Some(50.0));\n        assert!(!progress.is_complete());\n\n        let complete_progress = PullProgress {\n            status: \"success\".to_string(),\n            digest: None,\n            total: None,\n            completed: None,\n        };\n\n        assert!(complete_progress.is_complete());\n    }\n}\n","traces":[{"line":143,"address":[2488640],"length":1,"stats":{"Line":2}},{"line":144,"address":[2096933],"length":1,"stats":{"Line":2}},{"line":145,"address":[2097004],"length":1,"stats":{"Line":2}},{"line":146,"address":[2097064],"length":1,"stats":{"Line":2}},{"line":148,"address":[2506590],"length":1,"stats":{"Line":0}},{"line":153,"address":[2507241,2506784,2507235],"length":1,"stats":{"Line":2}},{"line":154,"address":[2097204,2097417,2097628],"length":1,"stats":{"Line":6}},{"line":155,"address":[6558065,6557945,6557876],"length":1,"stats":{"Line":2}},{"line":156,"address":[2507166,2507137],"length":1,"stats":{"Line":2}},{"line":234,"address":[6558176],"length":1,"stats":{"Line":3}},{"line":235,"address":[6558193],"length":1,"stats":{"Line":3}},{"line":239,"address":[6558224],"length":1,"stats":{"Line":2}},{"line":240,"address":[2507325],"length":1,"stats":{"Line":2}},{"line":244,"address":[2097824],"length":1,"stats":{"Line":2}},{"line":245,"address":[2097838],"length":1,"stats":{"Line":2}},{"line":249,"address":[2507552],"length":1,"stats":{"Line":2}},{"line":250,"address":[6558473],"length":1,"stats":{"Line":2}},{"line":256,"address":[2489728],"length":1,"stats":{"Line":0}},{"line":257,"address":[2098033],"length":1,"stats":{"Line":0}},{"line":261,"address":[2098064],"length":1,"stats":{"Line":0}},{"line":262,"address":[2489798],"length":1,"stats":{"Line":0}},{"line":264,"address":[6669292,6669280],"length":1,"stats":{"Line":0}},{"line":268,"address":[2507744],"length":1,"stats":{"Line":0}},{"line":269,"address":[2489869],"length":1,"stats":{"Line":0}},{"line":270,"address":[2098187],"length":1,"stats":{"Line":0}},{"line":271,"address":[2098209],"length":1,"stats":{"Line":0}},{"line":272,"address":[2489932],"length":1,"stats":{"Line":0}},{"line":273,"address":[2098280],"length":1,"stats":{"Line":0}},{"line":275,"address":[2507906],"length":1,"stats":{"Line":0}},{"line":281,"address":[2507936],"length":1,"stats":{"Line":3}},{"line":285,"address":[2507966],"length":1,"stats":{"Line":3}},{"line":286,"address":[6558889],"length":1,"stats":{"Line":2}},{"line":289,"address":[2508002],"length":1,"stats":{"Line":3}},{"line":290,"address":[2098447],"length":1,"stats":{"Line":3}},{"line":292,"address":[2490216,2490168,2490183,2491052],"length":1,"stats":{"Line":13}},{"line":293,"address":[2098512],"length":1,"stats":{"Line":3}},{"line":294,"address":[2491047,2491057,2490248],"length":1,"stats":{"Line":8}},{"line":297,"address":[2508091],"length":1,"stats":{"Line":3}},{"line":298,"address":[2098564,2098747],"length":1,"stats":{"Line":4}},{"line":300,"address":[2098698,2098929],"length":1,"stats":{"Line":8}}],"covered":27,"coverable":40},{"path":["/","home","vtriple","ollama_rust_sdk","src","models","options.rs"],"content":"//! Additional options and configurations\n\nuse serde::{Deserialize, Serialize};\n\n/// Model-specific configuration options\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct ModelOptions {\n    /// Temperature setting for this model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub temperature: Option\u003cf64\u003e,\n\n    /// Top-k setting for this model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub top_k: Option\u003ci32\u003e,\n\n    /// Top-p setting for this model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub top_p: Option\u003cf64\u003e,\n\n    /// Custom system prompt for this model\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub system: Option\u003cString\u003e,\n}\n\n/// Request options for fine-tuning behavior\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct RequestOptions {\n    /// Request timeout in seconds\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub timeout: Option\u003cu64\u003e,\n\n    /// Maximum retries for failed requests\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub max_retries: Option\u003cu32\u003e,\n\n    /// Custom headers to include\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub headers: Option\u003cstd::collections::HashMap\u003cString, String\u003e\u003e,\n\n    /// Enable debug logging\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub debug: Option\u003cbool\u003e,\n}\n\n/// Streaming configuration options\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct StreamOptions {\n    /// Buffer size for streaming responses\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub buffer_size: Option\u003cusize\u003e,\n\n    /// Timeout for individual stream chunks\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub chunk_timeout: Option\u003cu64\u003e,\n\n    /// Whether to include partial responses\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub include_partial: Option\u003cbool\u003e,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_model_options_default() {\n        let opts = ModelOptions::default();\n        assert!(opts.temperature.is_none());\n        assert!(opts.top_k.is_none());\n        assert!(opts.top_p.is_none());\n        assert!(opts.system.is_none());\n    }\n\n    #[test]\n    fn test_request_options_serialization() {\n        let mut headers = std::collections::HashMap::new();\n        headers.insert(\"X-Custom\".to_string(), \"value\".to_string());\n\n        let opts = RequestOptions {\n            timeout: Some(30),\n            max_retries: Some(3),\n            headers: Some(headers),\n            debug: Some(true),\n        };\n\n        let json = serde_json::to_string(\u0026opts).unwrap();\n        let deserialized: RequestOptions = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.timeout, Some(30));\n        assert_eq!(deserialized.max_retries, Some(3));\n        assert_eq!(deserialized.debug, Some(true));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","streaming","mod.rs"],"content":"//! Streaming utilities\n\npub mod stream;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","src","streaming","stream.rs"],"content":"//! Streaming response types\n\nuse crate::{\n    error::Result,\n    models::{chat::ChatResponse, generation::GenerateResponse},\n};\nuse futures_util::Stream;\nuse std::pin::Pin;\nuse std::task::{Context, Poll};\nuse tokio_stream::StreamExt;\n\n/// Stream chunk that can contain either data or an error\npub type StreamChunk\u003cT\u003e = Result\u003cT\u003e;\n\n/// Generate response stream\npub struct GenerateStream {\n    inner: Pin\u003cBox\u003cdyn Stream\u003cItem = StreamChunk\u003cGenerateResponse\u003e\u003e + Send\u003e\u003e,\n}\n\nimpl GenerateStream {\n    /// Create a new generate stream\n    pub fn new(stream: Pin\u003cBox\u003cdyn Stream\u003cItem = StreamChunk\u003cGenerateResponse\u003e\u003e + Send\u003e\u003e) -\u003e Self {\n        Self { inner: stream }\n    }\n\n    /// Collect all responses into a single response\n    pub async fn collect_response(mut self) -\u003e Result\u003cGenerateResponse\u003e {\n        let mut final_response = None;\n        let mut full_text = String::new();\n\n        while let Some(chunk) = self.next().await {\n            let response = chunk?;\n            full_text.push_str(\u0026response.response);\n\n            if response.done {\n                final_response = Some(GenerateResponse {\n                    model: response.model,\n                    response: full_text,\n                    done: true,\n                    context: response.context,\n                    total_duration: response.total_duration,\n                    load_duration: response.load_duration,\n                    prompt_eval_count: response.prompt_eval_count,\n                    prompt_eval_duration: response.prompt_eval_duration,\n                    eval_count: response.eval_count,\n                    eval_duration: response.eval_duration,\n                });\n                break;\n            }\n        }\n\n        final_response.ok_or_else(|| {\n            crate::error::OllamaError::StreamError(\n                \"Stream ended without final response\".to_string(),\n            )\n        })\n    }\n}\n\nimpl Stream for GenerateStream {\n    type Item = StreamChunk\u003cGenerateResponse\u003e;\n\n    fn poll_next(mut self: Pin\u003c\u0026mut Self\u003e, cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cOption\u003cSelf::Item\u003e\u003e {\n        self.inner.as_mut().poll_next(cx)\n    }\n}\n\n/// Chat response stream\npub struct ChatStream {\n    inner: Pin\u003cBox\u003cdyn Stream\u003cItem = StreamChunk\u003cChatResponse\u003e\u003e + Send\u003e\u003e,\n}\n\nimpl ChatStream {\n    /// Create a new chat stream\n    pub fn new(stream: Pin\u003cBox\u003cdyn Stream\u003cItem = StreamChunk\u003cChatResponse\u003e\u003e + Send\u003e\u003e) -\u003e Self {\n        Self { inner: stream }\n    }\n\n    /// Collect all responses into a single response\n    pub async fn collect_response(mut self) -\u003e Result\u003cChatResponse\u003e {\n        let mut final_response = None;\n        let mut full_content = String::new();\n\n        while let Some(chunk) = self.next().await {\n            let response = chunk?;\n            full_content.push_str(\u0026response.message.content);\n\n            if response.done {\n                final_response = Some(ChatResponse {\n                    model: response.model,\n                    message: crate::models::chat::ChatMessage {\n                        role: response.message.role,\n                        content: full_content,\n                        images: response.message.images,\n                        tool_calls: response.message.tool_calls,\n                        tool_call_id: response.message.tool_call_id,\n                    },\n                    done: true,\n                    total_duration: response.total_duration,\n                    load_duration: response.load_duration,\n                    prompt_eval_count: response.prompt_eval_count,\n                    prompt_eval_duration: response.prompt_eval_duration,\n                    eval_count: response.eval_count,\n                    eval_duration: response.eval_duration,\n                });\n                break;\n            }\n        }\n\n        final_response.ok_or_else(|| {\n            crate::error::OllamaError::StreamError(\n                \"Stream ended without final response\".to_string(),\n            )\n        })\n    }\n}\n\nimpl Stream for ChatStream {\n    type Item = StreamChunk\u003cChatResponse\u003e;\n\n    fn poll_next(mut self: Pin\u003c\u0026mut Self\u003e, cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cOption\u003cSelf::Item\u003e\u003e {\n        self.inner.as_mut().poll_next(cx)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use futures_util::stream;\n\n    #[tokio::test]\n    async fn test_generate_stream_creation() {\n        let mock_stream = stream::empty::\u003cStreamChunk\u003cGenerateResponse\u003e\u003e();\n        let generate_stream = GenerateStream::new(Box::pin(mock_stream));\n\n        // Just test that we can create the stream without errors\n        drop(generate_stream);\n    }\n\n    #[tokio::test]\n    async fn test_chat_stream_creation() {\n        let mock_stream = stream::empty::\u003cStreamChunk\u003cChatResponse\u003e\u003e();\n        let chat_stream = ChatStream::new(Box::pin(mock_stream));\n\n        // Just test that we can create the stream without errors\n        drop(chat_stream);\n    }\n}\n","traces":[{"line":22,"address":[2069008],"length":1,"stats":{"Line":3}},{"line":27,"address":[2613184,2613197],"length":1,"stats":{"Line":0}},{"line":28,"address":[6604048],"length":1,"stats":{"Line":0}},{"line":29,"address":[2533672],"length":1,"stats":{"Line":0}},{"line":31,"address":[2567072,2567139,2567204,2568409,2567268],"length":1,"stats":{"Line":0}},{"line":32,"address":[2534253,2534154],"length":1,"stats":{"Line":0}},{"line":33,"address":[6604949,6604852],"length":1,"stats":{"Line":0}},{"line":35,"address":[2554044],"length":1,"stats":{"Line":0}},{"line":36,"address":[2535128,2534809],"length":1,"stats":{"Line":0}},{"line":37,"address":[2567921],"length":1,"stats":{"Line":0}},{"line":38,"address":[2554116],"length":1,"stats":{"Line":0}},{"line":40,"address":[6605075],"length":1,"stats":{"Line":0}},{"line":41,"address":[6605115],"length":1,"stats":{"Line":0}},{"line":42,"address":[2568064],"length":1,"stats":{"Line":0}},{"line":43,"address":[2568080],"length":1,"stats":{"Line":0}},{"line":44,"address":[2568096],"length":1,"stats":{"Line":0}},{"line":45,"address":[2534779],"length":1,"stats":{"Line":0}},{"line":46,"address":[2554281],"length":1,"stats":{"Line":0}},{"line":52,"address":[2555124,2555392],"length":1,"stats":{"Line":0}},{"line":53,"address":[2535951],"length":1,"stats":{"Line":0}},{"line":54,"address":[2569214],"length":1,"stats":{"Line":0}},{"line":63,"address":[2613232],"length":1,"stats":{"Line":1}},{"line":64,"address":[2593772],"length":1,"stats":{"Line":1}},{"line":75,"address":[2069168],"length":1,"stats":{"Line":2}},{"line":80,"address":[2593856,2593869],"length":1,"stats":{"Line":0}},{"line":81,"address":[2536179],"length":1,"stats":{"Line":0}},{"line":82,"address":[2536204],"length":1,"stats":{"Line":0}},{"line":84,"address":[2569665,2569607,2569540,2569729,2571192],"length":1,"stats":{"Line":0}},{"line":85,"address":[2570071,2569968],"length":1,"stats":{"Line":0}},{"line":86,"address":[2556494,2556591],"length":1,"stats":{"Line":0}},{"line":88,"address":[2537110],"length":1,"stats":{"Line":0}},{"line":89,"address":[2570857,2571236],"length":1,"stats":{"Line":0}},{"line":90,"address":[2570414],"length":1,"stats":{"Line":0}},{"line":91,"address":[2556844],"length":1,"stats":{"Line":0}},{"line":92,"address":[2570454],"length":1,"stats":{"Line":0}},{"line":93,"address":[2537189],"length":1,"stats":{"Line":0}},{"line":94,"address":[2556724],"length":1,"stats":{"Line":0}},{"line":95,"address":[2537276],"length":1,"stats":{"Line":0}},{"line":96,"address":[2556804],"length":1,"stats":{"Line":0}},{"line":99,"address":[6607891],"length":1,"stats":{"Line":0}},{"line":100,"address":[2556995],"length":1,"stats":{"Line":0}},{"line":101,"address":[2537523],"length":1,"stats":{"Line":0}},{"line":102,"address":[2537539],"length":1,"stats":{"Line":0}},{"line":103,"address":[2557043],"length":1,"stats":{"Line":0}},{"line":104,"address":[2557057],"length":1,"stats":{"Line":0}},{"line":110,"address":[2538571,2538832],"length":1,"stats":{"Line":0}},{"line":111,"address":[2572111],"length":1,"stats":{"Line":0}},{"line":112,"address":[2572078],"length":1,"stats":{"Line":0}},{"line":121,"address":[2069232],"length":1,"stats":{"Line":0}},{"line":122,"address":[2069260],"length":1,"stats":{"Line":0}}],"covered":4,"coverable":50},{"path":["/","home","vtriple","ollama_rust_sdk","src","types.rs"],"content":"//! Common types used throughout the SDK\n\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n/// HTTP method types\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum HttpMethod {\n    Get,\n    Post,\n    Put,\n    Delete,\n    Head,\n}\n\nimpl HttpMethod {\n    pub fn as_str(\u0026self) -\u003e \u0026'static str {\n        match self {\n            HttpMethod::Get =\u003e \"GET\",\n            HttpMethod::Post =\u003e \"POST\",\n            HttpMethod::Put =\u003e \"PUT\",\n            HttpMethod::Delete =\u003e \"DELETE\",\n            HttpMethod::Head =\u003e \"HEAD\",\n        }\n    }\n}\n\n/// Request/response metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Metadata {\n    /// Request ID for tracing\n    pub request_id: Option\u003cString\u003e,\n    /// Additional metadata fields\n    #[serde(flatten)]\n    pub extra: HashMap\u003cString, serde_json::Value\u003e,\n}\n\nimpl Default for Metadata {\n    fn default() -\u003e Self {\n        Self {\n            request_id: None,\n            extra: HashMap::new(),\n        }\n    }\n}\n\n/// Progress information for long-running operations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Progress {\n    /// Current step in the operation\n    pub step: u32,\n    /// Total number of steps\n    pub total: u32,\n    /// Human-readable status message\n    pub status: String,\n    /// Optional detailed message\n    pub detail: Option\u003cString\u003e,\n}\n\n/// API version information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct VersionInfo {\n    /// API version string\n    pub version: String,\n    /// Build information\n    pub build: Option\u003cString\u003e,\n    /// Git commit hash\n    pub commit: Option\u003cString\u003e,\n}\n\n/// Health check response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HealthStatus {\n    /// Service status\n    pub status: String,\n    /// Timestamp of the check\n    pub timestamp: Option\u003cchrono::DateTime\u003cchrono::Utc\u003e\u003e,\n    /// Additional health information\n    pub details: Option\u003cHashMap\u003cString, serde_json::Value\u003e\u003e,\n}\n\n/// Generic API response wrapper\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ApiResponse\u003cT\u003e {\n    /// Response data\n    pub data: T,\n    /// Response metadata\n    #[serde(default)]\n    pub metadata: Metadata,\n}\n\n/// Generic error response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ErrorResponse {\n    /// Error code\n    pub code: Option\u003cString\u003e,\n    /// Error message\n    pub message: String,\n    /// Detailed error information\n    pub details: Option\u003cHashMap\u003cString, serde_json::Value\u003e\u003e,\n}\n\n/// File upload information\n#[derive(Debug, Clone)]\npub struct FileUpload {\n    /// File name\n    pub filename: String,\n    /// File content\n    pub content: Vec\u003cu8\u003e,\n    /// MIME type\n    pub mime_type: Option\u003cString\u003e,\n}\n\n/// Pagination parameters\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Pagination {\n    /// Number of items per page\n    pub limit: Option\u003cu32\u003e,\n    /// Offset for pagination\n    pub offset: Option\u003cu32\u003e,\n    /// Cursor-based pagination\n    pub cursor: Option\u003cString\u003e,\n}\n\n/// Paginated response\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PaginatedResponse\u003cT\u003e {\n    /// Response items\n    pub items: Vec\u003cT\u003e,\n    /// Total number of items\n    pub total: Option\u003cu32\u003e,\n    /// Next page cursor\n    pub next_cursor: Option\u003cString\u003e,\n    /// Whether there are more items\n    pub has_more: bool,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_http_method_as_str() {\n        assert_eq!(HttpMethod::Get.as_str(), \"GET\");\n        assert_eq!(HttpMethod::Post.as_str(), \"POST\");\n        assert_eq!(HttpMethod::Put.as_str(), \"PUT\");\n        assert_eq!(HttpMethod::Delete.as_str(), \"DELETE\");\n        assert_eq!(HttpMethod::Head.as_str(), \"HEAD\");\n    }\n\n    #[test]\n    fn test_metadata_default() {\n        let metadata = Metadata::default();\n        assert!(metadata.request_id.is_none());\n        assert!(metadata.extra.is_empty());\n    }\n\n    #[test]\n    fn test_progress_serialization() {\n        let progress = Progress {\n            step: 5,\n            total: 10,\n            status: \"Processing\".to_string(),\n            detail: Some(\"Working on step 5 of 10\".to_string()),\n        };\n\n        let json = serde_json::to_string(\u0026progress).unwrap();\n        let deserialized: Progress = serde_json::from_str(\u0026json).unwrap();\n\n        assert_eq!(deserialized.step, 5);\n        assert_eq!(deserialized.total, 10);\n        assert_eq!(deserialized.status, \"Processing\");\n        assert_eq!(\n            deserialized.detail,\n            Some(\"Working on step 5 of 10\".to_string())\n        );\n    }\n}\n","traces":[{"line":17,"address":[1906304],"length":1,"stats":{"Line":2}},{"line":18,"address":[1906309],"length":1,"stats":{"Line":2}},{"line":19,"address":[1906340],"length":1,"stats":{"Line":2}},{"line":20,"address":[1906363],"length":1,"stats":{"Line":2}},{"line":21,"address":[1906386],"length":1,"stats":{"Line":2}},{"line":22,"address":[1906409],"length":1,"stats":{"Line":2}},{"line":23,"address":[1906432],"length":1,"stats":{"Line":2}},{"line":39,"address":[1906595,1906601,1906464],"length":1,"stats":{"Line":2}},{"line":42,"address":[1906497],"length":1,"stats":{"Line":2}}],"covered":9,"coverable":9},{"path":["/","home","vtriple","ollama_rust_sdk","src","utils","http.rs"],"content":"//! HTTP client utilities\n\nuse crate::{\n    config::ClientConfig,\n    error::{OllamaError, Result},\n};\nuse reqwest::{Client, RequestBuilder, Response};\nuse serde::Serialize;\n\n/// HTTP client wrapper for Ollama API requests\n#[derive(Debug, Clone)]\npub struct HttpClient {\n    client: Client,\n    config: ClientConfig,\n}\n\nimpl HttpClient {\n    /// Create a new HTTP client with the given configuration\n    pub fn new(config: ClientConfig) -\u003e Result\u003cSelf\u003e {\n        let mut client_builder = Client::builder()\n            .timeout(config.timeout)\n            .user_agent(\u0026config.user_agent);\n\n        if config.follow_redirects {\n            client_builder = client_builder.redirect(reqwest::redirect::Policy::limited(10));\n        } else {\n            client_builder = client_builder.redirect(reqwest::redirect::Policy::none());\n        }\n\n        let client = client_builder.build().map_err(|e| {\n            OllamaError::ConfigError(format!(\"Failed to create HTTP client: {}\", e))\n        })?;\n\n        Ok(Self { client, config })\n    }\n\n    /// Make a GET request\n    pub async fn get(\u0026self, path: \u0026str) -\u003e Result\u003cResponse\u003e {\n        let url = self.config.endpoint_url(path)?;\n        let request = self.client.get(url);\n        self.send_request(request).await\n    }\n\n    /// Make a POST request\n    pub fn post(\u0026self, path: \u0026str) -\u003e PostRequestBuilder {\n        let url = self.config.endpoint_url(path).expect(\"Valid URL\");\n        PostRequestBuilder {\n            request: self.client.post(url),\n            http_client: self,\n        }\n    }\n\n    /// Make a PUT request\n    pub fn put(\u0026self, path: \u0026str) -\u003e PutRequestBuilder {\n        let url = self.config.endpoint_url(path).expect(\"Valid URL\");\n        PutRequestBuilder {\n            request: self.client.put(url),\n            http_client: self,\n        }\n    }\n\n    /// Make a DELETE request\n    pub fn delete(\u0026self, path: \u0026str) -\u003e DeleteRequestBuilder {\n        let url = self.config.endpoint_url(path).expect(\"Valid URL\");\n        DeleteRequestBuilder {\n            request: self.client.delete(url),\n            http_client: self,\n        }\n    }\n\n    /// Make a HEAD request\n    pub async fn head(\u0026self, path: \u0026str) -\u003e Result\u003cResponse\u003e {\n        let url = self.config.endpoint_url(path)?;\n        let request = self.client.head(url);\n        self.send_request(request).await\n    }\n\n    /// Send a request with common headers and error handling\n    async fn send_request(\u0026self, mut request: RequestBuilder) -\u003e Result\u003cResponse\u003e {\n        // Add custom headers\n        for (key, value) in \u0026self.config.headers {\n            request = request.header(key, value);\n        }\n\n        // Add content type for JSON requests\n        request = request.header(\"Content-Type\", \"application/json\");\n\n        let response = request.send().await.map_err(|e| {\n            if e.is_timeout() {\n                OllamaError::Timeout\n            } else if e.is_connect() {\n                OllamaError::NetworkError(e)\n            } else {\n                OllamaError::NetworkError(e)\n            }\n        })?;\n\n        Ok(response)\n    }\n}\n\n/// Builder for POST requests\npub struct PostRequestBuilder\u003c'a\u003e {\n    request: RequestBuilder,\n    http_client: \u0026'a HttpClient,\n}\n\nimpl\u003c'a\u003e PostRequestBuilder\u003c'a\u003e {\n    /// Set JSON body\n    pub fn json\u003cT: Serialize\u003e(mut self, json: \u0026T) -\u003e Self {\n        self.request = self.request.json(json);\n        self\n    }\n\n    /// Set raw body\n    pub fn body\u003cT: Into\u003creqwest::Body\u003e\u003e(mut self, body: T) -\u003e Self {\n        self.request = self.request.body(body);\n        self\n    }\n\n    /// Add a header\n    pub fn header\u003cK, V\u003e(mut self, key: K, value: V) -\u003e Self\n    where\n        K: AsRef\u003cstr\u003e,\n        V: AsRef\u003cstr\u003e,\n    {\n        self.request = self.request.header(key.as_ref(), value.as_ref());\n        self\n    }\n\n    /// Send the request\n    pub async fn send(self) -\u003e Result\u003cResponse\u003e {\n        self.http_client.send_request(self.request).await\n    }\n}\n\n/// Builder for PUT requests\npub struct PutRequestBuilder\u003c'a\u003e {\n    request: RequestBuilder,\n    http_client: \u0026'a HttpClient,\n}\n\n/// Builder for DELETE requests\npub struct DeleteRequestBuilder\u003c'a\u003e {\n    request: RequestBuilder,\n    http_client: \u0026'a HttpClient,\n}\n\nimpl\u003c'a\u003e PutRequestBuilder\u003c'a\u003e {\n    /// Set raw body\n    pub fn body\u003cT: Into\u003creqwest::Body\u003e\u003e(mut self, body: T) -\u003e Self {\n        self.request = self.request.body(body);\n        self\n    }\n\n    /// Add a header\n    pub fn header\u003cK, V\u003e(mut self, key: K, value: V) -\u003e Self\n    where\n        K: AsRef\u003cstr\u003e,\n        V: AsRef\u003cstr\u003e,\n    {\n        self.request = self.request.header(key.as_ref(), value.as_ref());\n        self\n    }\n\n    /// Send the request\n    pub async fn send(self) -\u003e Result\u003cResponse\u003e {\n        self.http_client.send_request(self.request).await\n    }\n}\n\nimpl\u003c'a\u003e DeleteRequestBuilder\u003c'a\u003e {\n    /// Set JSON body\n    pub fn json\u003cT: Serialize\u003e(mut self, json: \u0026T) -\u003e Self {\n        self.request = self.request.json(json);\n        self\n    }\n\n    /// Add a header\n    pub fn header\u003cK, V\u003e(mut self, key: K, value: V) -\u003e Self\n    where\n        K: AsRef\u003cstr\u003e,\n        V: AsRef\u003cstr\u003e,\n    {\n        self.request = self.request.header(key.as_ref(), value.as_ref());\n        self\n    }\n\n    /// Send the request\n    pub async fn send(self) -\u003e Result\u003cResponse\u003e {\n        self.http_client.send_request(self.request).await\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_http_client_creation() {\n        let config = ClientConfig::default();\n        let client = HttpClient::new(config);\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    fn test_config_with_custom_headers() {\n        let mut config = ClientConfig::default();\n        config\n            .headers\n            .insert(\"X-Test\".to_string(), \"value\".to_string());\n\n        let client = HttpClient::new(config);\n        assert!(client.is_ok());\n    }\n}\n","traces":[{"line":19,"address":[2591136,2591649,2592101],"length":1,"stats":{"Line":11}},{"line":20,"address":[6661661,6661573,6661697],"length":1,"stats":{"Line":33}},{"line":21,"address":[2610742],"length":1,"stats":{"Line":11}},{"line":22,"address":[6661693],"length":1,"stats":{"Line":14}},{"line":24,"address":[2610814,2611258],"length":1,"stats":{"Line":22}},{"line":25,"address":[2129039,2128773,2129450],"length":1,"stats":{"Line":11}},{"line":27,"address":[6661735,6662027,6661851],"length":1,"stats":{"Line":0}},{"line":30,"address":[6908881,6908887,6908640],"length":1,"stats":{"Line":18}},{"line":31,"address":[2070003,2070051],"length":1,"stats":{"Line":0}},{"line":34,"address":[2591973],"length":1,"stats":{"Line":11}},{"line":38,"address":[2858165,2858901,2859007,2858000,2858035,2858945],"length":1,"stats":{"Line":18}},{"line":39,"address":[2070476,2070378],"length":1,"stats":{"Line":9}},{"line":40,"address":[2070797],"length":1,"stats":{"Line":5}},{"line":41,"address":[2525623],"length":1,"stats":{"Line":12}},{"line":45,"address":[2592176],"length":1,"stats":{"Line":2}},{"line":46,"address":[2611709],"length":1,"stats":{"Line":2}},{"line":48,"address":[2129629],"length":1,"stats":{"Line":2}},{"line":54,"address":[2129712],"length":1,"stats":{"Line":0}},{"line":55,"address":[2129757],"length":1,"stats":{"Line":0}},{"line":57,"address":[2611935],"length":1,"stats":{"Line":0}},{"line":63,"address":[2612016],"length":1,"stats":{"Line":0}},{"line":64,"address":[2612061],"length":1,"stats":{"Line":0}},{"line":66,"address":[2592623],"length":1,"stats":{"Line":0}},{"line":72,"address":[6663104,6663122],"length":1,"stats":{"Line":0}},{"line":73,"address":[2849442,2849536],"length":1,"stats":{"Line":0}},{"line":74,"address":[2859897],"length":1,"stats":{"Line":0}},{"line":75,"address":[6744439],"length":1,"stats":{"Line":0}},{"line":79,"address":[2130147,2130112],"length":1,"stats":{"Line":20}},{"line":81,"address":[2073087,2073672,2072977],"length":1,"stats":{"Line":10}},{"line":82,"address":[2861089,2861495],"length":1,"stats":{"Line":0}},{"line":86,"address":[6912088],"length":1,"stats":{"Line":5}},{"line":88,"address":[2861904,2862384,2861567,2862390,2862144,2860870,2861350],"length":1,"stats":{"Line":9}},{"line":89,"address":[6913075,6913144,6913188],"length":1,"stats":{"Line":0}},{"line":90,"address":[6913175],"length":1,"stats":{"Line":0}},{"line":91,"address":[2074410,2074448,2074366],"length":1,"stats":{"Line":0}},{"line":92,"address":[2074455],"length":1,"stats":{"Line":0}},{"line":94,"address":[2852277],"length":1,"stats":{"Line":0}},{"line":98,"address":[2851948],"length":1,"stats":{"Line":4}},{"line":110,"address":[2852640,2853024,2852768,2852896,2853280,2852384,2852512,2853152],"length":1,"stats":{"Line":6}},{"line":111,"address":[2862690,2863074,2863202,2862562,2862946,2862434,2863330,2862818],"length":1,"stats":{"Line":6}},{"line":112,"address":[6913673,6914313,6913929,6914057,6913545,6913417,6913801,6914185],"length":1,"stats":{"Line":6}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[2592849,2592832],"length":1,"stats":{"Line":8}},{"line":133,"address":[2075684,2075769,2075842,2075928],"length":1,"stats":{"Line":6}},{"line":151,"address":[2076176],"length":1,"stats":{"Line":0}},{"line":152,"address":[2076203],"length":1,"stats":{"Line":0}},{"line":153,"address":[6915075],"length":1,"stats":{"Line":0}},{"line":157,"address":[6915104,6915431],"length":1,"stats":{"Line":0}},{"line":162,"address":[2076608,2076346],"length":1,"stats":{"Line":0}},{"line":163,"address":[2854459],"length":1,"stats":{"Line":0}},{"line":167,"address":[6916089,6915687,6915491,6915818,6915650,6915456],"length":1,"stats":{"Line":0}},{"line":168,"address":[2854660,2854916,2854749,2854806],"length":1,"stats":{"Line":0}},{"line":174,"address":[2855168],"length":1,"stats":{"Line":0}},{"line":175,"address":[2077314],"length":1,"stats":{"Line":0}},{"line":176,"address":[2855273],"length":1,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[2130320,2130337],"length":1,"stats":{"Line":0}},{"line":191,"address":[2077540,2077784,2077625,2077698],"length":1,"stats":{"Line":0}}],"covered":25,"coverable":63},{"path":["/","home","vtriple","ollama_rust_sdk","src","utils","mod.rs"],"content":"//! Utility modules\n\npub mod http;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","tests","integration","mod.rs"],"content":"//! Integration tests for the Ollama Rust SDK\n\nuse ollama_rust_sdk::{OllamaClient, OllamaError};\nuse tokio_stream::StreamExt;\nuse std::time::Instant;\n\n/// Test basic client creation and health check\n#[tokio::test]\nasync fn test_client_health_check() {\n    let client = OllamaClient::new(\"http://localhost:11434\").unwrap();\n    \n    // Health check should work even if no models are available\n    let is_healthy = client.health().await.unwrap_or(false);\n    \n    // This test will pass if Ollama is running, or skip if not\n    if !is_healthy {\n        println!(\"Ollama server not running, skipping health check test\");\n    }\n}\n\n/// Test listing models (requires Ollama to be running)\n#[tokio::test]\nasync fn test_list_models() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    match client.list_models().await {\n        Ok(models) =\u003e {\n            println!(\"Found {} models\", models.models.len());\n            for model in models.models {\n                println!(\"  - {} ({})\", model.name, model.size_string());\n            }\n        }\n        Err(OllamaError::NetworkError(_)) =\u003e {\n            println!(\"Ollama server not running, skipping test\");\n        }\n        Err(e) =\u003e {\n            panic!(\"Unexpected error: {}\", e);\n        }\n    }\n}\n\n/// Test error handling for non-existent model\n#[tokio::test]\nasync fn test_model_not_found_error() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    // Try to use a model that definitely doesn't exist\n    let result = client\n        .generate()\n        .model(\"definitely-not-a-real-model-12345\")\n        .prompt(\"test\")\n        .send()\n        .await;\n    \n    match result {\n        Err(OllamaError::ModelNotFound(model)) =\u003e {\n            assert_eq!(model, \"definitely-not-a-real-model-12345\");\n        }\n        Err(OllamaError::NetworkError(_)) =\u003e {\n            println!(\"Ollama server not running, skipping test\");\n        }\n        Ok(_) =\u003e {\n            panic!(\"Expected ModelNotFound error, but request succeeded\");\n        }\n        Err(e) =\u003e {\n            println!(\"Got different error (acceptable): {}\", e);\n        }\n    }\n}\n\n/// Test basic text generation with first available model\n#[tokio::test]\nasync fn test_generation_with_available_model() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    // Check if server is healthy\n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    // Get available models\n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing generation with model: {}\", model_name);\n    \n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"What is 1+1? Answer in one sentence.\")\n        .temperature(0.1)\n        .max_tokens(50)\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Generated response: {}\", resp.response);\n            println!(\"Generation took: {:?}\", duration);\n            assert!(!resp.response.is_empty());\n            assert_eq!(resp.model, *model_name);\n            assert!(resp.done);\n        }\n        Err(e) =\u003e {\n            println!(\"Generation failed: {}\", e);\n            // Don't panic, just log the error\n        }\n    }\n}\n\n/// Test streaming generation with first available model\n#[tokio::test]\nasync fn test_streaming_generation() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing streaming with model: {}\", model_name);\n    \n    let mut stream = match client\n        .generate()\n        .model(model_name)\n        .prompt(\"Count from 1 to 3:\")\n        .temperature(0.1)\n        .max_tokens(30)\n        .stream()\n        .await\n    {\n        Ok(stream) =\u003e stream,\n        Err(e) =\u003e {\n            println!(\"Failed to create stream: {}\", e);\n            return;\n        }\n    };\n    \n    let mut full_response = String::new();\n    let mut chunk_count = 0;\n    \n    while let Some(chunk) = stream.next().await {\n        match chunk {\n            Ok(response) =\u003e {\n                full_response.push_str(\u0026response.response);\n                chunk_count += 1;\n                \n                if response.done {\n                    println!(\"Streaming completed after {} chunks\", chunk_count);\n                    println!(\"Full response: {}\", full_response);\n                    break;\n                }\n            }\n            Err(e) =\u003e {\n                println!(\"Stream error: {}\", e);\n                break;\n            }\n        }\n    }\n    \n    assert!(chunk_count \u003e 0, \"Should have received at least one chunk\");\n    assert!(!full_response.is_empty(), \"Should have received some response\");\n}\n\n/// Test chat completion with first available model\n#[tokio::test]\nasync fn test_chat_completion() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing chat with model: {}\", model_name);\n    \n    let response = client\n        .chat()\n        .model(model_name)\n        .add_system_message(\"You are a helpful assistant. Keep responses very brief.\")\n        .add_user_message(\"What is the capital of France?\")\n        .temperature(0.1)\n        .max_tokens(20)\n        .send()\n        .await;\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Chat response: {}\", resp.message.content);\n            assert!(!resp.message.content.is_empty());\n            assert_eq!(resp.model, *model_name);\n            assert!(resp.done);\n        }\n        Err(e) =\u003e {\n            println!(\"Chat failed: {}\", e);\n            // Don't panic, just log the error\n        }\n    }\n}\n\n/// Test embeddings with embedding model if available\n#[tokio::test]\nasync fn test_embeddings() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    // Look for embedding models\n    let embedding_model = models.models.iter()\n        .find(|m| m.name.contains(\"embed\") || m.name.contains(\"nomic\"))\n        .map(|m| m.name.as_str());\n    \n    let model_name = match embedding_model {\n        Some(name) =\u003e name,\n        None =\u003e {\n            println!(\"No embedding model available, skipping test\");\n            return;\n        }\n    };\n    \n    println!(\"Testing embeddings with model: {}\", model_name);\n    \n    let response = client\n        .embed()\n        .model(model_name)\n        .input(vec![\"Hello world\".to_string(), \"Test text\".to_string()])\n        .send()\n        .await;\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Generated {} embeddings\", resp.count());\n            println!(\"Embedding dimensions: {:?}\", resp.dimensions());\n            assert_eq!(resp.count(), 2);\n            assert!(resp.dimensions().unwrap_or(0) \u003e 0);\n        }\n        Err(e) =\u003e {\n            println!(\"Embeddings failed: {}\", e);\n            // Don't panic, just log the error\n        }\n    }\n}\n\n/// Test performance metrics\n#[tokio::test]\nasync fn test_performance_metrics() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing performance with model: {}\", model_name);\n    \n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"Generate a short poem about performance.\")\n        .temperature(0.7)\n        .max_tokens(100)\n        .send()\n        .await;\n    let total_time = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Performance test completed in: {:?}\", total_time);\n            \n            if let Some(eval_rate) = resp.eval_rate() {\n                println!(\"Evaluation rate: {:.2} tokens/second\", eval_rate);\n                assert!(eval_rate \u003e 0.0, \"Evaluation rate should be positive\");\n            }\n            \n            if let Some(total_duration) = resp.total_duration {\n                let total_seconds = total_duration as f64 / 1e9;\n                println!(\"Total generation time: {:.2}s\", total_seconds);\n                assert!(total_seconds \u003e 0.0, \"Total duration should be positive\");\n            }\n            \n            if let Some(eval_count) = resp.eval_count {\n                println!(\"Tokens evaluated: {}\", eval_count);\n                assert!(eval_count \u003e 0, \"Should have evaluated some tokens\");\n            }\n        }\n        Err(e) =\u003e {\n            println!(\"Performance test failed: {}\", e);\n        }\n    }\n}","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","tests","integration.rs"],"content":"//! Integration tests for the Ollama Rust SDK\n\nuse ollama_rust_sdk::{OllamaClient, OllamaError};\nuse std::time::Instant;\n\n/// Test basic client creation and health check\n#[tokio::test]\nasync fn test_client_health_check() {\n    let client = OllamaClient::new(\"http://localhost:11434\").unwrap();\n    \n    // Health check should work even if no models are available\n    let is_healthy = client.health().await.unwrap_or(false);\n    \n    // This test will pass if Ollama is running, or skip if not\n    if !is_healthy {\n        println!(\"Ollama server not running, skipping health check test\");\n    }\n}\n\n/// Test listing models (requires Ollama to be running)\n#[tokio::test]\nasync fn test_list_models() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    match client.list_models().await {\n        Ok(models) =\u003e {\n            println!(\"Found {} models\", models.models.len());\n            for model in models.models {\n                println!(\"  - {} ({})\", model.name, model.size_string());\n            }\n        }\n        Err(OllamaError::NetworkError(_)) =\u003e {\n            println!(\"Ollama server not running, skipping test\");\n        }\n        Err(e) =\u003e {\n            panic!(\"Unexpected error: {}\", e);\n        }\n    }\n}\n\n/// Test basic text generation with first available model\n#[tokio::test]\nasync fn test_generation_with_available_model() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    // Check if server is healthy\n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    // Get available models\n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing generation with model: {}\", model_name);\n    \n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"What is 1+1? Answer in one sentence.\")\n        .temperature(0.1)\n        .max_tokens(50)\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Generated response: {}\", resp.response);\n            println!(\"Generation took: {:?}\", duration);\n            assert!(!resp.response.is_empty());\n            assert_eq!(resp.model, *model_name);\n            assert!(resp.done);\n        }\n        Err(e) =\u003e {\n            println!(\"Generation failed: {}\", e);\n            // Don't panic, just log the error\n        }\n    }\n}\n\n/// Test performance metrics\n#[tokio::test]\nasync fn test_performance_metrics() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"Testing performance with model: {}\", model_name);\n    \n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"Generate a short poem about performance.\")\n        .temperature(0.7)\n        .max_tokens(100)\n        .send()\n        .await;\n    let total_time = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Performance test completed in: {:?}\", total_time);\n            \n            if let Some(eval_rate) = resp.eval_rate() {\n                println!(\"Evaluation rate: {:.2} tokens/second\", eval_rate);\n                assert!(eval_rate \u003e 0.0, \"Evaluation rate should be positive\");\n            }\n            \n            if let Some(total_duration) = resp.total_duration {\n                let total_seconds = total_duration as f64 / 1e9;\n                println!(\"Total generation time: {:.2}s\", total_seconds);\n                assert!(total_seconds \u003e 0.0, \"Total duration should be positive\");\n            }\n            \n            if let Some(eval_count) = resp.eval_count {\n                println!(\"Tokens evaluated: {}\", eval_count);\n                assert!(eval_count \u003e 0, \"Should have evaluated some tokens\");\n            }\n        }\n        Err(e) =\u003e {\n            println!(\"Performance test failed: {}\", e);\n        }\n    }\n}\n\n/// Test embeddings with embedding model if available\n#[tokio::test]\nasync fn test_embeddings() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping test\");\n            return;\n        }\n    };\n    \n    // Look for embedding models\n    let embedding_model = models.models.iter()\n        .find(|m| m.name.contains(\"embed\") || m.name.contains(\"nomic\"))\n        .map(|m| m.name.as_str());\n    \n    let model_name = match embedding_model {\n        Some(name) =\u003e name,\n        None =\u003e {\n            println!(\"No embedding model available, skipping test\");\n            return;\n        }\n    };\n    \n    println!(\"Testing embeddings with model: {}\", model_name);\n    \n    let response = client\n        .embed()\n        .model(model_name)\n        .input(vec![\"Hello world\".to_string(), \"Test text\".to_string()])\n        .send()\n        .await;\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Generated {} embeddings\", resp.count());\n            println!(\"Embedding dimensions: {:?}\", resp.dimensions());\n            assert_eq!(resp.count(), 2);\n            assert!(resp.dimensions().unwrap_or(0) \u003e 0);\n        }\n        Err(e) =\u003e {\n            println!(\"Embeddings failed: {}\", e);\n            // Don't panic, just log the error\n        }\n    }\n}","traces":[],"covered":0,"coverable":0},{"path":["/","home","vtriple","ollama_rust_sdk","tests","performance.rs"],"content":"//! Performance tests for the Ollama Rust SDK\n\nuse ollama_rust_sdk::{OllamaClient};\nuse tokio_stream::StreamExt;\nuse std::time::Instant;\n\n/// Test generation performance with different parameters\n#[tokio::test]\nasync fn test_generation_performance_metrics() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping performance test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping performance test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping performance test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping performance test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"\\\\n=== Performance Test Results ===\");\n    println!(\"Model: {}\", model_name);\n    \n    // Test 1: Short prompt, fast response\n    println!(\"\\\\n--- Test 1: Short Prompt ---\");\n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"Hello\")\n        .temperature(0.1)\n        .max_tokens(10)\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Response: {}\", resp.response);\n            println!(\"Wall clock time: {:?}\", duration);\n            \n            if let Some(total_duration) = resp.total_duration {\n                let server_time = total_duration as f64 / 1e9;\n                println!(\"Server total time: {:.3}s\", server_time);\n            }\n            \n            if let Some(eval_rate) = resp.eval_rate() {\n                println!(\"Generation rate: {:.2} tokens/second\", eval_rate);\n            }\n        }\n        Err(e) =\u003e println!(\"Test 1 failed: {}\", e),\n    }\n    \n    // Test 2: Medium prompt\n    println!(\"\\\\n--- Test 2: Medium Prompt ---\");\n    let start = Instant::now();\n    let response = client\n        .generate()\n        .model(model_name)\n        .prompt(\"Write a short paragraph about artificial intelligence.\")\n        .temperature(0.7)\n        .max_tokens(100)\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Response length: {} characters\", resp.response.len());\n            println!(\"Wall clock time: {:?}\", duration);\n            \n            if let Some(total_duration) = resp.total_duration {\n                let server_time = total_duration as f64 / 1e9;\n                println!(\"Server total time: {:.3}s\", server_time);\n            }\n            \n            if let Some(eval_rate) = resp.eval_rate() {\n                println!(\"Generation rate: {:.2} tokens/second\", eval_rate);\n            }\n            \n            if let Some(eval_count) = resp.eval_count {\n                println!(\"Tokens generated: {}\", eval_count);\n            }\n        }\n        Err(e) =\u003e println!(\"Test 2 failed: {}\", e),\n    }\n    \n    // Test 3: Streaming performance\n    println!(\"\\\\n--- Test 3: Streaming Performance ---\");\n    let start = Instant::now();\n    let mut stream = match client\n        .generate()\n        .model(model_name)\n        .prompt(\"Count from 1 to 10 with explanations:\")\n        .temperature(0.3)\n        .max_tokens(150)\n        .stream()\n        .await\n    {\n        Ok(stream) =\u003e stream,\n        Err(e) =\u003e {\n            println!(\"Failed to create stream: {}\", e);\n            return;\n        }\n    };\n    \n    let mut chunks = 0;\n    let mut total_chars = 0;\n    let mut first_token_time: Option\u003cInstant\u003e = None;\n    \n    while let Some(chunk) = stream.next().await {\n        match chunk {\n            Ok(response) =\u003e {\n                if first_token_time.is_none() \u0026\u0026 !response.response.is_empty() {\n                    first_token_time = Some(Instant::now());\n                }\n                \n                chunks += 1;\n                total_chars += response.response.len();\n                \n                if response.done {\n                    let total_time = start.elapsed();\n                    println!(\"Streaming completed:\");\n                    println!(\"  Total chunks: {}\", chunks);\n                    println!(\"  Total characters: {}\", total_chars);\n                    println!(\"  Total time: {:?}\", total_time);\n                    \n                    if let Some(first_token) = first_token_time {\n                        let time_to_first_token = first_token.duration_since(start);\n                        println!(\"  Time to first token: {:?}\", time_to_first_token);\n                    }\n                    \n                    if let Some(eval_rate) = response.eval_rate() {\n                        println!(\"  Final generation rate: {:.2} tokens/second\", eval_rate);\n                    }\n                    \n                    break;\n                }\n            }\n            Err(e) =\u003e {\n                println!(\"Stream error: {}\", e);\n                break;\n            }\n        }\n    }\n    \n    println!(\"\\\\n=== Performance Summary ===\");\n    println!(\"All performance tests completed successfully!\");\n}\n\n/// Test chat performance\n#[tokio::test]\nasync fn test_chat_performance() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping chat performance test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping chat performance test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping chat performance test\");\n            return;\n        }\n    };\n    \n    if models.models.is_empty() {\n        println!(\"No models available, skipping chat performance test\");\n        return;\n    }\n    \n    let model_name = \u0026models.models[0].name;\n    println!(\"\\\\n=== Chat Performance Test ===\");\n    println!(\"Model: {}\", model_name);\n    \n    let start = Instant::now();\n    let response = client\n        .chat()\n        .model(model_name)\n        .add_system_message(\"You are a helpful assistant.\")\n        .add_user_message(\"What is the capital of Japan?\")\n        .temperature(0.3)\n        .max_tokens(50)\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Chat response: {}\", resp.message.content);\n            println!(\"Wall clock time: {:?}\", duration);\n            \n            if let Some(total_duration) = resp.total_duration {\n                let server_time = total_duration as f64 / 1e9;\n                println!(\"Server total time: {:.3}s\", server_time);\n            }\n            \n            if let Some(eval_rate) = resp.eval_rate() {\n                println!(\"Generation rate: {:.2} tokens/second\", eval_rate);\n            }\n        }\n        Err(e) =\u003e println!(\"Chat performance test failed: {}\", e),\n    }\n}\n\n/// Test embeddings performance\n#[tokio::test]\nasync fn test_embeddings_performance() {\n    let client = match OllamaClient::new(\"http://localhost:11434\") {\n        Ok(client) =\u003e client,\n        Err(_) =\u003e {\n            println!(\"Failed to create client, skipping embeddings performance test\");\n            return;\n        }\n    };\n    \n    if !client.health().await.unwrap_or(false) {\n        println!(\"Ollama server not healthy, skipping embeddings performance test\");\n        return;\n    }\n    \n    let models = match client.list_models().await {\n        Ok(models) =\u003e models,\n        Err(_) =\u003e {\n            println!(\"Could not list models, skipping embeddings performance test\");\n            return;\n        }\n    };\n    \n    // Look for embedding models\n    let embedding_model = models.models.iter()\n        .find(|m| m.name.contains(\"embed\") || m.name.contains(\"nomic\"))\n        .map(|m| m.name.as_str());\n    \n    let model_name = match embedding_model {\n        Some(name) =\u003e name,\n        None =\u003e {\n            println!(\"No embedding model available, skipping embeddings performance test\");\n            return;\n        }\n    };\n    \n    println!(\"\\\\n=== Embeddings Performance Test ===\");\n    println!(\"Model: {}\", model_name);\n    \n    let texts = vec![\n        \"This is a test sentence for embeddings.\",\n        \"Machine learning is a fascinating field.\",\n        \"Performance testing is important for quality software.\",\n        \"Rust is a systems programming language.\",\n        \"Artificial intelligence will shape the future.\",\n    ];\n    \n    let start = Instant::now();\n    let response = client\n        .embed()\n        .model(model_name)\n        .input(texts.clone())\n        .send()\n        .await;\n    let duration = start.elapsed();\n    \n    match response {\n        Ok(resp) =\u003e {\n            println!(\"Generated {} embeddings\", resp.count());\n            println!(\"Embedding dimensions: {:?}\", resp.dimensions());\n            println!(\"Total time: {:?}\", duration);\n            println!(\"Average time per text: {:?}\", duration / texts.len() as u32);\n            \n            if let Some(total_duration) = resp.total_duration {\n                let server_time = total_duration as f64 / 1e9;\n                println!(\"Server total time: {:.3}s\", server_time);\n            }\n        }\n        Err(e) =\u003e println!(\"Embeddings performance test failed: {}\", e),\n    }\n}","traces":[],"covered":0,"coverable":0}]};
        var previousData = null;
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      }
    };
  });

  return [
    ...folders,
    ...files.filter(file => file.path.length === 1),
  ];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener("hashchange", () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.substr(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(({current}) => {
      return {current: [...current, file.path[0]]};
    }, () => this.updateHash());
  }

  back(file) {
    this.setState(({current}) => {
      return {current: current.slice(0, current.length - 1)};
    }, () => this.updateHash());
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e('div', {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e('table', {className: 'files-list'},
      e('thead', {className: 'files-list__head'},
        e('tr', null,
          e('th', null, "Path"),
          e('th', null, "Coverage")
        )
      ),
      e('tbody', {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile}))
      )
    )
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? file.covered / file.coverable * 100 : -1;
  const coverageDelta = file.prevRun &&
    (file.covered / file.coverable * 100 - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('tr', {
      className: 'files-list__file'
        + (coverage >= 0 && coverage < 50 ? ' files-list__file_low': '')
        + (coverage >= 50 && coverage < 80 ? ' files-list__file_medium': '')
        + (coverage >= 80 ? ' files-list__file_high': '')
        + (file.is_folder ? ' files-list__file_folder': ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e('td', null,
      file.covered + ' / ' + file.coverable +
      (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'},
    e(FileHeader, {file, onBack}),
    e(FileContent, {file})
  );
}

function FileHeader({file, onBack}) {
  const coverage = file.covered / file.coverable * 100;
  const coverageDelta = file.prevRun && (coverage - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('div', {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e('div', {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable +
      (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function FileContent({file}) {
  return e('pre', {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      return e('code', {
          className: 'code-line'
            + (covered ? ' code-line_covered' : '')
            + (uncovered ? ' code-line_uncovered' : ''),
          title: trace ? JSON.stringify(trace.stats, null, 2) : null,
        }, line);
    })
  );
}

(function(){
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData && previousData.files.forEach((file) => {
    const path = file.path.slice(commonPath.length).join('/');
    prevFilesMap.set(path, file);
  });

  const files = data.files.map((file) => {
    const path = file.path.slice(commonPath.length);
    const { covered = 0, coverable = 0 } = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: { covered, coverable },
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    }
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));
}());
</script>
</body>
</html>