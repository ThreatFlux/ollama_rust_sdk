name: Ollama Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run integration tests daily
    - cron: '0 4 * * *'
  workflow_dispatch:

jobs:
  integration-test:
    name: Ollama Integration Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        model: ["llama3.2:1b", "qwen2.5:0.5b"]  # Small models for CI
    
    services:
      ollama:
        image: ollama/ollama:latest
        ports:
          - 11434:11434
        options: >-
          --health-cmd "ollama list || exit 1"
          --health-interval 15s
          --health-timeout 10s
          --health-retries 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable

    - name: Cache cargo
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-integration-${{ hashFiles('**/Cargo.lock') }}

    - name: Wait for Ollama
      run: |
        for i in {1..30}; do
          if curl -s http://localhost:11434/ > /dev/null; then
            echo "Ollama is ready"
            break
          fi
          echo "Waiting for Ollama... ($i/30)"
          sleep 2
        done

    - name: Pull test model
      run: |
        curl -X POST http://localhost:11434/api/pull \
          -d '{"name": "${{ matrix.model }}", "stream": false}'
        
        # Wait for model to be ready
        sleep 5
        
        # Verify model is available
        curl http://localhost:11434/api/tags | jq .

    - name: Run integration tests
      env:
        OLLAMA_HOST: http://localhost:11434
        TEST_MODEL: ${{ matrix.model }}
      run: |
        cargo test --test integration -- --nocapture
        
    - name: Test examples
      env:
        OLLAMA_HOST: http://localhost:11434
      run: |
        # Test basic generation
        cargo run --example basic_generation
        
        # Test streaming
        timeout 30 cargo run --example streaming_chat || true
        
        # Test embeddings
        cargo run --example embeddings

  tool-calling-test:
    name: Tool Calling Integration
    runs-on: ubuntu-latest
    
    services:
      ollama:
        image: ollama/ollama:latest
        ports:
          - 11434:11434
        options: >-
          --health-cmd "ollama list || exit 1"
          --health-interval 15s
          --health-timeout 10s
          --health-retries 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable

    - name: Wait for Ollama
      run: |
        for i in {1..30}; do
          if curl -s http://localhost:11434/ > /dev/null; then
            echo "Ollama is ready"
            break
          fi
          echo "Waiting for Ollama... ($i/30)"
          sleep 2
        done

    - name: Pull tool-supporting model
      run: |
        # Try to pull a model that supports tools
        # Note: This might fail if the model is too large for CI
        curl -X POST http://localhost:11434/api/pull \
          -d '{"name": "mistral:7b-instruct", "stream": false}' || \
        curl -X POST http://localhost:11434/api/pull \
          -d '{"name": "llama3.2:3b-instruct", "stream": false}'
        
        sleep 5

    - name: Test tool calling
      env:
        OLLAMA_HOST: http://localhost:11434
      run: |
        # Test if model supports tools
        cargo run --example tool_test || echo "Model may not support tool calling"
        
        # Test streaming with tools
        timeout 30 cargo run --example streaming_tools || echo "Streaming tools test completed"

  docker-test:
    name: Docker Build Test
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: ollama-rust-sdk:test
        cache-from: type=gha
        cache-to: type=gha,mode=max